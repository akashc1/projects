{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M_W4mLIRd0B"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "data_dir = '/content/drive/My Drive/cs461/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1s_77-0Sq1A"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLrMnwIESuzA"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "  def __init__(self):\n",
    "    self.use_cuda = True\n",
    "    self.log_interval = 1\n",
    "    self.train_batch_size = 64\n",
    "    self.test_batch_size = 64\n",
    "    self.lr = 0.01\n",
    "    self.momentum = 0.9\n",
    "    self.num_epochs = 3\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tpasRb_ESy2z",
    "outputId": "987c0601-5417-4cb1-ed22-6ac0d3dfc3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if args.use_cuda and torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "\n",
    "print('Using {}.'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "llCnf5B_S0Gd"
   },
   "outputs": [],
   "source": [
    "def prepare_data(args):\n",
    "  kwargs = {}\n",
    "  if args.use_cuda and torch.cuda.is_available():\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "  mean = (0.485, 0.456, 0.406)\n",
    "  std = (0.229, 0.224, 0.225)\n",
    "\n",
    "  train_transform = transforms.Compose([\n",
    "      transforms.Lambda(lambda x: x.convert('RGB')),\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean, std),\n",
    "  ])\n",
    "  test_transform = transforms.Compose([\n",
    "      transforms.Lambda(lambda x: x.convert('RGB')),\n",
    "      transforms.Resize(256),\n",
    "      transforms.CenterCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean, std),\n",
    "  ])\n",
    "\n",
    "  # Load original data set with training transforms.\n",
    "  dataset = torchvision.datasets.Caltech101(\n",
    "      root=data_dir, download=True, transform=train_transform)\n",
    "  \n",
    "  n = len(dataset)\n",
    "  train_indices = [i for i in range(n) if i % 5 != 0 and i % 5 != 1]\n",
    "  val_indices = [i for i in range(n) if i % 5 == 1]\n",
    "  test_indices = [i for i in range(n) if i % 5 == 0]\n",
    "\n",
    "  # Train.\n",
    "  train_set = torch.utils.data.Subset(dataset, train_indices)\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "      train_set, batch_size=args.train_batch_size, shuffle=True, **kwargs)\n",
    "  \n",
    "  # Load original data set with testing transforms.\n",
    "  dataset = torchvision.datasets.Caltech101(\n",
    "      root=data_dir, download=False, transform=test_transform)\n",
    "\n",
    "  # Val.\n",
    "  val_set = torch.utils.data.Subset(dataset, val_indices)\n",
    "  val_loader = torch.utils.data.DataLoader(\n",
    "      val_set, batch_size=args.test_batch_size, shuffle=False, **kwargs)\n",
    "  \n",
    "  # Test.\n",
    "  test_set = torch.utils.data.Subset(dataset, test_indices)\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "      test_set, batch_size=args.test_batch_size, shuffle=False, **kwargs)\n",
    "  \n",
    "  return train_set, val_set, test_set, train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "EB6CmEnK33h4",
    "outputId": "adf9e9a7-f799-4b41-d701-58335d3d25a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz to /content/drive/My Drive/cs461/data/caltech101/101_ObjectCategories.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 131530752/131740031 [00:16<00:00, 9517562.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/drive/My Drive/cs461/data/caltech101/101_ObjectCategories.tar.gz to /content/drive/My Drive/cs461/data/caltech101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.vision.caltech.edu/Image_Datasets/Caltech101/Annotations.tar to /content/drive/My Drive/cs461/data/caltech101/101_Annotations.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/14028800 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/14028800 [00:00<02:13, 105248.98it/s]\u001b[A\n",
      "  0%|          | 49152/14028800 [00:00<01:53, 123559.50it/s]\u001b[A\n",
      "  1%|          | 106496/14028800 [00:00<01:30, 154100.89it/s]\u001b[A\n",
      "  2%|▏         | 221184/14028800 [00:01<01:08, 201845.80it/s]\u001b[A\n",
      "  3%|▎         | 385024/14028800 [00:01<00:51, 266191.27it/s]\u001b[A\n",
      "  6%|▌         | 786432/14028800 [00:01<00:36, 364002.75it/s]\u001b[A\n",
      " 10%|█         | 1425408/14028800 [00:01<00:25, 500748.13it/s]\u001b[A\n",
      " 14%|█▍        | 2015232/14028800 [00:01<00:17, 674813.25it/s]\u001b[A\n",
      " 17%|█▋        | 2351104/14028800 [00:01<00:13, 853780.88it/s]\u001b[A\n",
      " 26%|██▋       | 3694592/14028800 [00:02<00:08, 1169490.32it/s]\u001b[A\n",
      " 32%|███▏      | 4497408/14028800 [00:02<00:06, 1521146.38it/s]\u001b[A\n",
      " 38%|███▊      | 5308416/14028800 [00:02<00:04, 1928812.32it/s]\u001b[A\n",
      " 44%|████▍     | 6144000/14028800 [00:02<00:03, 2379570.18it/s]\u001b[A\n",
      " 50%|████▉     | 6987776/14028800 [00:02<00:02, 2861806.60it/s]\u001b[A\n",
      " 56%|█████▌    | 7856128/14028800 [00:02<00:01, 3344782.96it/s]\u001b[A\n",
      " 62%|██████▏   | 8740864/14028800 [00:02<00:01, 3792424.55it/s]\u001b[A\n",
      " 69%|██████▊   | 9633792/14028800 [00:03<00:01, 4227244.68it/s]\u001b[A\n",
      " 75%|███████▌  | 10551296/14028800 [00:03<00:00, 4606801.69it/s]\u001b[A\n",
      " 82%|████████▏ | 11476992/14028800 [00:03<00:00, 4926266.93it/s]\u001b[A\n",
      " 89%|████████▊ | 12419072/14028800 [00:03<00:00, 5201592.47it/s]\u001b[A\n",
      " 95%|█████████▌| 13377536/14028800 [00:03<00:00, 5414132.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/drive/My Drive/cs461/data/caltech101/101_Annotations.tar to /content/drive/My Drive/cs461/data/caltech101\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set, train_loader, val_loader, test_loader = prepare_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBDXkn__2cQb"
   },
   "source": [
    "Define the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMMSANaK2b0F"
   },
   "outputs": [],
   "source": [
    "def train(args, model, criterion, train_loader, optimizer, device):\n",
    "  model.train()\n",
    "  total_loss = 0.\n",
    "  for i, data in enumerate(train_loader):\n",
    "    imgs, lbls = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(imgs)\n",
    "    loss = criterion(outputs, lbls)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    if (i + 1) % args.log_interval == 0:\n",
    "      mean_loss = total_loss / args.log_interval\n",
    "      print('  batch {:4d}: loss={:.3f}'.format(i + 1, mean_loss))\n",
    "      total_loss = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6F-t6K3Z2sCC"
   },
   "source": [
    "Define the testing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YN6nQOkN2pDx",
    "outputId": "d183899b-3e1f-4ef9-a5dd-a69349dc5df8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14032896it [00:20, 5414132.73it/s]                              \u001b[A"
     ]
    }
   ],
   "source": [
    "def test(args, model, test_loader, device):\n",
    "  model.eval()\n",
    "  total, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "      imgs, lbls = data[0].to(device), data[1].to(device)\n",
    "      outputs = model(imgs)\n",
    "      _, preds = torch.max(outputs.data, 1)\n",
    "      total += lbls.shape[0]\n",
    "      correct += (preds == lbls).sum().item()\n",
    "\n",
    "  acc = correct / total\n",
    "  print('  acc={:.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cS-lRDjD2vCV"
   },
   "source": [
    "Run training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K1qIspAO2u2c",
    "outputId": "59b6d969-2b35-44ef-eca8-27d90a02bf76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n",
      "\n",
      "\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 7.19M/13.6M [00:00<00:00, 75.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 85.2MB/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "  batch    1: loss=4.709\n",
      "  batch    2: loss=4.617\n",
      "  batch    3: loss=4.690\n",
      "  batch    4: loss=4.437\n",
      "  batch    5: loss=4.321\n",
      "  batch    6: loss=4.100\n",
      "  batch    7: loss=4.224\n",
      "  batch    8: loss=3.464\n",
      "  batch    9: loss=3.558\n",
      "  batch   10: loss=3.634\n",
      "  batch   11: loss=3.670\n",
      "  batch   12: loss=3.510\n",
      "  batch   13: loss=3.569\n",
      "  batch   14: loss=3.395\n",
      "  batch   15: loss=3.562\n",
      "  batch   16: loss=2.827\n",
      "  batch   17: loss=3.026\n",
      "  batch   18: loss=3.367\n",
      "  batch   19: loss=2.984\n",
      "  batch   20: loss=2.737\n",
      "  batch   21: loss=3.318\n",
      "  batch   22: loss=3.693\n",
      "  batch   23: loss=3.256\n",
      "  batch   24: loss=2.967\n",
      "  batch   25: loss=2.972\n",
      "  batch   26: loss=3.447\n",
      "  batch   27: loss=2.661\n",
      "  batch   28: loss=3.007\n",
      "  batch   29: loss=2.804\n",
      "  batch   30: loss=2.590\n",
      "  batch   31: loss=3.261\n",
      "  batch   32: loss=2.531\n",
      "  batch   33: loss=2.364\n",
      "  batch   34: loss=2.690\n",
      "  batch   35: loss=2.452\n",
      "  batch   36: loss=2.607\n",
      "  batch   37: loss=2.461\n",
      "  batch   38: loss=2.977\n",
      "  batch   39: loss=2.651\n",
      "  batch   40: loss=2.593\n",
      "  batch   41: loss=2.750\n",
      "  batch   42: loss=2.606\n",
      "  batch   43: loss=2.425\n",
      "  batch   44: loss=2.668\n",
      "  batch   45: loss=2.565\n",
      "  batch   46: loss=2.308\n",
      "  batch   47: loss=2.234\n",
      "  batch   48: loss=1.879\n",
      "  batch   49: loss=2.321\n",
      "  batch   50: loss=2.004\n",
      "  batch   51: loss=2.103\n",
      "  batch   52: loss=2.331\n",
      "  batch   53: loss=2.638\n",
      "  batch   54: loss=2.329\n",
      "  batch   55: loss=2.321\n",
      "  batch   56: loss=1.953\n",
      "  batch   57: loss=1.836\n",
      "  batch   58: loss=2.035\n",
      "  batch   59: loss=2.286\n",
      "  batch   60: loss=2.178\n",
      "  batch   61: loss=2.074\n",
      "  batch   62: loss=2.139\n",
      "  batch   63: loss=1.813\n",
      "  batch   64: loss=1.717\n",
      "  batch   65: loss=2.032\n",
      "  batch   66: loss=1.944\n",
      "  batch   67: loss=1.985\n",
      "  batch   68: loss=1.749\n",
      "  batch   69: loss=1.663\n",
      "  batch   70: loss=2.091\n",
      "  batch   71: loss=1.388\n",
      "  batch   72: loss=2.128\n",
      "  batch   73: loss=1.840\n",
      "  batch   74: loss=1.822\n",
      "  batch   75: loss=1.468\n",
      "  batch   76: loss=1.566\n",
      "  batch   77: loss=2.070\n",
      "  batch   78: loss=1.545\n",
      "  batch   79: loss=1.802\n",
      "  batch   80: loss=1.641\n",
      "  batch   81: loss=1.541\n",
      "  batch   82: loss=2.516\n",
      "Testing on validation set\n",
      "  acc=0.713\n",
      "Training epoch 1\n",
      "  batch    1: loss=1.542\n",
      "  batch    2: loss=1.567\n",
      "  batch    3: loss=1.465\n",
      "  batch    4: loss=1.448\n",
      "  batch    5: loss=1.472\n",
      "  batch    6: loss=1.492\n",
      "  batch    7: loss=1.504\n",
      "  batch    8: loss=1.174\n",
      "  batch    9: loss=1.099\n",
      "  batch   10: loss=1.468\n",
      "  batch   11: loss=1.784\n",
      "  batch   12: loss=1.487\n",
      "  batch   13: loss=1.535\n",
      "  batch   14: loss=1.158\n",
      "  batch   15: loss=1.337\n",
      "  batch   16: loss=1.200\n",
      "  batch   17: loss=1.252\n",
      "  batch   18: loss=1.331\n",
      "  batch   19: loss=1.310\n",
      "  batch   20: loss=1.055\n",
      "  batch   21: loss=1.240\n",
      "  batch   22: loss=1.226\n",
      "  batch   23: loss=1.402\n",
      "  batch   24: loss=1.312\n",
      "  batch   25: loss=1.066\n",
      "  batch   26: loss=1.309\n",
      "  batch   27: loss=1.112\n",
      "  batch   28: loss=1.183\n",
      "  batch   29: loss=1.087\n",
      "  batch   30: loss=1.241\n",
      "  batch   31: loss=1.043\n",
      "  batch   32: loss=1.132\n",
      "  batch   33: loss=1.076\n",
      "  batch   34: loss=1.418\n",
      "  batch   35: loss=1.003\n",
      "  batch   36: loss=1.122\n",
      "  batch   37: loss=1.694\n",
      "  batch   38: loss=1.158\n",
      "  batch   39: loss=1.272\n",
      "  batch   40: loss=1.248\n",
      "  batch   41: loss=1.219\n",
      "  batch   42: loss=1.132\n",
      "  batch   43: loss=1.202\n",
      "  batch   44: loss=1.282\n",
      "  batch   45: loss=0.808\n",
      "  batch   46: loss=1.359\n",
      "  batch   47: loss=1.053\n",
      "  batch   48: loss=1.095\n",
      "  batch   49: loss=1.402\n",
      "  batch   50: loss=1.165\n",
      "  batch   51: loss=1.138\n",
      "  batch   52: loss=0.970\n",
      "  batch   53: loss=1.176\n",
      "  batch   54: loss=0.964\n",
      "  batch   55: loss=1.252\n",
      "  batch   56: loss=0.960\n",
      "  batch   57: loss=1.110\n",
      "  batch   58: loss=1.206\n",
      "  batch   59: loss=1.196\n",
      "  batch   60: loss=1.089\n",
      "  batch   61: loss=1.025\n",
      "  batch   62: loss=1.184\n",
      "  batch   63: loss=0.995\n",
      "  batch   64: loss=0.844\n",
      "  batch   65: loss=0.979\n",
      "  batch   66: loss=0.858\n",
      "  batch   67: loss=1.190\n",
      "  batch   68: loss=1.078\n",
      "  batch   69: loss=0.756\n",
      "  batch   70: loss=1.372\n",
      "  batch   71: loss=0.759\n",
      "  batch   72: loss=0.950\n",
      "  batch   73: loss=0.894\n",
      "  batch   74: loss=0.942\n",
      "  batch   75: loss=1.021\n",
      "  batch   76: loss=1.085\n",
      "  batch   77: loss=0.837\n",
      "  batch   78: loss=0.863\n",
      "  batch   79: loss=0.863\n",
      "  batch   80: loss=1.208\n",
      "  batch   81: loss=0.861\n",
      "  batch   82: loss=1.049\n",
      "Testing on validation set\n",
      "  acc=0.844\n",
      "Training epoch 2\n",
      "  batch    1: loss=0.815\n",
      "  batch    2: loss=0.808\n",
      "  batch    3: loss=1.037\n",
      "  batch    4: loss=0.747\n",
      "  batch    5: loss=1.129\n",
      "  batch    6: loss=1.208\n",
      "  batch    7: loss=0.903\n",
      "  batch    8: loss=0.624\n",
      "  batch    9: loss=0.892\n",
      "  batch   10: loss=1.059\n",
      "  batch   11: loss=1.004\n",
      "  batch   12: loss=0.621\n",
      "  batch   13: loss=0.754\n",
      "  batch   14: loss=0.625\n",
      "  batch   15: loss=1.104\n",
      "  batch   16: loss=0.943\n",
      "  batch   17: loss=0.939\n",
      "  batch   18: loss=0.946\n",
      "  batch   19: loss=0.819\n",
      "  batch   20: loss=0.878\n",
      "  batch   21: loss=0.880\n",
      "  batch   22: loss=0.741\n",
      "  batch   23: loss=0.812\n",
      "  batch   24: loss=0.867\n",
      "  batch   25: loss=0.657\n",
      "  batch   26: loss=1.019\n",
      "  batch   27: loss=0.732\n",
      "  batch   28: loss=0.871\n",
      "  batch   29: loss=0.724\n",
      "  batch   30: loss=0.917\n",
      "  batch   31: loss=0.820\n",
      "  batch   32: loss=0.728\n",
      "  batch   33: loss=0.808\n",
      "  batch   34: loss=0.676\n",
      "  batch   35: loss=0.758\n",
      "  batch   36: loss=0.740\n",
      "  batch   37: loss=0.645\n",
      "  batch   38: loss=0.563\n",
      "  batch   39: loss=0.713\n",
      "  batch   40: loss=0.828\n",
      "  batch   41: loss=1.064\n",
      "  batch   42: loss=0.949\n",
      "  batch   43: loss=1.007\n",
      "  batch   44: loss=0.509\n",
      "  batch   45: loss=0.792\n",
      "  batch   46: loss=0.635\n",
      "  batch   47: loss=0.778\n",
      "  batch   48: loss=0.829\n",
      "  batch   49: loss=0.756\n",
      "  batch   50: loss=0.659\n",
      "  batch   51: loss=1.190\n",
      "  batch   52: loss=0.901\n",
      "  batch   53: loss=0.937\n",
      "  batch   54: loss=0.679\n",
      "  batch   55: loss=0.801\n",
      "  batch   56: loss=0.960\n",
      "  batch   57: loss=0.988\n",
      "  batch   58: loss=0.667\n",
      "  batch   59: loss=0.877\n",
      "  batch   60: loss=0.845\n",
      "  batch   61: loss=0.544\n",
      "  batch   62: loss=0.975\n",
      "  batch   63: loss=0.625\n",
      "  batch   64: loss=0.638\n",
      "  batch   65: loss=0.692\n",
      "  batch   66: loss=0.648\n",
      "  batch   67: loss=0.720\n",
      "  batch   68: loss=0.940\n",
      "  batch   69: loss=0.625\n",
      "  batch   70: loss=0.963\n",
      "  batch   71: loss=0.971\n",
      "  batch   72: loss=0.524\n",
      "  batch   73: loss=0.664\n",
      "  batch   74: loss=0.894\n",
      "  batch   75: loss=0.664\n",
      "  batch   76: loss=0.804\n",
      "  batch   77: loss=0.700\n",
      "  batch   78: loss=0.625\n",
      "  batch   79: loss=0.714\n",
      "  batch   80: loss=0.781\n",
      "  batch   81: loss=0.647\n",
      "  batch   82: loss=0.570\n",
      "Testing on validation set\n",
      "  acc=0.877\n",
      "Training epoch 3\n",
      "  batch    1: loss=0.684\n",
      "  batch    2: loss=0.507\n",
      "  batch    3: loss=0.422\n",
      "  batch    4: loss=0.542\n",
      "  batch    5: loss=0.802\n",
      "  batch    6: loss=0.730\n",
      "  batch    7: loss=0.595\n",
      "  batch    8: loss=0.428\n",
      "  batch    9: loss=0.377\n",
      "  batch   10: loss=0.683\n",
      "  batch   11: loss=0.735\n",
      "  batch   12: loss=0.576\n",
      "  batch   13: loss=0.730\n",
      "  batch   14: loss=0.598\n",
      "  batch   15: loss=0.753\n",
      "  batch   16: loss=0.794\n",
      "  batch   17: loss=0.570\n",
      "  batch   18: loss=0.337\n",
      "  batch   19: loss=0.521\n",
      "  batch   20: loss=0.410\n",
      "  batch   21: loss=0.587\n",
      "  batch   22: loss=0.824\n",
      "  batch   23: loss=0.390\n",
      "  batch   24: loss=0.565\n",
      "  batch   25: loss=0.620\n",
      "  batch   26: loss=0.725\n",
      "  batch   27: loss=0.590\n",
      "  batch   28: loss=0.689\n",
      "  batch   29: loss=0.719\n",
      "  batch   30: loss=0.433\n",
      "  batch   31: loss=0.791\n",
      "  batch   32: loss=0.676\n",
      "  batch   33: loss=0.570\n",
      "  batch   34: loss=0.446\n",
      "  batch   35: loss=0.933\n",
      "  batch   36: loss=0.552\n",
      "  batch   37: loss=0.576\n",
      "  batch   38: loss=0.530\n",
      "  batch   39: loss=0.735\n",
      "  batch   40: loss=0.621\n",
      "  batch   41: loss=0.706\n",
      "  batch   42: loss=0.899\n",
      "  batch   43: loss=0.794\n",
      "  batch   44: loss=0.952\n",
      "  batch   45: loss=0.657\n",
      "  batch   46: loss=0.611\n",
      "  batch   47: loss=0.686\n",
      "  batch   48: loss=0.725\n",
      "  batch   49: loss=0.703\n",
      "  batch   50: loss=0.586\n",
      "  batch   51: loss=0.784\n",
      "  batch   52: loss=0.456\n",
      "  batch   53: loss=0.845\n",
      "  batch   54: loss=0.834\n",
      "  batch   55: loss=0.673\n",
      "  batch   56: loss=0.661\n",
      "  batch   57: loss=0.429\n",
      "  batch   58: loss=0.679\n",
      "  batch   59: loss=0.452\n",
      "  batch   60: loss=0.815\n",
      "  batch   61: loss=0.555\n",
      "  batch   62: loss=0.755\n",
      "  batch   63: loss=0.560\n",
      "  batch   64: loss=0.746\n",
      "  batch   65: loss=0.707\n",
      "  batch   66: loss=0.683\n",
      "  batch   67: loss=0.594\n",
      "  batch   68: loss=0.757\n",
      "  batch   69: loss=0.736\n",
      "  batch   70: loss=0.702\n",
      "  batch   71: loss=0.783\n",
      "  batch   72: loss=0.812\n",
      "  batch   73: loss=0.436\n",
      "  batch   74: loss=0.676\n",
      "  batch   75: loss=0.533\n",
      "  batch   76: loss=0.513\n",
      "  batch   77: loss=0.629\n",
      "  batch   78: loss=0.745\n",
      "  batch   79: loss=0.726\n",
      "  batch   80: loss=0.937\n",
      "  batch   81: loss=0.444\n",
      "  batch   82: loss=0.887\n",
      "Testing on validation set\n",
      "  acc=0.887\n",
      "Training epoch 4\n",
      "  batch    1: loss=0.592\n",
      "  batch    2: loss=0.575\n",
      "  batch    3: loss=0.603\n",
      "  batch    4: loss=0.545\n",
      "  batch    5: loss=0.522\n",
      "  batch    6: loss=0.618\n",
      "  batch    7: loss=0.760\n",
      "  batch    8: loss=0.672\n",
      "  batch    9: loss=0.378\n",
      "  batch   10: loss=0.730\n",
      "  batch   11: loss=0.554\n",
      "  batch   12: loss=0.583\n",
      "  batch   13: loss=0.661\n",
      "  batch   14: loss=0.390\n",
      "  batch   15: loss=0.455\n",
      "  batch   16: loss=0.596\n",
      "  batch   17: loss=0.668\n",
      "  batch   18: loss=0.594\n",
      "  batch   19: loss=0.669\n",
      "  batch   20: loss=0.438\n",
      "  batch   21: loss=0.694\n",
      "  batch   22: loss=0.311\n",
      "  batch   23: loss=0.808\n",
      "  batch   24: loss=0.261\n",
      "  batch   25: loss=0.490\n",
      "  batch   26: loss=0.660\n",
      "  batch   27: loss=0.551\n",
      "  batch   28: loss=0.500\n",
      "  batch   29: loss=0.465\n",
      "  batch   30: loss=0.699\n",
      "  batch   31: loss=0.425\n",
      "  batch   32: loss=0.687\n",
      "  batch   33: loss=0.394\n",
      "  batch   34: loss=0.810\n",
      "  batch   35: loss=0.675\n",
      "  batch   36: loss=0.548\n",
      "  batch   37: loss=0.859\n",
      "  batch   38: loss=0.568\n",
      "  batch   39: loss=0.613\n",
      "  batch   40: loss=0.388\n",
      "  batch   41: loss=0.486\n",
      "  batch   42: loss=0.671\n",
      "  batch   43: loss=0.501\n",
      "  batch   44: loss=0.385\n",
      "  batch   45: loss=0.508\n",
      "  batch   46: loss=0.607\n",
      "  batch   47: loss=0.529\n",
      "  batch   48: loss=0.487\n",
      "  batch   49: loss=0.403\n",
      "  batch   50: loss=0.721\n",
      "  batch   51: loss=0.530\n",
      "  batch   52: loss=0.381\n",
      "  batch   53: loss=0.456\n",
      "  batch   54: loss=0.572\n",
      "  batch   55: loss=0.700\n",
      "  batch   56: loss=0.401\n",
      "  batch   57: loss=0.659\n",
      "  batch   58: loss=0.455\n",
      "  batch   59: loss=0.594\n",
      "  batch   60: loss=0.487\n",
      "  batch   61: loss=0.528\n",
      "  batch   62: loss=0.501\n",
      "  batch   63: loss=0.378\n",
      "  batch   64: loss=0.611\n",
      "  batch   65: loss=0.681\n",
      "  batch   66: loss=0.427\n",
      "  batch   67: loss=0.556\n",
      "  batch   68: loss=0.640\n",
      "  batch   69: loss=0.747\n",
      "  batch   70: loss=0.605\n",
      "  batch   71: loss=0.326\n",
      "  batch   72: loss=0.342\n",
      "  batch   73: loss=0.518\n",
      "  batch   74: loss=0.491\n",
      "  batch   75: loss=0.550\n",
      "  batch   76: loss=0.537\n",
      "  batch   77: loss=0.476\n",
      "  batch   78: loss=0.420\n",
      "  batch   79: loss=0.514\n",
      "  batch   80: loss=0.766\n",
      "  batch   81: loss=0.590\n",
      "  batch   82: loss=0.306\n",
      "Testing on validation set\n",
      "  acc=0.897\n",
      "Training epoch 5\n",
      "  batch    1: loss=0.367\n",
      "  batch    2: loss=0.393\n",
      "  batch    3: loss=0.582\n",
      "  batch    4: loss=0.726\n",
      "  batch    5: loss=0.461\n",
      "  batch    6: loss=0.616\n",
      "  batch    7: loss=0.622\n",
      "  batch    8: loss=0.655\n",
      "  batch    9: loss=0.516\n",
      "  batch   10: loss=0.425\n",
      "  batch   11: loss=0.384\n",
      "  batch   12: loss=0.686\n",
      "  batch   13: loss=0.408\n",
      "  batch   14: loss=0.629\n",
      "  batch   15: loss=0.398\n",
      "  batch   16: loss=0.650\n",
      "  batch   17: loss=0.686\n",
      "  batch   18: loss=0.466\n",
      "  batch   19: loss=0.335\n",
      "  batch   20: loss=0.398\n",
      "  batch   21: loss=0.424\n",
      "  batch   22: loss=0.321\n",
      "  batch   23: loss=0.376\n",
      "  batch   24: loss=0.466\n",
      "  batch   25: loss=0.395\n",
      "  batch   26: loss=0.477\n",
      "  batch   27: loss=0.266\n",
      "  batch   28: loss=0.645\n",
      "  batch   29: loss=0.797\n",
      "  batch   30: loss=0.436\n",
      "  batch   31: loss=0.343\n",
      "  batch   32: loss=0.594\n",
      "  batch   33: loss=0.465\n",
      "  batch   34: loss=0.651\n",
      "  batch   35: loss=0.510\n",
      "  batch   36: loss=0.565\n",
      "  batch   37: loss=0.423\n",
      "  batch   38: loss=0.433\n",
      "  batch   39: loss=0.633\n",
      "  batch   40: loss=0.581\n",
      "  batch   41: loss=0.457\n",
      "  batch   42: loss=0.645\n",
      "  batch   43: loss=0.418\n",
      "  batch   44: loss=0.582\n",
      "  batch   45: loss=0.419\n",
      "  batch   46: loss=0.363\n",
      "  batch   47: loss=0.363\n",
      "  batch   48: loss=0.617\n",
      "  batch   49: loss=0.768\n",
      "  batch   50: loss=0.727\n",
      "  batch   51: loss=0.391\n",
      "  batch   52: loss=0.378\n",
      "  batch   53: loss=0.579\n",
      "  batch   54: loss=0.382\n",
      "  batch   55: loss=0.425\n",
      "  batch   56: loss=0.507\n",
      "  batch   57: loss=0.415\n",
      "  batch   58: loss=0.436\n",
      "  batch   59: loss=0.404\n",
      "  batch   60: loss=0.451\n",
      "  batch   61: loss=0.282\n",
      "  batch   62: loss=0.529\n",
      "  batch   63: loss=0.430\n",
      "  batch   64: loss=0.507\n",
      "  batch   65: loss=0.553\n",
      "  batch   66: loss=0.367\n",
      "  batch   67: loss=0.590\n",
      "  batch   68: loss=0.501\n",
      "  batch   69: loss=0.478\n",
      "  batch   70: loss=0.337\n",
      "  batch   71: loss=0.439\n",
      "  batch   72: loss=0.746\n",
      "  batch   73: loss=0.696\n",
      "  batch   74: loss=0.422\n",
      "  batch   75: loss=0.690\n",
      "  batch   76: loss=0.555\n",
      "  batch   77: loss=0.501\n",
      "  batch   78: loss=0.389\n",
      "  batch   79: loss=0.403\n",
      "  batch   80: loss=0.474\n",
      "  batch   81: loss=0.502\n",
      "  batch   82: loss=0.581\n",
      "Testing on validation set\n",
      "  acc=0.917\n",
      "Training epoch 6\n",
      "  batch    1: loss=0.533\n",
      "  batch    2: loss=0.466\n",
      "  batch    3: loss=0.204\n",
      "  batch    4: loss=0.489\n",
      "  batch    5: loss=0.467\n",
      "  batch    6: loss=0.544\n",
      "  batch    7: loss=0.608\n",
      "  batch    8: loss=0.486\n",
      "  batch    9: loss=0.483\n",
      "  batch   10: loss=0.481\n",
      "  batch   11: loss=0.393\n",
      "  batch   12: loss=0.347\n",
      "  batch   13: loss=0.511\n",
      "  batch   14: loss=0.404\n",
      "  batch   15: loss=0.557\n",
      "  batch   16: loss=0.557\n",
      "  batch   17: loss=0.458\n",
      "  batch   18: loss=0.439\n",
      "  batch   19: loss=0.232\n",
      "  batch   20: loss=0.367\n",
      "  batch   21: loss=0.511\n",
      "  batch   22: loss=0.614\n",
      "  batch   23: loss=0.414\n",
      "  batch   24: loss=0.479\n",
      "  batch   25: loss=0.500\n",
      "  batch   26: loss=0.403\n",
      "  batch   27: loss=0.432\n",
      "  batch   28: loss=0.452\n",
      "  batch   29: loss=0.404\n",
      "  batch   30: loss=0.858\n",
      "  batch   31: loss=0.446\n",
      "  batch   32: loss=0.328\n",
      "  batch   33: loss=0.272\n",
      "  batch   34: loss=0.245\n",
      "  batch   35: loss=0.464\n",
      "  batch   36: loss=0.355\n",
      "  batch   37: loss=0.442\n",
      "  batch   38: loss=0.304\n",
      "  batch   39: loss=0.384\n",
      "  batch   40: loss=0.350\n",
      "  batch   41: loss=0.445\n",
      "  batch   42: loss=0.392\n",
      "  batch   43: loss=0.512\n",
      "  batch   44: loss=0.330\n",
      "  batch   45: loss=0.580\n",
      "  batch   46: loss=0.544\n",
      "  batch   47: loss=0.581\n",
      "  batch   48: loss=0.384\n",
      "  batch   49: loss=0.329\n",
      "  batch   50: loss=0.400\n",
      "  batch   51: loss=0.487\n",
      "  batch   52: loss=0.446\n",
      "  batch   53: loss=0.425\n",
      "  batch   54: loss=0.501\n",
      "  batch   55: loss=0.505\n",
      "  batch   56: loss=0.269\n",
      "  batch   57: loss=0.426\n",
      "  batch   58: loss=0.490\n",
      "  batch   59: loss=0.433\n",
      "  batch   60: loss=0.542\n",
      "  batch   61: loss=0.488\n",
      "  batch   62: loss=0.262\n",
      "  batch   63: loss=0.341\n",
      "  batch   64: loss=0.710\n",
      "  batch   65: loss=0.538\n",
      "  batch   66: loss=0.409\n",
      "  batch   67: loss=0.586\n",
      "  batch   68: loss=0.450\n",
      "  batch   69: loss=0.355\n",
      "  batch   70: loss=0.247\n",
      "  batch   71: loss=0.453\n",
      "  batch   72: loss=0.608\n",
      "  batch   73: loss=0.667\n",
      "  batch   74: loss=0.424\n",
      "  batch   75: loss=0.288\n",
      "  batch   76: loss=0.490\n",
      "  batch   77: loss=0.232\n",
      "  batch   78: loss=0.334\n",
      "  batch   79: loss=0.332\n",
      "  batch   80: loss=0.555\n",
      "  batch   81: loss=0.714\n",
      "  batch   82: loss=0.446\n",
      "Testing on validation set\n",
      "  acc=0.911\n",
      "Training epoch 7\n",
      "  batch    1: loss=0.465\n",
      "  batch    2: loss=0.760\n",
      "  batch    3: loss=0.309\n",
      "  batch    4: loss=0.296\n",
      "  batch    5: loss=0.393\n",
      "  batch    6: loss=0.671\n",
      "  batch    7: loss=0.378\n",
      "  batch    8: loss=0.543\n",
      "  batch    9: loss=0.498\n",
      "  batch   10: loss=0.271\n",
      "  batch   11: loss=0.630\n",
      "  batch   12: loss=0.402\n",
      "  batch   13: loss=0.409\n",
      "  batch   14: loss=0.209\n",
      "  batch   15: loss=0.659\n",
      "  batch   16: loss=0.335\n",
      "  batch   17: loss=0.526\n",
      "  batch   18: loss=0.384\n",
      "  batch   19: loss=0.269\n",
      "  batch   20: loss=0.378\n",
      "  batch   21: loss=0.520\n",
      "  batch   22: loss=0.693\n",
      "  batch   23: loss=0.528\n",
      "  batch   24: loss=0.273\n",
      "  batch   25: loss=0.387\n",
      "  batch   26: loss=0.354\n",
      "  batch   27: loss=0.455\n",
      "  batch   28: loss=0.447\n",
      "  batch   29: loss=0.407\n",
      "  batch   30: loss=0.583\n",
      "  batch   31: loss=0.313\n",
      "  batch   32: loss=0.498\n",
      "  batch   33: loss=0.484\n",
      "  batch   34: loss=0.623\n",
      "  batch   35: loss=0.432\n",
      "  batch   36: loss=0.172\n",
      "  batch   37: loss=0.441\n",
      "  batch   38: loss=0.399\n",
      "  batch   39: loss=0.748\n",
      "  batch   40: loss=0.380\n",
      "  batch   41: loss=0.280\n",
      "  batch   42: loss=0.437\n",
      "  batch   43: loss=0.434\n",
      "  batch   44: loss=0.352\n",
      "  batch   45: loss=0.386\n",
      "  batch   46: loss=0.494\n",
      "  batch   47: loss=0.438\n",
      "  batch   48: loss=0.393\n",
      "  batch   49: loss=0.259\n",
      "  batch   50: loss=0.487\n",
      "  batch   51: loss=0.480\n",
      "  batch   52: loss=0.308\n",
      "  batch   53: loss=0.409\n",
      "  batch   54: loss=0.405\n",
      "  batch   55: loss=0.455\n",
      "  batch   56: loss=0.302\n",
      "  batch   57: loss=0.368\n",
      "  batch   58: loss=0.550\n",
      "  batch   59: loss=0.496\n",
      "  batch   60: loss=0.299\n",
      "  batch   61: loss=0.272\n",
      "  batch   62: loss=0.324\n",
      "  batch   63: loss=0.303\n",
      "  batch   64: loss=0.492\n",
      "  batch   65: loss=0.536\n",
      "  batch   66: loss=0.428\n",
      "  batch   67: loss=0.410\n",
      "  batch   68: loss=0.246\n",
      "  batch   69: loss=0.469\n",
      "  batch   70: loss=0.258\n",
      "  batch   71: loss=0.557\n",
      "  batch   72: loss=0.676\n",
      "  batch   73: loss=0.595\n",
      "  batch   74: loss=0.376\n",
      "  batch   75: loss=0.309\n",
      "  batch   76: loss=0.559\n",
      "  batch   77: loss=0.300\n",
      "  batch   78: loss=0.440\n",
      "  batch   79: loss=0.398\n",
      "  batch   80: loss=0.446\n",
      "  batch   81: loss=0.465\n",
      "  batch   82: loss=1.442\n",
      "Testing on validation set\n",
      "  acc=0.918\n",
      "Training epoch 8\n",
      "  batch    1: loss=0.239\n",
      "  batch    2: loss=0.345\n",
      "  batch    3: loss=0.502\n",
      "  batch    4: loss=0.650\n",
      "  batch    5: loss=0.420\n",
      "  batch    6: loss=0.248\n",
      "  batch    7: loss=0.243\n",
      "  batch    8: loss=0.443\n",
      "  batch    9: loss=0.380\n",
      "  batch   10: loss=0.358\n",
      "  batch   11: loss=0.527\n",
      "  batch   12: loss=0.229\n",
      "  batch   13: loss=0.444\n",
      "  batch   14: loss=0.382\n",
      "  batch   15: loss=0.407\n",
      "  batch   16: loss=0.352\n",
      "  batch   17: loss=0.593\n",
      "  batch   18: loss=0.317\n",
      "  batch   19: loss=0.484\n",
      "  batch   20: loss=0.499\n",
      "  batch   21: loss=0.328\n",
      "  batch   22: loss=0.351\n",
      "  batch   23: loss=0.443\n",
      "  batch   24: loss=0.265\n",
      "  batch   25: loss=0.440\n",
      "  batch   26: loss=0.400\n",
      "  batch   27: loss=0.408\n",
      "  batch   28: loss=0.471\n",
      "  batch   29: loss=0.348\n",
      "  batch   30: loss=0.545\n",
      "  batch   31: loss=0.245\n",
      "  batch   32: loss=0.240\n",
      "  batch   33: loss=0.369\n",
      "  batch   34: loss=0.442\n",
      "  batch   35: loss=0.349\n",
      "  batch   36: loss=0.350\n",
      "  batch   37: loss=0.327\n",
      "  batch   38: loss=0.366\n",
      "  batch   39: loss=0.410\n",
      "  batch   40: loss=0.336\n",
      "  batch   41: loss=0.509\n",
      "  batch   42: loss=0.439\n",
      "  batch   43: loss=0.284\n",
      "  batch   44: loss=0.334\n",
      "  batch   45: loss=0.374\n",
      "  batch   46: loss=0.494\n",
      "  batch   47: loss=0.608\n",
      "  batch   48: loss=0.375\n",
      "  batch   49: loss=0.367\n",
      "  batch   50: loss=0.425\n",
      "  batch   51: loss=0.522\n",
      "  batch   52: loss=0.357\n",
      "  batch   53: loss=0.354\n",
      "  batch   54: loss=0.198\n",
      "  batch   55: loss=0.268\n",
      "  batch   56: loss=0.330\n",
      "  batch   57: loss=0.460\n",
      "  batch   58: loss=0.531\n",
      "  batch   59: loss=0.364\n",
      "  batch   60: loss=0.457\n",
      "  batch   61: loss=0.568\n",
      "  batch   62: loss=0.634\n",
      "  batch   63: loss=0.276\n",
      "  batch   64: loss=0.577\n",
      "  batch   65: loss=0.339\n",
      "  batch   66: loss=0.367\n",
      "  batch   67: loss=0.267\n",
      "  batch   68: loss=0.479\n",
      "  batch   69: loss=0.484\n",
      "  batch   70: loss=0.381\n",
      "  batch   71: loss=0.425\n",
      "  batch   72: loss=0.274\n",
      "  batch   73: loss=0.665\n",
      "  batch   74: loss=0.496\n",
      "  batch   75: loss=0.533\n",
      "  batch   76: loss=0.250\n",
      "  batch   77: loss=0.274\n",
      "  batch   78: loss=0.415\n",
      "  batch   79: loss=0.539\n",
      "  batch   80: loss=0.282\n",
      "  batch   81: loss=0.418\n",
      "  batch   82: loss=0.525\n",
      "Testing on validation set\n",
      "  acc=0.896\n",
      "Training epoch 9\n",
      "  batch    1: loss=0.505\n",
      "  batch    2: loss=0.426\n",
      "  batch    3: loss=0.214\n",
      "  batch    4: loss=0.450\n",
      "  batch    5: loss=0.338\n",
      "  batch    6: loss=0.344\n",
      "  batch    7: loss=0.435\n",
      "  batch    8: loss=0.287\n",
      "  batch    9: loss=0.327\n",
      "  batch   10: loss=0.399\n",
      "  batch   11: loss=0.354\n",
      "  batch   12: loss=0.225\n",
      "  batch   13: loss=0.254\n",
      "  batch   14: loss=0.113\n",
      "  batch   15: loss=0.362\n",
      "  batch   16: loss=0.476\n",
      "  batch   17: loss=0.314\n",
      "  batch   18: loss=0.384\n",
      "  batch   19: loss=0.577\n",
      "  batch   20: loss=0.397\n",
      "  batch   21: loss=0.336\n",
      "  batch   22: loss=0.418\n",
      "  batch   23: loss=0.272\n",
      "  batch   24: loss=0.291\n",
      "  batch   25: loss=0.387\n",
      "  batch   26: loss=0.269\n",
      "  batch   27: loss=0.334\n",
      "  batch   28: loss=0.351\n",
      "  batch   29: loss=0.381\n",
      "  batch   30: loss=0.267\n",
      "  batch   31: loss=0.286\n",
      "  batch   32: loss=0.329\n",
      "  batch   33: loss=0.381\n",
      "  batch   34: loss=0.271\n",
      "  batch   35: loss=0.336\n",
      "  batch   36: loss=0.298\n",
      "  batch   37: loss=0.465\n",
      "  batch   38: loss=0.287\n",
      "  batch   39: loss=0.316\n",
      "  batch   40: loss=0.557\n",
      "  batch   41: loss=0.461\n",
      "  batch   42: loss=0.544\n",
      "  batch   43: loss=0.546\n",
      "  batch   44: loss=0.366\n",
      "  batch   45: loss=0.493\n",
      "  batch   46: loss=0.371\n",
      "  batch   47: loss=0.495\n",
      "  batch   48: loss=0.231\n",
      "  batch   49: loss=0.198\n",
      "  batch   50: loss=0.253\n",
      "  batch   51: loss=0.221\n",
      "  batch   52: loss=0.351\n",
      "  batch   53: loss=0.326\n",
      "  batch   54: loss=0.310\n",
      "  batch   55: loss=0.532\n",
      "  batch   56: loss=0.155\n",
      "  batch   57: loss=0.421\n",
      "  batch   58: loss=0.301\n",
      "  batch   59: loss=0.254\n",
      "  batch   60: loss=0.403\n",
      "  batch   61: loss=0.703\n",
      "  batch   62: loss=0.344\n",
      "  batch   63: loss=0.445\n",
      "  batch   64: loss=0.497\n",
      "  batch   65: loss=0.276\n",
      "  batch   66: loss=0.297\n",
      "  batch   67: loss=0.231\n",
      "  batch   68: loss=0.304\n",
      "  batch   69: loss=0.330\n",
      "  batch   70: loss=0.369\n",
      "  batch   71: loss=0.254\n",
      "  batch   72: loss=0.296\n",
      "  batch   73: loss=0.161\n",
      "  batch   74: loss=0.413\n",
      "  batch   75: loss=0.503\n",
      "  batch   76: loss=0.392\n",
      "  batch   77: loss=0.455\n",
      "  batch   78: loss=0.425\n",
      "  batch   79: loss=0.409\n",
      "  batch   80: loss=0.529\n",
      "  batch   81: loss=0.517\n",
      "  batch   82: loss=0.318\n",
      "Testing on validation set\n",
      "  acc=0.925\n",
      "Training epoch 10\n",
      "  batch    1: loss=0.334\n",
      "  batch    2: loss=0.263\n",
      "  batch    3: loss=0.364\n",
      "  batch    4: loss=0.476\n",
      "  batch    5: loss=0.199\n",
      "  batch    6: loss=0.278\n",
      "  batch    7: loss=0.228\n",
      "  batch    8: loss=0.273\n",
      "  batch    9: loss=0.323\n",
      "  batch   10: loss=0.299\n",
      "  batch   11: loss=0.296\n",
      "  batch   12: loss=0.288\n",
      "  batch   13: loss=0.300\n",
      "  batch   14: loss=0.333\n",
      "  batch   15: loss=0.280\n",
      "  batch   16: loss=0.272\n",
      "  batch   17: loss=0.365\n",
      "  batch   18: loss=0.233\n",
      "  batch   19: loss=0.388\n",
      "  batch   20: loss=0.279\n",
      "  batch   21: loss=0.309\n",
      "  batch   22: loss=0.335\n",
      "  batch   23: loss=0.180\n",
      "  batch   24: loss=0.405\n",
      "  batch   25: loss=0.267\n",
      "  batch   26: loss=0.244\n",
      "  batch   27: loss=0.506\n",
      "  batch   28: loss=0.500\n",
      "  batch   29: loss=0.272\n",
      "  batch   30: loss=0.391\n",
      "  batch   31: loss=0.280\n",
      "  batch   32: loss=0.465\n",
      "  batch   33: loss=0.219\n",
      "  batch   34: loss=0.337\n",
      "  batch   35: loss=0.300\n",
      "  batch   36: loss=0.377\n",
      "  batch   37: loss=0.321\n",
      "  batch   38: loss=0.503\n",
      "  batch   39: loss=0.301\n",
      "  batch   40: loss=0.391\n",
      "  batch   41: loss=0.162\n",
      "  batch   42: loss=0.301\n",
      "  batch   43: loss=0.384\n",
      "  batch   44: loss=0.310\n",
      "  batch   45: loss=0.503\n",
      "  batch   46: loss=0.625\n",
      "  batch   47: loss=0.470\n",
      "  batch   48: loss=0.418\n",
      "  batch   49: loss=0.228\n",
      "  batch   50: loss=0.422\n",
      "  batch   51: loss=0.320\n",
      "  batch   52: loss=0.505\n",
      "  batch   53: loss=0.331\n",
      "  batch   54: loss=0.365\n",
      "  batch   55: loss=0.445\n",
      "  batch   56: loss=0.536\n",
      "  batch   57: loss=0.425\n",
      "  batch   58: loss=0.276\n",
      "  batch   59: loss=0.419\n",
      "  batch   60: loss=0.251\n",
      "  batch   61: loss=0.364\n",
      "  batch   62: loss=0.362\n",
      "  batch   63: loss=0.544\n",
      "  batch   64: loss=0.182\n",
      "  batch   65: loss=0.400\n",
      "  batch   66: loss=0.335\n",
      "  batch   67: loss=0.280\n",
      "  batch   68: loss=0.252\n",
      "  batch   69: loss=0.266\n",
      "  batch   70: loss=0.382\n",
      "  batch   71: loss=0.244\n",
      "  batch   72: loss=0.326\n",
      "  batch   73: loss=0.452\n",
      "  batch   74: loss=0.227\n",
      "  batch   75: loss=0.484\n",
      "  batch   76: loss=0.552\n",
      "  batch   77: loss=0.258\n",
      "  batch   78: loss=0.406\n",
      "  batch   79: loss=0.355\n",
      "  batch   80: loss=0.281\n",
      "  batch   81: loss=0.304\n",
      "  batch   82: loss=0.450\n",
      "Testing on validation set\n",
      "  acc=0.920\n",
      "Training epoch 11\n",
      "  batch    1: loss=0.292\n",
      "  batch    2: loss=0.225\n",
      "  batch    3: loss=0.353\n",
      "  batch    4: loss=0.375\n",
      "  batch    5: loss=0.481\n",
      "  batch    6: loss=0.275\n",
      "  batch    7: loss=0.341\n",
      "  batch    8: loss=0.198\n",
      "  batch    9: loss=0.481\n",
      "  batch   10: loss=0.249\n",
      "  batch   11: loss=0.507\n",
      "  batch   12: loss=0.222\n",
      "  batch   13: loss=0.242\n",
      "  batch   14: loss=0.342\n",
      "  batch   15: loss=0.456\n",
      "  batch   16: loss=0.632\n",
      "  batch   17: loss=0.419\n",
      "  batch   18: loss=0.228\n",
      "  batch   19: loss=0.192\n",
      "  batch   20: loss=0.379\n",
      "  batch   21: loss=0.596\n",
      "  batch   22: loss=0.217\n",
      "  batch   23: loss=0.145\n",
      "  batch   24: loss=0.293\n",
      "  batch   25: loss=0.287\n",
      "  batch   26: loss=0.340\n",
      "  batch   27: loss=0.223\n",
      "  batch   28: loss=0.461\n",
      "  batch   29: loss=0.411\n",
      "  batch   30: loss=0.388\n",
      "  batch   31: loss=0.402\n",
      "  batch   32: loss=0.333\n",
      "  batch   33: loss=0.378\n",
      "  batch   34: loss=0.316\n",
      "  batch   35: loss=0.359\n",
      "  batch   36: loss=0.182\n",
      "  batch   37: loss=0.219\n",
      "  batch   38: loss=0.232\n",
      "  batch   39: loss=0.224\n",
      "  batch   40: loss=0.550\n",
      "  batch   41: loss=0.438\n",
      "  batch   42: loss=0.415\n",
      "  batch   43: loss=0.374\n",
      "  batch   44: loss=0.445\n",
      "  batch   45: loss=0.331\n",
      "  batch   46: loss=0.198\n",
      "  batch   47: loss=0.352\n",
      "  batch   48: loss=0.365\n",
      "  batch   49: loss=0.222\n",
      "  batch   50: loss=0.283\n",
      "  batch   51: loss=0.313\n",
      "  batch   52: loss=0.323\n",
      "  batch   53: loss=0.422\n",
      "  batch   54: loss=0.428\n",
      "  batch   55: loss=0.604\n",
      "  batch   56: loss=0.165\n",
      "  batch   57: loss=0.447\n",
      "  batch   58: loss=0.294\n",
      "  batch   59: loss=0.300\n",
      "  batch   60: loss=0.410\n",
      "  batch   61: loss=0.370\n",
      "  batch   62: loss=0.326\n",
      "  batch   63: loss=0.650\n",
      "  batch   64: loss=0.491\n",
      "  batch   65: loss=0.423\n",
      "  batch   66: loss=0.334\n",
      "  batch   67: loss=0.212\n",
      "  batch   68: loss=0.471\n",
      "  batch   69: loss=0.249\n",
      "  batch   70: loss=0.254\n",
      "  batch   71: loss=0.374\n",
      "  batch   72: loss=0.379\n",
      "  batch   73: loss=0.355\n",
      "  batch   74: loss=0.239\n",
      "  batch   75: loss=0.511\n",
      "  batch   76: loss=0.686\n",
      "  batch   77: loss=0.241\n",
      "  batch   78: loss=0.432\n",
      "  batch   79: loss=0.331\n",
      "  batch   80: loss=0.393\n",
      "  batch   81: loss=0.269\n",
      "  batch   82: loss=0.445\n",
      "Testing on validation set\n",
      "  acc=0.911\n",
      "Training epoch 12\n",
      "  batch    1: loss=0.337\n",
      "  batch    2: loss=0.533\n",
      "  batch    3: loss=0.376\n",
      "  batch    4: loss=0.346\n",
      "  batch    5: loss=0.321\n",
      "  batch    6: loss=0.452\n",
      "  batch    7: loss=0.455\n",
      "  batch    8: loss=0.206\n",
      "  batch    9: loss=0.396\n",
      "  batch   10: loss=0.179\n",
      "  batch   11: loss=0.433\n",
      "  batch   12: loss=0.159\n",
      "  batch   13: loss=0.412\n",
      "  batch   14: loss=0.259\n",
      "  batch   15: loss=0.274\n",
      "  batch   16: loss=0.191\n",
      "  batch   17: loss=0.421\n",
      "  batch   18: loss=0.249\n",
      "  batch   19: loss=0.384\n",
      "  batch   20: loss=0.282\n",
      "  batch   21: loss=0.250\n",
      "  batch   22: loss=0.342\n",
      "  batch   23: loss=0.600\n",
      "  batch   24: loss=0.363\n",
      "  batch   25: loss=0.330\n",
      "  batch   26: loss=0.383\n",
      "  batch   27: loss=0.474\n",
      "  batch   28: loss=0.258\n",
      "  batch   29: loss=0.273\n",
      "  batch   30: loss=0.459\n",
      "  batch   31: loss=0.433\n",
      "  batch   32: loss=0.283\n",
      "  batch   33: loss=0.427\n",
      "  batch   34: loss=0.292\n",
      "  batch   35: loss=0.281\n",
      "  batch   36: loss=0.304\n",
      "  batch   37: loss=0.504\n",
      "  batch   38: loss=0.449\n",
      "  batch   39: loss=0.250\n",
      "  batch   40: loss=0.339\n",
      "  batch   41: loss=0.299\n",
      "  batch   42: loss=0.250\n",
      "  batch   43: loss=0.342\n",
      "  batch   44: loss=0.409\n",
      "  batch   45: loss=0.294\n",
      "  batch   46: loss=0.262\n",
      "  batch   47: loss=0.226\n",
      "  batch   48: loss=0.499\n",
      "  batch   49: loss=0.244\n",
      "  batch   50: loss=0.344\n",
      "  batch   51: loss=0.195\n",
      "  batch   52: loss=0.417\n",
      "  batch   53: loss=0.378\n",
      "  batch   54: loss=0.437\n",
      "  batch   55: loss=0.365\n",
      "  batch   56: loss=0.279\n",
      "  batch   57: loss=0.264\n",
      "  batch   58: loss=0.207\n",
      "  batch   59: loss=0.546\n",
      "  batch   60: loss=0.156\n",
      "  batch   61: loss=0.351\n",
      "  batch   62: loss=0.273\n",
      "  batch   63: loss=0.385\n",
      "  batch   64: loss=0.335\n",
      "  batch   65: loss=0.371\n",
      "  batch   66: loss=0.285\n",
      "  batch   67: loss=0.403\n",
      "  batch   68: loss=0.211\n",
      "  batch   69: loss=0.404\n",
      "  batch   70: loss=0.381\n",
      "  batch   71: loss=0.286\n",
      "  batch   72: loss=0.308\n",
      "  batch   73: loss=0.482\n",
      "  batch   74: loss=0.157\n",
      "  batch   75: loss=0.248\n",
      "  batch   76: loss=0.314\n",
      "  batch   77: loss=0.704\n",
      "  batch   78: loss=0.399\n",
      "  batch   79: loss=0.210\n",
      "  batch   80: loss=0.193\n",
      "  batch   81: loss=0.570\n",
      "  batch   82: loss=0.645\n",
      "Testing on validation set\n",
      "  acc=0.916\n",
      "Training epoch 13\n",
      "  batch    1: loss=0.122\n",
      "  batch    2: loss=0.162\n",
      "  batch    3: loss=0.365\n",
      "  batch    4: loss=0.336\n",
      "  batch    5: loss=0.352\n",
      "  batch    6: loss=0.227\n",
      "  batch    7: loss=0.369\n",
      "  batch    8: loss=0.442\n",
      "  batch    9: loss=0.337\n",
      "  batch   10: loss=0.253\n",
      "  batch   11: loss=0.314\n",
      "  batch   12: loss=0.237\n",
      "  batch   13: loss=0.395\n",
      "  batch   14: loss=0.410\n",
      "  batch   15: loss=0.361\n",
      "  batch   16: loss=0.319\n",
      "  batch   17: loss=0.132\n",
      "  batch   18: loss=0.332\n",
      "  batch   19: loss=0.272\n",
      "  batch   20: loss=0.307\n",
      "  batch   21: loss=0.331\n",
      "  batch   22: loss=0.274\n",
      "  batch   23: loss=0.206\n",
      "  batch   24: loss=0.328\n",
      "  batch   25: loss=0.319\n",
      "  batch   26: loss=0.319\n",
      "  batch   27: loss=0.280\n",
      "  batch   28: loss=0.275\n",
      "  batch   29: loss=0.414\n",
      "  batch   30: loss=0.214\n",
      "  batch   31: loss=0.328\n",
      "  batch   32: loss=0.365\n",
      "  batch   33: loss=0.200\n",
      "  batch   34: loss=0.173\n",
      "  batch   35: loss=0.342\n",
      "  batch   36: loss=0.410\n",
      "  batch   37: loss=0.504\n",
      "  batch   38: loss=0.291\n",
      "  batch   39: loss=0.236\n",
      "  batch   40: loss=0.293\n",
      "  batch   41: loss=0.325\n",
      "  batch   42: loss=0.322\n",
      "  batch   43: loss=0.302\n",
      "  batch   44: loss=0.391\n",
      "  batch   45: loss=0.223\n",
      "  batch   46: loss=0.237\n",
      "  batch   47: loss=0.253\n",
      "  batch   48: loss=0.211\n",
      "  batch   49: loss=0.410\n",
      "  batch   50: loss=0.155\n",
      "  batch   51: loss=0.311\n",
      "  batch   52: loss=0.270\n",
      "  batch   53: loss=0.310\n",
      "  batch   54: loss=0.403\n",
      "  batch   55: loss=0.390\n",
      "  batch   56: loss=0.346\n",
      "  batch   57: loss=0.181\n",
      "  batch   58: loss=0.331\n",
      "  batch   59: loss=0.180\n",
      "  batch   60: loss=0.384\n",
      "  batch   61: loss=0.374\n",
      "  batch   62: loss=0.432\n",
      "  batch   63: loss=0.227\n",
      "  batch   64: loss=0.251\n",
      "  batch   65: loss=0.463\n",
      "  batch   66: loss=0.280\n",
      "  batch   67: loss=0.241\n",
      "  batch   68: loss=0.406\n",
      "  batch   69: loss=0.240\n",
      "  batch   70: loss=0.414\n",
      "  batch   71: loss=0.431\n",
      "  batch   72: loss=0.263\n",
      "  batch   73: loss=0.423\n",
      "  batch   74: loss=0.442\n",
      "  batch   75: loss=0.351\n",
      "  batch   76: loss=0.258\n",
      "  batch   77: loss=0.366\n",
      "  batch   78: loss=0.284\n",
      "  batch   79: loss=0.198\n",
      "  batch   80: loss=0.100\n",
      "  batch   81: loss=0.277\n",
      "  batch   82: loss=1.000\n",
      "Testing on validation set\n",
      "  acc=0.921\n",
      "Training epoch 14\n",
      "  batch    1: loss=0.279\n",
      "  batch    2: loss=0.282\n",
      "  batch    3: loss=0.225\n",
      "  batch    4: loss=0.395\n",
      "  batch    5: loss=0.168\n",
      "  batch    6: loss=0.323\n",
      "  batch    7: loss=0.402\n",
      "  batch    8: loss=0.313\n",
      "  batch    9: loss=0.479\n",
      "  batch   10: loss=0.364\n",
      "  batch   11: loss=0.566\n",
      "  batch   12: loss=0.337\n",
      "  batch   13: loss=0.309\n",
      "  batch   14: loss=0.484\n",
      "  batch   15: loss=0.249\n",
      "  batch   16: loss=0.513\n",
      "  batch   17: loss=0.306\n",
      "  batch   18: loss=0.257\n",
      "  batch   19: loss=0.413\n",
      "  batch   20: loss=0.369\n",
      "  batch   21: loss=0.229\n",
      "  batch   22: loss=0.453\n",
      "  batch   23: loss=0.465\n",
      "  batch   24: loss=0.455\n",
      "  batch   25: loss=0.393\n",
      "  batch   26: loss=0.485\n",
      "  batch   27: loss=0.280\n",
      "  batch   28: loss=0.237\n",
      "  batch   29: loss=0.194\n",
      "  batch   30: loss=0.161\n",
      "  batch   31: loss=0.343\n",
      "  batch   32: loss=0.384\n",
      "  batch   33: loss=0.325\n",
      "  batch   34: loss=0.318\n",
      "  batch   35: loss=0.303\n",
      "  batch   36: loss=0.444\n",
      "  batch   37: loss=0.427\n",
      "  batch   38: loss=0.286\n",
      "  batch   39: loss=0.409\n",
      "  batch   40: loss=0.178\n",
      "  batch   41: loss=0.308\n",
      "  batch   42: loss=0.496\n",
      "  batch   43: loss=0.235\n",
      "  batch   44: loss=0.477\n",
      "  batch   45: loss=0.201\n",
      "  batch   46: loss=0.358\n",
      "  batch   47: loss=0.620\n",
      "  batch   48: loss=0.238\n",
      "  batch   49: loss=0.365\n",
      "  batch   50: loss=0.344\n",
      "  batch   51: loss=0.245\n",
      "  batch   52: loss=0.227\n",
      "  batch   53: loss=0.253\n",
      "  batch   54: loss=0.445\n",
      "  batch   55: loss=0.239\n",
      "  batch   56: loss=0.342\n",
      "  batch   57: loss=0.348\n",
      "  batch   58: loss=0.241\n",
      "  batch   59: loss=0.332\n",
      "  batch   60: loss=0.356\n",
      "  batch   61: loss=0.216\n",
      "  batch   62: loss=0.273\n",
      "  batch   63: loss=0.346\n",
      "  batch   64: loss=0.294\n",
      "  batch   65: loss=0.264\n",
      "  batch   66: loss=0.246\n",
      "  batch   67: loss=0.329\n",
      "  batch   68: loss=0.365\n",
      "  batch   69: loss=0.339\n",
      "  batch   70: loss=0.175\n",
      "  batch   71: loss=0.256\n",
      "  batch   72: loss=0.485\n",
      "  batch   73: loss=0.263\n",
      "  batch   74: loss=0.528\n",
      "  batch   75: loss=0.258\n",
      "  batch   76: loss=0.299\n",
      "  batch   77: loss=0.338\n",
      "  batch   78: loss=0.312\n",
      "  batch   79: loss=0.505\n",
      "  batch   80: loss=0.323\n",
      "  batch   81: loss=0.402\n",
      "  batch   82: loss=0.385\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 15\n",
      "  batch    1: loss=0.236\n",
      "  batch    2: loss=0.269\n",
      "  batch    3: loss=0.282\n",
      "  batch    4: loss=0.589\n",
      "  batch    5: loss=0.265\n",
      "  batch    6: loss=0.516\n",
      "  batch    7: loss=0.263\n",
      "  batch    8: loss=0.109\n",
      "  batch    9: loss=0.222\n",
      "  batch   10: loss=0.216\n",
      "  batch   11: loss=0.142\n",
      "  batch   12: loss=0.342\n",
      "  batch   13: loss=0.260\n",
      "  batch   14: loss=0.409\n",
      "  batch   15: loss=0.129\n",
      "  batch   16: loss=0.188\n",
      "  batch   17: loss=0.286\n",
      "  batch   18: loss=0.296\n",
      "  batch   19: loss=0.222\n",
      "  batch   20: loss=0.270\n",
      "  batch   21: loss=0.473\n",
      "  batch   22: loss=0.198\n",
      "  batch   23: loss=0.341\n",
      "  batch   24: loss=0.446\n",
      "  batch   25: loss=0.313\n",
      "  batch   26: loss=0.230\n",
      "  batch   27: loss=0.208\n",
      "  batch   28: loss=0.370\n",
      "  batch   29: loss=0.374\n",
      "  batch   30: loss=0.138\n",
      "  batch   31: loss=0.248\n",
      "  batch   32: loss=0.330\n",
      "  batch   33: loss=0.254\n",
      "  batch   34: loss=0.262\n",
      "  batch   35: loss=0.266\n",
      "  batch   36: loss=0.445\n",
      "  batch   37: loss=0.523\n",
      "  batch   38: loss=0.161\n",
      "  batch   39: loss=0.163\n",
      "  batch   40: loss=0.383\n",
      "  batch   41: loss=0.481\n",
      "  batch   42: loss=0.292\n",
      "  batch   43: loss=0.326\n",
      "  batch   44: loss=0.330\n",
      "  batch   45: loss=0.262\n",
      "  batch   46: loss=0.614\n",
      "  batch   47: loss=0.161\n",
      "  batch   48: loss=0.484\n",
      "  batch   49: loss=0.331\n",
      "  batch   50: loss=0.312\n",
      "  batch   51: loss=0.277\n",
      "  batch   52: loss=0.463\n",
      "  batch   53: loss=0.410\n",
      "  batch   54: loss=0.294\n",
      "  batch   55: loss=0.500\n",
      "  batch   56: loss=0.534\n",
      "  batch   57: loss=0.200\n",
      "  batch   58: loss=0.392\n",
      "  batch   59: loss=0.208\n",
      "  batch   60: loss=0.398\n",
      "  batch   61: loss=0.308\n",
      "  batch   62: loss=0.330\n",
      "  batch   63: loss=0.323\n",
      "  batch   64: loss=0.277\n",
      "  batch   65: loss=0.151\n",
      "  batch   66: loss=0.299\n",
      "  batch   67: loss=0.331\n",
      "  batch   68: loss=0.223\n",
      "  batch   69: loss=0.214\n",
      "  batch   70: loss=0.279\n",
      "  batch   71: loss=0.266\n",
      "  batch   72: loss=0.175\n",
      "  batch   73: loss=0.283\n",
      "  batch   74: loss=0.379\n",
      "  batch   75: loss=0.234\n",
      "  batch   76: loss=0.423\n",
      "  batch   77: loss=0.433\n",
      "  batch   78: loss=0.242\n",
      "  batch   79: loss=0.320\n",
      "  batch   80: loss=0.340\n",
      "  batch   81: loss=0.382\n",
      "  batch   82: loss=0.318\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 16\n",
      "  batch    1: loss=0.224\n",
      "  batch    2: loss=0.544\n",
      "  batch    3: loss=0.245\n",
      "  batch    4: loss=0.190\n",
      "  batch    5: loss=0.283\n",
      "  batch    6: loss=0.154\n",
      "  batch    7: loss=0.480\n",
      "  batch    8: loss=0.250\n",
      "  batch    9: loss=0.355\n",
      "  batch   10: loss=0.379\n",
      "  batch   11: loss=0.589\n",
      "  batch   12: loss=0.210\n",
      "  batch   13: loss=0.211\n",
      "  batch   14: loss=0.132\n",
      "  batch   15: loss=0.255\n",
      "  batch   16: loss=0.389\n",
      "  batch   17: loss=0.269\n",
      "  batch   18: loss=0.312\n",
      "  batch   19: loss=0.088\n",
      "  batch   20: loss=0.202\n",
      "  batch   21: loss=0.274\n",
      "  batch   22: loss=0.203\n",
      "  batch   23: loss=0.181\n",
      "  batch   24: loss=0.213\n",
      "  batch   25: loss=0.328\n",
      "  batch   26: loss=0.244\n",
      "  batch   27: loss=0.190\n",
      "  batch   28: loss=0.170\n",
      "  batch   29: loss=0.184\n",
      "  batch   30: loss=0.337\n",
      "  batch   31: loss=0.460\n",
      "  batch   32: loss=0.296\n",
      "  batch   33: loss=0.318\n",
      "  batch   34: loss=0.255\n",
      "  batch   35: loss=0.160\n",
      "  batch   36: loss=0.373\n",
      "  batch   37: loss=0.137\n",
      "  batch   38: loss=0.413\n",
      "  batch   39: loss=0.281\n",
      "  batch   40: loss=0.365\n",
      "  batch   41: loss=0.303\n",
      "  batch   42: loss=0.207\n",
      "  batch   43: loss=0.213\n",
      "  batch   44: loss=0.384\n",
      "  batch   45: loss=0.187\n",
      "  batch   46: loss=0.464\n",
      "  batch   47: loss=0.355\n",
      "  batch   48: loss=0.190\n",
      "  batch   49: loss=0.312\n",
      "  batch   50: loss=0.278\n",
      "  batch   51: loss=0.180\n",
      "  batch   52: loss=0.430\n",
      "  batch   53: loss=0.574\n",
      "  batch   54: loss=0.255\n",
      "  batch   55: loss=0.254\n",
      "  batch   56: loss=0.292\n",
      "  batch   57: loss=0.342\n",
      "  batch   58: loss=0.190\n",
      "  batch   59: loss=0.202\n",
      "  batch   60: loss=0.474\n",
      "  batch   61: loss=0.459\n",
      "  batch   62: loss=0.115\n",
      "  batch   63: loss=0.141\n",
      "  batch   64: loss=0.375\n",
      "  batch   65: loss=0.157\n",
      "  batch   66: loss=0.654\n",
      "  batch   67: loss=0.243\n",
      "  batch   68: loss=0.360\n",
      "  batch   69: loss=0.236\n",
      "  batch   70: loss=0.350\n",
      "  batch   71: loss=0.310\n",
      "  batch   72: loss=0.202\n",
      "  batch   73: loss=0.252\n",
      "  batch   74: loss=0.350\n",
      "  batch   75: loss=0.159\n",
      "  batch   76: loss=0.255\n",
      "  batch   77: loss=0.241\n",
      "  batch   78: loss=0.239\n",
      "  batch   79: loss=0.299\n",
      "  batch   80: loss=0.264\n",
      "  batch   81: loss=0.358\n",
      "  batch   82: loss=0.239\n",
      "Testing on validation set\n",
      "  acc=0.924\n",
      "Training epoch 17\n",
      "  batch    1: loss=0.288\n",
      "  batch    2: loss=0.391\n",
      "  batch    3: loss=0.266\n",
      "  batch    4: loss=0.354\n",
      "  batch    5: loss=0.252\n",
      "  batch    6: loss=0.108\n",
      "  batch    7: loss=0.319\n",
      "  batch    8: loss=0.191\n",
      "  batch    9: loss=0.357\n",
      "  batch   10: loss=0.237\n",
      "  batch   11: loss=0.325\n",
      "  batch   12: loss=0.337\n",
      "  batch   13: loss=0.277\n",
      "  batch   14: loss=0.273\n",
      "  batch   15: loss=0.209\n",
      "  batch   16: loss=0.316\n",
      "  batch   17: loss=0.274\n",
      "  batch   18: loss=0.348\n",
      "  batch   19: loss=0.229\n",
      "  batch   20: loss=0.285\n",
      "  batch   21: loss=0.231\n",
      "  batch   22: loss=0.242\n",
      "  batch   23: loss=0.349\n",
      "  batch   24: loss=0.227\n",
      "  batch   25: loss=0.322\n",
      "  batch   26: loss=0.180\n",
      "  batch   27: loss=0.442\n",
      "  batch   28: loss=0.250\n",
      "  batch   29: loss=0.228\n",
      "  batch   30: loss=0.200\n",
      "  batch   31: loss=0.252\n",
      "  batch   32: loss=0.457\n",
      "  batch   33: loss=0.375\n",
      "  batch   34: loss=0.289\n",
      "  batch   35: loss=0.543\n",
      "  batch   36: loss=0.241\n",
      "  batch   37: loss=0.262\n",
      "  batch   38: loss=0.293\n",
      "  batch   39: loss=0.283\n",
      "  batch   40: loss=0.268\n",
      "  batch   41: loss=0.380\n",
      "  batch   42: loss=0.277\n",
      "  batch   43: loss=0.545\n",
      "  batch   44: loss=0.257\n",
      "  batch   45: loss=0.403\n",
      "  batch   46: loss=0.396\n",
      "  batch   47: loss=0.397\n",
      "  batch   48: loss=0.350\n",
      "  batch   49: loss=0.274\n",
      "  batch   50: loss=0.139\n",
      "  batch   51: loss=0.286\n",
      "  batch   52: loss=0.244\n",
      "  batch   53: loss=0.370\n",
      "  batch   54: loss=0.200\n",
      "  batch   55: loss=0.595\n",
      "  batch   56: loss=0.253\n",
      "  batch   57: loss=0.256\n",
      "  batch   58: loss=0.278\n",
      "  batch   59: loss=0.328\n",
      "  batch   60: loss=0.171\n",
      "  batch   61: loss=0.333\n",
      "  batch   62: loss=0.486\n",
      "  batch   63: loss=0.332\n",
      "  batch   64: loss=0.286\n",
      "  batch   65: loss=0.257\n",
      "  batch   66: loss=0.365\n",
      "  batch   67: loss=0.330\n",
      "  batch   68: loss=0.318\n",
      "  batch   69: loss=0.283\n",
      "  batch   70: loss=0.248\n",
      "  batch   71: loss=0.347\n",
      "  batch   72: loss=0.235\n",
      "  batch   73: loss=0.406\n",
      "  batch   74: loss=0.382\n",
      "  batch   75: loss=0.238\n",
      "  batch   76: loss=0.320\n",
      "  batch   77: loss=0.123\n",
      "  batch   78: loss=0.242\n",
      "  batch   79: loss=0.305\n",
      "  batch   80: loss=0.234\n",
      "  batch   81: loss=0.352\n",
      "  batch   82: loss=0.322\n",
      "Testing on validation set\n",
      "  acc=0.907\n",
      "Training epoch 18\n",
      "  batch    1: loss=0.203\n",
      "  batch    2: loss=0.403\n",
      "  batch    3: loss=0.352\n",
      "  batch    4: loss=0.277\n",
      "  batch    5: loss=0.292\n",
      "  batch    6: loss=0.259\n",
      "  batch    7: loss=0.293\n",
      "  batch    8: loss=0.290\n",
      "  batch    9: loss=0.119\n",
      "  batch   10: loss=0.128\n",
      "  batch   11: loss=0.323\n",
      "  batch   12: loss=0.203\n",
      "  batch   13: loss=0.111\n",
      "  batch   14: loss=0.331\n",
      "  batch   15: loss=0.429\n",
      "  batch   16: loss=0.131\n",
      "  batch   17: loss=0.187\n",
      "  batch   18: loss=0.153\n",
      "  batch   19: loss=0.303\n",
      "  batch   20: loss=0.465\n",
      "  batch   21: loss=0.317\n",
      "  batch   22: loss=0.423\n",
      "  batch   23: loss=0.312\n",
      "  batch   24: loss=0.165\n",
      "  batch   25: loss=0.117\n",
      "  batch   26: loss=0.433\n",
      "  batch   27: loss=0.298\n",
      "  batch   28: loss=0.627\n",
      "  batch   29: loss=0.196\n",
      "  batch   30: loss=0.106\n",
      "  batch   31: loss=0.225\n",
      "  batch   32: loss=0.504\n",
      "  batch   33: loss=0.430\n",
      "  batch   34: loss=0.256\n",
      "  batch   35: loss=0.302\n",
      "  batch   36: loss=0.293\n",
      "  batch   37: loss=0.325\n",
      "  batch   38: loss=0.329\n",
      "  batch   39: loss=0.277\n",
      "  batch   40: loss=0.300\n",
      "  batch   41: loss=0.411\n",
      "  batch   42: loss=0.404\n",
      "  batch   43: loss=0.175\n",
      "  batch   44: loss=0.528\n",
      "  batch   45: loss=0.242\n",
      "  batch   46: loss=0.454\n",
      "  batch   47: loss=0.219\n",
      "  batch   48: loss=0.136\n",
      "  batch   49: loss=0.312\n",
      "  batch   50: loss=0.329\n",
      "  batch   51: loss=0.224\n",
      "  batch   52: loss=0.210\n",
      "  batch   53: loss=0.275\n",
      "  batch   54: loss=0.340\n",
      "  batch   55: loss=0.135\n",
      "  batch   56: loss=0.188\n",
      "  batch   57: loss=0.145\n",
      "  batch   58: loss=0.457\n",
      "  batch   59: loss=0.458\n",
      "  batch   60: loss=0.138\n",
      "  batch   61: loss=0.317\n",
      "  batch   62: loss=0.229\n",
      "  batch   63: loss=0.372\n",
      "  batch   64: loss=0.363\n",
      "  batch   65: loss=0.342\n",
      "  batch   66: loss=0.206\n",
      "  batch   67: loss=0.209\n",
      "  batch   68: loss=0.193\n",
      "  batch   69: loss=0.228\n",
      "  batch   70: loss=0.439\n",
      "  batch   71: loss=0.221\n",
      "  batch   72: loss=0.169\n",
      "  batch   73: loss=0.345\n",
      "  batch   74: loss=0.260\n",
      "  batch   75: loss=0.389\n",
      "  batch   76: loss=0.165\n",
      "  batch   77: loss=0.284\n",
      "  batch   78: loss=0.305\n",
      "  batch   79: loss=0.211\n",
      "  batch   80: loss=0.188\n",
      "  batch   81: loss=0.370\n",
      "  batch   82: loss=0.517\n",
      "Testing on validation set\n",
      "  acc=0.918\n",
      "Training epoch 19\n",
      "  batch    1: loss=0.121\n",
      "  batch    2: loss=0.356\n",
      "  batch    3: loss=0.201\n",
      "  batch    4: loss=0.245\n",
      "  batch    5: loss=0.463\n",
      "  batch    6: loss=0.348\n",
      "  batch    7: loss=0.178\n",
      "  batch    8: loss=0.251\n",
      "  batch    9: loss=0.176\n",
      "  batch   10: loss=0.317\n",
      "  batch   11: loss=0.407\n",
      "  batch   12: loss=0.586\n",
      "  batch   13: loss=0.142\n",
      "  batch   14: loss=0.474\n",
      "  batch   15: loss=0.278\n",
      "  batch   16: loss=0.139\n",
      "  batch   17: loss=0.485\n",
      "  batch   18: loss=0.321\n",
      "  batch   19: loss=0.599\n",
      "  batch   20: loss=0.294\n",
      "  batch   21: loss=0.304\n",
      "  batch   22: loss=0.082\n",
      "  batch   23: loss=0.189\n",
      "  batch   24: loss=0.244\n",
      "  batch   25: loss=0.526\n",
      "  batch   26: loss=0.282\n",
      "  batch   27: loss=0.282\n",
      "  batch   28: loss=0.274\n",
      "  batch   29: loss=0.206\n",
      "  batch   30: loss=0.302\n",
      "  batch   31: loss=0.197\n",
      "  batch   32: loss=0.183\n",
      "  batch   33: loss=0.264\n",
      "  batch   34: loss=0.441\n",
      "  batch   35: loss=0.291\n",
      "  batch   36: loss=0.229\n",
      "  batch   37: loss=0.522\n",
      "  batch   38: loss=0.333\n",
      "  batch   39: loss=0.195\n",
      "  batch   40: loss=0.396\n",
      "  batch   41: loss=0.400\n",
      "  batch   42: loss=0.227\n",
      "  batch   43: loss=0.233\n",
      "  batch   44: loss=0.146\n",
      "  batch   45: loss=0.334\n",
      "  batch   46: loss=0.402\n",
      "  batch   47: loss=0.233\n",
      "  batch   48: loss=0.468\n",
      "  batch   49: loss=0.265\n",
      "  batch   50: loss=0.263\n",
      "  batch   51: loss=0.387\n",
      "  batch   52: loss=0.167\n",
      "  batch   53: loss=0.212\n",
      "  batch   54: loss=0.473\n",
      "  batch   55: loss=0.389\n",
      "  batch   56: loss=0.268\n",
      "  batch   57: loss=0.251\n",
      "  batch   58: loss=0.393\n",
      "  batch   59: loss=0.247\n",
      "  batch   60: loss=0.443\n",
      "  batch   61: loss=0.262\n",
      "  batch   62: loss=0.246\n",
      "  batch   63: loss=0.355\n",
      "  batch   64: loss=0.191\n",
      "  batch   65: loss=0.366\n",
      "  batch   66: loss=0.372\n",
      "  batch   67: loss=0.342\n",
      "  batch   68: loss=0.252\n",
      "  batch   69: loss=0.168\n",
      "  batch   70: loss=0.185\n",
      "  batch   71: loss=0.207\n",
      "  batch   72: loss=0.269\n",
      "  batch   73: loss=0.269\n",
      "  batch   74: loss=0.133\n",
      "  batch   75: loss=0.346\n",
      "  batch   76: loss=0.591\n",
      "  batch   77: loss=0.202\n",
      "  batch   78: loss=0.261\n",
      "  batch   79: loss=0.253\n",
      "  batch   80: loss=0.356\n",
      "  batch   81: loss=0.293\n",
      "  batch   82: loss=0.119\n",
      "Testing on validation set\n",
      "  acc=0.911\n",
      "Training epoch 20\n",
      "  batch    1: loss=0.103\n",
      "  batch    2: loss=0.424\n",
      "  batch    3: loss=0.349\n",
      "  batch    4: loss=0.164\n",
      "  batch    5: loss=0.272\n",
      "  batch    6: loss=0.170\n",
      "  batch    7: loss=0.335\n",
      "  batch    8: loss=0.201\n",
      "  batch    9: loss=0.136\n",
      "  batch   10: loss=0.094\n",
      "  batch   11: loss=0.299\n",
      "  batch   12: loss=0.169\n",
      "  batch   13: loss=0.384\n",
      "  batch   14: loss=0.359\n",
      "  batch   15: loss=0.544\n",
      "  batch   16: loss=0.295\n",
      "  batch   17: loss=0.306\n",
      "  batch   18: loss=0.394\n",
      "  batch   19: loss=0.403\n",
      "  batch   20: loss=0.267\n",
      "  batch   21: loss=0.131\n",
      "  batch   22: loss=0.195\n",
      "  batch   23: loss=0.546\n",
      "  batch   24: loss=0.244\n",
      "  batch   25: loss=0.379\n",
      "  batch   26: loss=0.380\n",
      "  batch   27: loss=0.273\n",
      "  batch   28: loss=0.363\n",
      "  batch   29: loss=0.154\n",
      "  batch   30: loss=0.526\n",
      "  batch   31: loss=0.390\n",
      "  batch   32: loss=0.171\n",
      "  batch   33: loss=0.222\n",
      "  batch   34: loss=0.290\n",
      "  batch   35: loss=0.399\n",
      "  batch   36: loss=0.179\n",
      "  batch   37: loss=0.205\n",
      "  batch   38: loss=0.160\n",
      "  batch   39: loss=0.334\n",
      "  batch   40: loss=0.273\n",
      "  batch   41: loss=0.204\n",
      "  batch   42: loss=0.153\n",
      "  batch   43: loss=0.183\n",
      "  batch   44: loss=0.324\n",
      "  batch   45: loss=0.594\n",
      "  batch   46: loss=0.293\n",
      "  batch   47: loss=0.135\n",
      "  batch   48: loss=0.155\n",
      "  batch   49: loss=0.179\n",
      "  batch   50: loss=0.421\n",
      "  batch   51: loss=0.351\n",
      "  batch   52: loss=0.220\n",
      "  batch   53: loss=0.145\n",
      "  batch   54: loss=0.331\n",
      "  batch   55: loss=0.323\n",
      "  batch   56: loss=0.303\n",
      "  batch   57: loss=0.310\n",
      "  batch   58: loss=0.255\n",
      "  batch   59: loss=0.106\n",
      "  batch   60: loss=0.295\n",
      "  batch   61: loss=0.202\n",
      "  batch   62: loss=0.246\n",
      "  batch   63: loss=0.313\n",
      "  batch   64: loss=0.333\n",
      "  batch   65: loss=0.218\n",
      "  batch   66: loss=0.345\n",
      "  batch   67: loss=0.151\n",
      "  batch   68: loss=0.265\n",
      "  batch   69: loss=0.311\n",
      "  batch   70: loss=0.302\n",
      "  batch   71: loss=0.223\n",
      "  batch   72: loss=0.476\n",
      "  batch   73: loss=0.186\n",
      "  batch   74: loss=0.182\n",
      "  batch   75: loss=0.366\n",
      "  batch   76: loss=0.238\n",
      "  batch   77: loss=0.229\n",
      "  batch   78: loss=0.226\n",
      "  batch   79: loss=0.290\n",
      "  batch   80: loss=0.227\n",
      "  batch   81: loss=0.254\n",
      "  batch   82: loss=0.078\n",
      "Testing on validation set\n",
      "  acc=0.906\n",
      "Training epoch 21\n",
      "  batch    1: loss=0.166\n",
      "  batch    2: loss=0.226\n",
      "  batch    3: loss=0.133\n",
      "  batch    4: loss=0.260\n",
      "  batch    5: loss=0.407\n",
      "  batch    6: loss=0.199\n",
      "  batch    7: loss=0.229\n",
      "  batch    8: loss=0.219\n",
      "  batch    9: loss=0.387\n",
      "  batch   10: loss=0.444\n",
      "  batch   11: loss=0.232\n",
      "  batch   12: loss=0.276\n",
      "  batch   13: loss=0.174\n",
      "  batch   14: loss=0.174\n",
      "  batch   15: loss=0.134\n",
      "  batch   16: loss=0.267\n",
      "  batch   17: loss=0.118\n",
      "  batch   18: loss=0.121\n",
      "  batch   19: loss=0.280\n",
      "  batch   20: loss=0.184\n",
      "  batch   21: loss=0.143\n",
      "  batch   22: loss=0.502\n",
      "  batch   23: loss=0.187\n",
      "  batch   24: loss=0.205\n",
      "  batch   25: loss=0.219\n",
      "  batch   26: loss=0.335\n",
      "  batch   27: loss=0.117\n",
      "  batch   28: loss=0.357\n",
      "  batch   29: loss=0.304\n",
      "  batch   30: loss=0.421\n",
      "  batch   31: loss=0.244\n",
      "  batch   32: loss=0.150\n",
      "  batch   33: loss=0.454\n",
      "  batch   34: loss=0.258\n",
      "  batch   35: loss=0.266\n",
      "  batch   36: loss=0.316\n",
      "  batch   37: loss=0.293\n",
      "  batch   38: loss=0.181\n",
      "  batch   39: loss=0.274\n",
      "  batch   40: loss=0.329\n",
      "  batch   41: loss=0.076\n",
      "  batch   42: loss=0.189\n",
      "  batch   43: loss=0.440\n",
      "  batch   44: loss=0.328\n",
      "  batch   45: loss=0.423\n",
      "  batch   46: loss=0.208\n",
      "  batch   47: loss=0.153\n",
      "  batch   48: loss=0.405\n",
      "  batch   49: loss=0.197\n",
      "  batch   50: loss=0.261\n",
      "  batch   51: loss=0.236\n",
      "  batch   52: loss=0.226\n",
      "  batch   53: loss=0.129\n",
      "  batch   54: loss=0.167\n",
      "  batch   55: loss=0.230\n",
      "  batch   56: loss=0.129\n",
      "  batch   57: loss=0.425\n",
      "  batch   58: loss=0.419\n",
      "  batch   59: loss=0.347\n",
      "  batch   60: loss=0.123\n",
      "  batch   61: loss=0.257\n",
      "  batch   62: loss=0.218\n",
      "  batch   63: loss=0.211\n",
      "  batch   64: loss=0.339\n",
      "  batch   65: loss=0.466\n",
      "  batch   66: loss=0.424\n",
      "  batch   67: loss=0.288\n",
      "  batch   68: loss=0.343\n",
      "  batch   69: loss=0.377\n",
      "  batch   70: loss=0.202\n",
      "  batch   71: loss=0.202\n",
      "  batch   72: loss=0.253\n",
      "  batch   73: loss=0.328\n",
      "  batch   74: loss=0.221\n",
      "  batch   75: loss=0.213\n",
      "  batch   76: loss=0.457\n",
      "  batch   77: loss=0.237\n",
      "  batch   78: loss=0.396\n",
      "  batch   79: loss=0.206\n",
      "  batch   80: loss=0.356\n",
      "  batch   81: loss=0.268\n",
      "  batch   82: loss=0.146\n",
      "Testing on validation set\n",
      "  acc=0.909\n",
      "Training epoch 22\n",
      "  batch    1: loss=0.101\n",
      "  batch    2: loss=0.130\n",
      "  batch    3: loss=0.162\n",
      "  batch    4: loss=0.316\n",
      "  batch    5: loss=0.063\n",
      "  batch    6: loss=0.300\n",
      "  batch    7: loss=0.161\n",
      "  batch    8: loss=0.108\n",
      "  batch    9: loss=0.142\n",
      "  batch   10: loss=0.184\n",
      "  batch   11: loss=0.297\n",
      "  batch   12: loss=0.526\n",
      "  batch   13: loss=0.273\n",
      "  batch   14: loss=0.123\n",
      "  batch   15: loss=0.208\n",
      "  batch   16: loss=0.294\n",
      "  batch   17: loss=0.288\n",
      "  batch   18: loss=0.218\n",
      "  batch   19: loss=0.259\n",
      "  batch   20: loss=0.288\n",
      "  batch   21: loss=0.185\n",
      "  batch   22: loss=0.271\n",
      "  batch   23: loss=0.239\n",
      "  batch   24: loss=0.129\n",
      "  batch   25: loss=0.230\n",
      "  batch   26: loss=0.458\n",
      "  batch   27: loss=0.142\n",
      "  batch   28: loss=0.369\n",
      "  batch   29: loss=0.188\n",
      "  batch   30: loss=0.202\n",
      "  batch   31: loss=0.192\n",
      "  batch   32: loss=0.098\n",
      "  batch   33: loss=0.246\n",
      "  batch   34: loss=0.211\n",
      "  batch   35: loss=0.201\n",
      "  batch   36: loss=0.241\n",
      "  batch   37: loss=0.337\n",
      "  batch   38: loss=0.318\n",
      "  batch   39: loss=0.134\n",
      "  batch   40: loss=0.375\n",
      "  batch   41: loss=0.169\n",
      "  batch   42: loss=0.210\n",
      "  batch   43: loss=0.154\n",
      "  batch   44: loss=0.250\n",
      "  batch   45: loss=0.327\n",
      "  batch   46: loss=0.221\n",
      "  batch   47: loss=0.205\n",
      "  batch   48: loss=0.151\n",
      "  batch   49: loss=0.207\n",
      "  batch   50: loss=0.252\n",
      "  batch   51: loss=0.290\n",
      "  batch   52: loss=0.124\n",
      "  batch   53: loss=0.147\n",
      "  batch   54: loss=0.323\n",
      "  batch   55: loss=0.263\n",
      "  batch   56: loss=0.222\n",
      "  batch   57: loss=0.269\n",
      "  batch   58: loss=0.472\n",
      "  batch   59: loss=0.403\n",
      "  batch   60: loss=0.253\n",
      "  batch   61: loss=0.651\n",
      "  batch   62: loss=0.390\n",
      "  batch   63: loss=0.352\n",
      "  batch   64: loss=0.217\n",
      "  batch   65: loss=0.221\n",
      "  batch   66: loss=0.244\n",
      "  batch   67: loss=0.242\n",
      "  batch   68: loss=0.260\n",
      "  batch   69: loss=0.203\n",
      "  batch   70: loss=0.283\n",
      "  batch   71: loss=0.223\n",
      "  batch   72: loss=0.256\n",
      "  batch   73: loss=0.188\n",
      "  batch   74: loss=0.186\n",
      "  batch   75: loss=0.193\n",
      "  batch   76: loss=0.312\n",
      "  batch   77: loss=0.397\n",
      "  batch   78: loss=0.221\n",
      "  batch   79: loss=0.182\n",
      "  batch   80: loss=0.475\n",
      "  batch   81: loss=0.521\n",
      "  batch   82: loss=0.878\n",
      "Testing on validation set\n",
      "  acc=0.927\n",
      "Training epoch 23\n",
      "  batch    1: loss=0.290\n",
      "  batch    2: loss=0.109\n",
      "  batch    3: loss=0.174\n",
      "  batch    4: loss=0.458\n",
      "  batch    5: loss=0.146\n",
      "  batch    6: loss=0.033\n",
      "  batch    7: loss=0.151\n",
      "  batch    8: loss=0.225\n",
      "  batch    9: loss=0.380\n",
      "  batch   10: loss=0.189\n",
      "  batch   11: loss=0.412\n",
      "  batch   12: loss=0.432\n",
      "  batch   13: loss=0.163\n",
      "  batch   14: loss=0.188\n",
      "  batch   15: loss=0.147\n",
      "  batch   16: loss=0.261\n",
      "  batch   17: loss=0.280\n",
      "  batch   18: loss=0.193\n",
      "  batch   19: loss=0.311\n",
      "  batch   20: loss=0.225\n",
      "  batch   21: loss=0.186\n",
      "  batch   22: loss=0.526\n",
      "  batch   23: loss=0.213\n",
      "  batch   24: loss=0.167\n",
      "  batch   25: loss=0.207\n",
      "  batch   26: loss=0.201\n",
      "  batch   27: loss=0.259\n",
      "  batch   28: loss=0.191\n",
      "  batch   29: loss=0.340\n",
      "  batch   30: loss=0.177\n",
      "  batch   31: loss=0.239\n",
      "  batch   32: loss=0.556\n",
      "  batch   33: loss=0.162\n",
      "  batch   34: loss=0.172\n",
      "  batch   35: loss=0.228\n",
      "  batch   36: loss=0.326\n",
      "  batch   37: loss=0.235\n",
      "  batch   38: loss=0.249\n",
      "  batch   39: loss=0.309\n",
      "  batch   40: loss=0.294\n",
      "  batch   41: loss=0.244\n",
      "  batch   42: loss=0.243\n",
      "  batch   43: loss=0.274\n",
      "  batch   44: loss=0.218\n",
      "  batch   45: loss=0.269\n",
      "  batch   46: loss=0.278\n",
      "  batch   47: loss=0.394\n",
      "  batch   48: loss=0.201\n",
      "  batch   49: loss=0.178\n",
      "  batch   50: loss=0.177\n",
      "  batch   51: loss=0.154\n",
      "  batch   52: loss=0.244\n",
      "  batch   53: loss=0.144\n",
      "  batch   54: loss=0.264\n",
      "  batch   55: loss=0.171\n",
      "  batch   56: loss=0.265\n",
      "  batch   57: loss=0.255\n",
      "  batch   58: loss=0.113\n",
      "  batch   59: loss=0.232\n",
      "  batch   60: loss=0.235\n",
      "  batch   61: loss=0.222\n",
      "  batch   62: loss=0.193\n",
      "  batch   63: loss=0.224\n",
      "  batch   64: loss=0.300\n",
      "  batch   65: loss=0.260\n",
      "  batch   66: loss=0.320\n",
      "  batch   67: loss=0.193\n",
      "  batch   68: loss=0.235\n",
      "  batch   69: loss=0.223\n",
      "  batch   70: loss=0.394\n",
      "  batch   71: loss=0.173\n",
      "  batch   72: loss=0.211\n",
      "  batch   73: loss=0.144\n",
      "  batch   74: loss=0.341\n",
      "  batch   75: loss=0.102\n",
      "  batch   76: loss=0.239\n",
      "  batch   77: loss=0.412\n",
      "  batch   78: loss=0.197\n",
      "  batch   79: loss=0.060\n",
      "  batch   80: loss=0.195\n",
      "  batch   81: loss=0.129\n",
      "  batch   82: loss=0.349\n",
      "Testing on validation set\n",
      "  acc=0.929\n",
      "Training epoch 24\n",
      "  batch    1: loss=0.452\n",
      "  batch    2: loss=0.229\n",
      "  batch    3: loss=0.176\n",
      "  batch    4: loss=0.372\n",
      "  batch    5: loss=0.250\n",
      "  batch    6: loss=0.160\n",
      "  batch    7: loss=0.346\n",
      "  batch    8: loss=0.261\n",
      "  batch    9: loss=0.103\n",
      "  batch   10: loss=0.325\n",
      "  batch   11: loss=0.212\n",
      "  batch   12: loss=0.254\n",
      "  batch   13: loss=0.316\n",
      "  batch   14: loss=0.400\n",
      "  batch   15: loss=0.355\n",
      "  batch   16: loss=0.245\n",
      "  batch   17: loss=0.239\n",
      "  batch   18: loss=0.249\n",
      "  batch   19: loss=0.263\n",
      "  batch   20: loss=0.240\n",
      "  batch   21: loss=0.089\n",
      "  batch   22: loss=0.222\n",
      "  batch   23: loss=0.294\n",
      "  batch   24: loss=0.265\n",
      "  batch   25: loss=0.330\n",
      "  batch   26: loss=0.544\n",
      "  batch   27: loss=0.182\n",
      "  batch   28: loss=0.148\n",
      "  batch   29: loss=0.089\n",
      "  batch   30: loss=0.349\n",
      "  batch   31: loss=0.383\n",
      "  batch   32: loss=0.103\n",
      "  batch   33: loss=0.301\n",
      "  batch   34: loss=0.186\n",
      "  batch   35: loss=0.337\n",
      "  batch   36: loss=0.337\n",
      "  batch   37: loss=0.189\n",
      "  batch   38: loss=0.329\n",
      "  batch   39: loss=0.125\n",
      "  batch   40: loss=0.117\n",
      "  batch   41: loss=0.170\n",
      "  batch   42: loss=0.212\n",
      "  batch   43: loss=0.317\n",
      "  batch   44: loss=0.469\n",
      "  batch   45: loss=0.098\n",
      "  batch   46: loss=0.338\n",
      "  batch   47: loss=0.257\n",
      "  batch   48: loss=0.502\n",
      "  batch   49: loss=0.384\n",
      "  batch   50: loss=0.172\n",
      "  batch   51: loss=0.182\n",
      "  batch   52: loss=0.275\n",
      "  batch   53: loss=0.236\n",
      "  batch   54: loss=0.240\n",
      "  batch   55: loss=0.278\n",
      "  batch   56: loss=0.222\n",
      "  batch   57: loss=0.456\n",
      "  batch   58: loss=0.251\n",
      "  batch   59: loss=0.275\n",
      "  batch   60: loss=0.333\n",
      "  batch   61: loss=0.211\n",
      "  batch   62: loss=0.099\n",
      "  batch   63: loss=0.427\n",
      "  batch   64: loss=0.274\n",
      "  batch   65: loss=0.250\n",
      "  batch   66: loss=0.174\n",
      "  batch   67: loss=0.524\n",
      "  batch   68: loss=0.143\n",
      "  batch   69: loss=0.289\n",
      "  batch   70: loss=0.459\n",
      "  batch   71: loss=0.177\n",
      "  batch   72: loss=0.292\n",
      "  batch   73: loss=0.239\n",
      "  batch   74: loss=0.154\n",
      "  batch   75: loss=0.189\n",
      "  batch   76: loss=0.124\n",
      "  batch   77: loss=0.286\n",
      "  batch   78: loss=0.214\n",
      "  batch   79: loss=0.540\n",
      "  batch   80: loss=0.183\n",
      "  batch   81: loss=0.355\n",
      "  batch   82: loss=0.258\n",
      "Testing on validation set\n",
      "  acc=0.905\n",
      "Training epoch 25\n",
      "  batch    1: loss=0.125\n",
      "  batch    2: loss=0.116\n",
      "  batch    3: loss=0.177\n",
      "  batch    4: loss=0.289\n",
      "  batch    5: loss=0.157\n",
      "  batch    6: loss=0.215\n",
      "  batch    7: loss=0.173\n",
      "  batch    8: loss=0.190\n",
      "  batch    9: loss=0.346\n",
      "  batch   10: loss=0.211\n",
      "  batch   11: loss=0.193\n",
      "  batch   12: loss=0.398\n",
      "  batch   13: loss=0.358\n",
      "  batch   14: loss=0.323\n",
      "  batch   15: loss=0.263\n",
      "  batch   16: loss=0.165\n",
      "  batch   17: loss=0.185\n",
      "  batch   18: loss=0.229\n",
      "  batch   19: loss=0.267\n",
      "  batch   20: loss=0.181\n",
      "  batch   21: loss=0.259\n",
      "  batch   22: loss=0.159\n",
      "  batch   23: loss=0.195\n",
      "  batch   24: loss=0.288\n",
      "  batch   25: loss=0.303\n",
      "  batch   26: loss=0.573\n",
      "  batch   27: loss=0.282\n",
      "  batch   28: loss=0.306\n",
      "  batch   29: loss=0.112\n",
      "  batch   30: loss=0.319\n",
      "  batch   31: loss=0.463\n",
      "  batch   32: loss=0.426\n",
      "  batch   33: loss=0.162\n",
      "  batch   34: loss=0.213\n",
      "  batch   35: loss=0.369\n",
      "  batch   36: loss=0.265\n",
      "  batch   37: loss=0.254\n",
      "  batch   38: loss=0.316\n",
      "  batch   39: loss=0.241\n",
      "  batch   40: loss=0.176\n",
      "  batch   41: loss=0.417\n",
      "  batch   42: loss=0.274\n",
      "  batch   43: loss=0.201\n",
      "  batch   44: loss=0.363\n",
      "  batch   45: loss=0.214\n",
      "  batch   46: loss=0.219\n",
      "  batch   47: loss=0.217\n",
      "  batch   48: loss=0.293\n",
      "  batch   49: loss=0.174\n",
      "  batch   50: loss=0.211\n",
      "  batch   51: loss=0.188\n",
      "  batch   52: loss=0.175\n",
      "  batch   53: loss=0.367\n",
      "  batch   54: loss=0.343\n",
      "  batch   55: loss=0.338\n",
      "  batch   56: loss=0.267\n",
      "  batch   57: loss=0.242\n",
      "  batch   58: loss=0.187\n",
      "  batch   59: loss=0.307\n",
      "  batch   60: loss=0.523\n",
      "  batch   61: loss=0.158\n",
      "  batch   62: loss=0.231\n",
      "  batch   63: loss=0.405\n",
      "  batch   64: loss=0.258\n",
      "  batch   65: loss=0.393\n",
      "  batch   66: loss=0.218\n",
      "  batch   67: loss=0.167\n",
      "  batch   68: loss=0.143\n",
      "  batch   69: loss=0.256\n",
      "  batch   70: loss=0.094\n",
      "  batch   71: loss=0.317\n",
      "  batch   72: loss=0.149\n",
      "  batch   73: loss=0.185\n",
      "  batch   74: loss=0.314\n",
      "  batch   75: loss=0.348\n",
      "  batch   76: loss=0.460\n",
      "  batch   77: loss=0.469\n",
      "  batch   78: loss=0.469\n",
      "  batch   79: loss=0.192\n",
      "  batch   80: loss=0.298\n",
      "  batch   81: loss=0.348\n",
      "  batch   82: loss=0.400\n",
      "Testing on validation set\n",
      "  acc=0.930\n",
      "Training epoch 26\n",
      "  batch    1: loss=0.131\n",
      "  batch    2: loss=0.220\n",
      "  batch    3: loss=0.350\n",
      "  batch    4: loss=0.086\n",
      "  batch    5: loss=0.209\n",
      "  batch    6: loss=0.305\n",
      "  batch    7: loss=0.366\n",
      "  batch    8: loss=0.387\n",
      "  batch    9: loss=0.465\n",
      "  batch   10: loss=0.153\n",
      "  batch   11: loss=0.247\n",
      "  batch   12: loss=0.271\n",
      "  batch   13: loss=0.326\n",
      "  batch   14: loss=0.179\n",
      "  batch   15: loss=0.169\n",
      "  batch   16: loss=0.373\n",
      "  batch   17: loss=0.314\n",
      "  batch   18: loss=0.318\n",
      "  batch   19: loss=0.333\n",
      "  batch   20: loss=0.149\n",
      "  batch   21: loss=0.348\n",
      "  batch   22: loss=0.190\n",
      "  batch   23: loss=0.297\n",
      "  batch   24: loss=0.180\n",
      "  batch   25: loss=0.167\n",
      "  batch   26: loss=0.273\n",
      "  batch   27: loss=0.217\n",
      "  batch   28: loss=0.180\n",
      "  batch   29: loss=0.431\n",
      "  batch   30: loss=0.157\n",
      "  batch   31: loss=0.235\n",
      "  batch   32: loss=0.337\n",
      "  batch   33: loss=0.241\n",
      "  batch   34: loss=0.135\n",
      "  batch   35: loss=0.189\n",
      "  batch   36: loss=0.205\n",
      "  batch   37: loss=0.080\n",
      "  batch   38: loss=0.210\n",
      "  batch   39: loss=0.229\n",
      "  batch   40: loss=0.219\n",
      "  batch   41: loss=0.165\n",
      "  batch   42: loss=0.160\n",
      "  batch   43: loss=0.236\n",
      "  batch   44: loss=0.213\n",
      "  batch   45: loss=0.335\n",
      "  batch   46: loss=0.222\n",
      "  batch   47: loss=0.373\n",
      "  batch   48: loss=0.284\n",
      "  batch   49: loss=0.115\n",
      "  batch   50: loss=0.419\n",
      "  batch   51: loss=0.220\n",
      "  batch   52: loss=0.164\n",
      "  batch   53: loss=0.241\n",
      "  batch   54: loss=0.300\n",
      "  batch   55: loss=0.239\n",
      "  batch   56: loss=0.172\n",
      "  batch   57: loss=0.075\n",
      "  batch   58: loss=0.183\n",
      "  batch   59: loss=0.134\n",
      "  batch   60: loss=0.127\n",
      "  batch   61: loss=0.261\n",
      "  batch   62: loss=0.189\n",
      "  batch   63: loss=0.144\n",
      "  batch   64: loss=0.098\n",
      "  batch   65: loss=0.311\n",
      "  batch   66: loss=0.214\n",
      "  batch   67: loss=0.153\n",
      "  batch   68: loss=0.245\n",
      "  batch   69: loss=0.109\n",
      "  batch   70: loss=0.183\n",
      "  batch   71: loss=0.050\n",
      "  batch   72: loss=0.196\n",
      "  batch   73: loss=0.151\n",
      "  batch   74: loss=0.225\n",
      "  batch   75: loss=0.375\n",
      "  batch   76: loss=0.186\n",
      "  batch   77: loss=0.291\n",
      "  batch   78: loss=0.227\n",
      "  batch   79: loss=0.227\n",
      "  batch   80: loss=0.272\n",
      "  batch   81: loss=0.417\n",
      "  batch   82: loss=0.058\n",
      "Testing on validation set\n",
      "  acc=0.918\n",
      "Training epoch 27\n",
      "  batch    1: loss=0.252\n",
      "  batch    2: loss=0.217\n",
      "  batch    3: loss=0.203\n",
      "  batch    4: loss=0.241\n",
      "  batch    5: loss=0.226\n",
      "  batch    6: loss=0.161\n",
      "  batch    7: loss=0.183\n",
      "  batch    8: loss=0.291\n",
      "  batch    9: loss=0.200\n",
      "  batch   10: loss=0.162\n",
      "  batch   11: loss=0.229\n",
      "  batch   12: loss=0.209\n",
      "  batch   13: loss=0.148\n",
      "  batch   14: loss=0.194\n",
      "  batch   15: loss=0.186\n",
      "  batch   16: loss=0.144\n",
      "  batch   17: loss=0.087\n",
      "  batch   18: loss=0.156\n",
      "  batch   19: loss=0.199\n",
      "  batch   20: loss=0.208\n",
      "  batch   21: loss=0.373\n",
      "  batch   22: loss=0.158\n",
      "  batch   23: loss=0.176\n",
      "  batch   24: loss=0.233\n",
      "  batch   25: loss=0.166\n",
      "  batch   26: loss=0.312\n",
      "  batch   27: loss=0.150\n",
      "  batch   28: loss=0.081\n",
      "  batch   29: loss=0.193\n",
      "  batch   30: loss=0.270\n",
      "  batch   31: loss=0.245\n",
      "  batch   32: loss=0.140\n",
      "  batch   33: loss=0.155\n",
      "  batch   34: loss=0.078\n",
      "  batch   35: loss=0.178\n",
      "  batch   36: loss=0.237\n",
      "  batch   37: loss=0.343\n",
      "  batch   38: loss=0.148\n",
      "  batch   39: loss=0.346\n",
      "  batch   40: loss=0.175\n",
      "  batch   41: loss=0.135\n",
      "  batch   42: loss=0.108\n",
      "  batch   43: loss=0.195\n",
      "  batch   44: loss=0.283\n",
      "  batch   45: loss=0.126\n",
      "  batch   46: loss=0.272\n",
      "  batch   47: loss=0.491\n",
      "  batch   48: loss=0.265\n",
      "  batch   49: loss=0.322\n",
      "  batch   50: loss=0.193\n",
      "  batch   51: loss=0.230\n",
      "  batch   52: loss=0.119\n",
      "  batch   53: loss=0.346\n",
      "  batch   54: loss=0.267\n",
      "  batch   55: loss=0.345\n",
      "  batch   56: loss=0.216\n",
      "  batch   57: loss=0.462\n",
      "  batch   58: loss=0.160\n",
      "  batch   59: loss=0.178\n",
      "  batch   60: loss=0.089\n",
      "  batch   61: loss=0.325\n",
      "  batch   62: loss=0.264\n",
      "  batch   63: loss=0.330\n",
      "  batch   64: loss=0.225\n",
      "  batch   65: loss=0.282\n",
      "  batch   66: loss=0.125\n",
      "  batch   67: loss=0.253\n",
      "  batch   68: loss=0.102\n",
      "  batch   69: loss=0.171\n",
      "  batch   70: loss=0.133\n",
      "  batch   71: loss=0.287\n",
      "  batch   72: loss=0.138\n",
      "  batch   73: loss=0.139\n",
      "  batch   74: loss=0.141\n",
      "  batch   75: loss=0.224\n",
      "  batch   76: loss=0.079\n",
      "  batch   77: loss=0.219\n",
      "  batch   78: loss=0.238\n",
      "  batch   79: loss=0.269\n",
      "  batch   80: loss=0.194\n",
      "  batch   81: loss=0.207\n",
      "  batch   82: loss=0.262\n",
      "Testing on validation set\n",
      "  acc=0.922\n",
      "Training epoch 28\n",
      "  batch    1: loss=0.474\n",
      "  batch    2: loss=0.176\n",
      "  batch    3: loss=0.116\n",
      "  batch    4: loss=0.407\n",
      "  batch    5: loss=0.221\n",
      "  batch    6: loss=0.283\n",
      "  batch    7: loss=0.158\n",
      "  batch    8: loss=0.193\n",
      "  batch    9: loss=0.340\n",
      "  batch   10: loss=0.160\n",
      "  batch   11: loss=0.178\n",
      "  batch   12: loss=0.431\n",
      "  batch   13: loss=0.284\n",
      "  batch   14: loss=0.283\n",
      "  batch   15: loss=0.367\n",
      "  batch   16: loss=0.285\n",
      "  batch   17: loss=0.086\n",
      "  batch   18: loss=0.304\n",
      "  batch   19: loss=0.097\n",
      "  batch   20: loss=0.290\n",
      "  batch   21: loss=0.163\n",
      "  batch   22: loss=0.279\n",
      "  batch   23: loss=0.114\n",
      "  batch   24: loss=0.468\n",
      "  batch   25: loss=0.239\n",
      "  batch   26: loss=0.198\n",
      "  batch   27: loss=0.280\n",
      "  batch   28: loss=0.344\n",
      "  batch   29: loss=0.336\n",
      "  batch   30: loss=0.279\n",
      "  batch   31: loss=0.277\n",
      "  batch   32: loss=0.121\n",
      "  batch   33: loss=0.293\n",
      "  batch   34: loss=0.382\n",
      "  batch   35: loss=0.067\n",
      "  batch   36: loss=0.224\n",
      "  batch   37: loss=0.184\n",
      "  batch   38: loss=0.358\n",
      "  batch   39: loss=0.203\n",
      "  batch   40: loss=0.088\n",
      "  batch   41: loss=0.162\n",
      "  batch   42: loss=0.444\n",
      "  batch   43: loss=0.309\n",
      "  batch   44: loss=0.211\n",
      "  batch   45: loss=0.220\n",
      "  batch   46: loss=0.154\n",
      "  batch   47: loss=0.188\n",
      "  batch   48: loss=0.334\n",
      "  batch   49: loss=0.368\n",
      "  batch   50: loss=0.288\n",
      "  batch   51: loss=0.230\n",
      "  batch   52: loss=0.331\n",
      "  batch   53: loss=0.269\n",
      "  batch   54: loss=0.230\n",
      "  batch   55: loss=0.239\n",
      "  batch   56: loss=0.291\n",
      "  batch   57: loss=0.135\n",
      "  batch   58: loss=0.266\n",
      "  batch   59: loss=0.430\n",
      "  batch   60: loss=0.299\n",
      "  batch   61: loss=0.167\n",
      "  batch   62: loss=0.289\n",
      "  batch   63: loss=0.421\n",
      "  batch   64: loss=0.252\n",
      "  batch   65: loss=0.386\n",
      "  batch   66: loss=0.197\n",
      "  batch   67: loss=0.095\n",
      "  batch   68: loss=0.262\n",
      "  batch   69: loss=0.191\n",
      "  batch   70: loss=0.252\n",
      "  batch   71: loss=0.151\n",
      "  batch   72: loss=0.164\n",
      "  batch   73: loss=0.277\n",
      "  batch   74: loss=0.215\n",
      "  batch   75: loss=0.302\n",
      "  batch   76: loss=0.208\n",
      "  batch   77: loss=0.188\n",
      "  batch   78: loss=0.131\n",
      "  batch   79: loss=0.383\n",
      "  batch   80: loss=0.223\n",
      "  batch   81: loss=0.290\n",
      "  batch   82: loss=0.065\n",
      "Testing on validation set\n",
      "  acc=0.913\n",
      "Training epoch 29\n",
      "  batch    1: loss=0.188\n",
      "  batch    2: loss=0.213\n",
      "  batch    3: loss=0.131\n",
      "  batch    4: loss=0.355\n",
      "  batch    5: loss=0.249\n",
      "  batch    6: loss=0.175\n",
      "  batch    7: loss=0.247\n",
      "  batch    8: loss=0.207\n",
      "  batch    9: loss=0.144\n",
      "  batch   10: loss=0.089\n",
      "  batch   11: loss=0.245\n",
      "  batch   12: loss=0.186\n",
      "  batch   13: loss=0.130\n",
      "  batch   14: loss=0.472\n",
      "  batch   15: loss=0.241\n",
      "  batch   16: loss=0.377\n",
      "  batch   17: loss=0.127\n",
      "  batch   18: loss=0.191\n",
      "  batch   19: loss=0.299\n",
      "  batch   20: loss=0.276\n",
      "  batch   21: loss=0.226\n",
      "  batch   22: loss=0.223\n",
      "  batch   23: loss=0.330\n",
      "  batch   24: loss=0.120\n",
      "  batch   25: loss=0.156\n",
      "  batch   26: loss=0.241\n",
      "  batch   27: loss=0.267\n",
      "  batch   28: loss=0.110\n",
      "  batch   29: loss=0.283\n",
      "  batch   30: loss=0.377\n",
      "  batch   31: loss=0.290\n",
      "  batch   32: loss=0.348\n",
      "  batch   33: loss=0.373\n",
      "  batch   34: loss=0.202\n",
      "  batch   35: loss=0.163\n",
      "  batch   36: loss=0.294\n",
      "  batch   37: loss=0.396\n",
      "  batch   38: loss=0.348\n",
      "  batch   39: loss=0.238\n",
      "  batch   40: loss=0.428\n",
      "  batch   41: loss=0.220\n",
      "  batch   42: loss=0.221\n",
      "  batch   43: loss=0.295\n",
      "  batch   44: loss=0.210\n",
      "  batch   45: loss=0.133\n",
      "  batch   46: loss=0.098\n",
      "  batch   47: loss=0.120\n",
      "  batch   48: loss=0.179\n",
      "  batch   49: loss=0.286\n",
      "  batch   50: loss=0.096\n",
      "  batch   51: loss=0.250\n",
      "  batch   52: loss=0.140\n",
      "  batch   53: loss=0.169\n",
      "  batch   54: loss=0.096\n",
      "  batch   55: loss=0.210\n",
      "  batch   56: loss=0.207\n",
      "  batch   57: loss=0.197\n",
      "  batch   58: loss=0.163\n",
      "  batch   59: loss=0.191\n",
      "  batch   60: loss=0.219\n",
      "  batch   61: loss=0.403\n",
      "  batch   62: loss=0.249\n",
      "  batch   63: loss=0.298\n",
      "  batch   64: loss=0.177\n",
      "  batch   65: loss=0.126\n",
      "  batch   66: loss=0.224\n",
      "  batch   67: loss=0.328\n",
      "  batch   68: loss=0.192\n",
      "  batch   69: loss=0.267\n",
      "  batch   70: loss=0.064\n",
      "  batch   71: loss=0.128\n",
      "  batch   72: loss=0.240\n",
      "  batch   73: loss=0.349\n",
      "  batch   74: loss=0.154\n",
      "  batch   75: loss=0.281\n",
      "  batch   76: loss=0.126\n",
      "  batch   77: loss=0.090\n",
      "  batch   78: loss=0.167\n",
      "  batch   79: loss=0.154\n",
      "  batch   80: loss=0.289\n",
      "  batch   81: loss=0.312\n",
      "  batch   82: loss=0.486\n",
      "Testing on validation set\n",
      "  acc=0.916\n",
      "Training epoch 30\n",
      "  batch    1: loss=0.069\n",
      "  batch    2: loss=0.127\n",
      "  batch    3: loss=0.299\n",
      "  batch    4: loss=0.264\n",
      "  batch    5: loss=0.239\n",
      "  batch    6: loss=0.304\n",
      "  batch    7: loss=0.160\n",
      "  batch    8: loss=0.233\n",
      "  batch    9: loss=0.184\n",
      "  batch   10: loss=0.252\n",
      "  batch   11: loss=0.371\n",
      "  batch   12: loss=0.223\n",
      "  batch   13: loss=0.188\n",
      "  batch   14: loss=0.330\n",
      "  batch   15: loss=0.355\n",
      "  batch   16: loss=0.140\n",
      "  batch   17: loss=0.325\n",
      "  batch   18: loss=0.228\n",
      "  batch   19: loss=0.346\n",
      "  batch   20: loss=0.403\n",
      "  batch   21: loss=0.224\n",
      "  batch   22: loss=0.140\n",
      "  batch   23: loss=0.135\n",
      "  batch   24: loss=0.311\n",
      "  batch   25: loss=0.093\n",
      "  batch   26: loss=0.418\n",
      "  batch   27: loss=0.368\n",
      "  batch   28: loss=0.128\n",
      "  batch   29: loss=0.318\n",
      "  batch   30: loss=0.150\n",
      "  batch   31: loss=0.208\n",
      "  batch   32: loss=0.157\n",
      "  batch   33: loss=0.103\n",
      "  batch   34: loss=0.250\n",
      "  batch   35: loss=0.310\n",
      "  batch   36: loss=0.287\n",
      "  batch   37: loss=0.215\n",
      "  batch   38: loss=0.200\n",
      "  batch   39: loss=0.216\n",
      "  batch   40: loss=0.132\n",
      "  batch   41: loss=0.189\n",
      "  batch   42: loss=0.233\n",
      "  batch   43: loss=0.209\n",
      "  batch   44: loss=0.197\n",
      "  batch   45: loss=0.397\n",
      "  batch   46: loss=0.218\n",
      "  batch   47: loss=0.289\n",
      "  batch   48: loss=0.107\n",
      "  batch   49: loss=0.216\n",
      "  batch   50: loss=0.374\n",
      "  batch   51: loss=0.392\n",
      "  batch   52: loss=0.280\n",
      "  batch   53: loss=0.114\n",
      "  batch   54: loss=0.148\n",
      "  batch   55: loss=0.104\n",
      "  batch   56: loss=0.101\n",
      "  batch   57: loss=0.221\n",
      "  batch   58: loss=0.280\n",
      "  batch   59: loss=0.170\n",
      "  batch   60: loss=0.103\n",
      "  batch   61: loss=0.288\n",
      "  batch   62: loss=0.056\n",
      "  batch   63: loss=0.245\n",
      "  batch   64: loss=0.164\n",
      "  batch   65: loss=0.273\n",
      "  batch   66: loss=0.389\n",
      "  batch   67: loss=0.321\n",
      "  batch   68: loss=0.222\n",
      "  batch   69: loss=0.239\n",
      "  batch   70: loss=0.369\n",
      "  batch   71: loss=0.308\n",
      "  batch   72: loss=0.136\n",
      "  batch   73: loss=0.280\n",
      "  batch   74: loss=0.311\n",
      "  batch   75: loss=0.495\n",
      "  batch   76: loss=0.170\n",
      "  batch   77: loss=0.140\n",
      "  batch   78: loss=0.315\n",
      "  batch   79: loss=0.141\n",
      "  batch   80: loss=0.127\n",
      "  batch   81: loss=0.256\n",
      "  batch   82: loss=0.183\n",
      "Testing on validation set\n",
      "  acc=0.931\n",
      "Training epoch 31\n",
      "  batch    1: loss=0.208\n",
      "  batch    2: loss=0.187\n",
      "  batch    3: loss=0.332\n",
      "  batch    4: loss=0.177\n",
      "  batch    5: loss=0.149\n",
      "  batch    6: loss=0.183\n",
      "  batch    7: loss=0.199\n",
      "  batch    8: loss=0.151\n",
      "  batch    9: loss=0.159\n",
      "  batch   10: loss=0.264\n",
      "  batch   11: loss=0.310\n",
      "  batch   12: loss=0.304\n",
      "  batch   13: loss=0.132\n",
      "  batch   14: loss=0.325\n",
      "  batch   15: loss=0.173\n",
      "  batch   16: loss=0.149\n",
      "  batch   17: loss=0.277\n",
      "  batch   18: loss=0.110\n",
      "  batch   19: loss=0.185\n",
      "  batch   20: loss=0.258\n",
      "  batch   21: loss=0.241\n",
      "  batch   22: loss=0.084\n",
      "  batch   23: loss=0.197\n",
      "  batch   24: loss=0.183\n",
      "  batch   25: loss=0.317\n",
      "  batch   26: loss=0.166\n",
      "  batch   27: loss=0.207\n",
      "  batch   28: loss=0.184\n",
      "  batch   29: loss=0.212\n",
      "  batch   30: loss=0.115\n",
      "  batch   31: loss=0.067\n",
      "  batch   32: loss=0.121\n",
      "  batch   33: loss=0.241\n",
      "  batch   34: loss=0.116\n",
      "  batch   35: loss=0.196\n",
      "  batch   36: loss=0.184\n",
      "  batch   37: loss=0.114\n",
      "  batch   38: loss=0.153\n",
      "  batch   39: loss=0.077\n",
      "  batch   40: loss=0.207\n",
      "  batch   41: loss=0.167\n",
      "  batch   42: loss=0.307\n",
      "  batch   43: loss=0.140\n",
      "  batch   44: loss=0.285\n",
      "  batch   45: loss=0.183\n",
      "  batch   46: loss=0.351\n",
      "  batch   47: loss=0.174\n",
      "  batch   48: loss=0.380\n",
      "  batch   49: loss=0.207\n",
      "  batch   50: loss=0.112\n",
      "  batch   51: loss=0.164\n",
      "  batch   52: loss=0.173\n",
      "  batch   53: loss=0.130\n",
      "  batch   54: loss=0.124\n",
      "  batch   55: loss=0.290\n",
      "  batch   56: loss=0.322\n",
      "  batch   57: loss=0.345\n",
      "  batch   58: loss=0.190\n",
      "  batch   59: loss=0.351\n",
      "  batch   60: loss=0.226\n",
      "  batch   61: loss=0.207\n",
      "  batch   62: loss=0.232\n",
      "  batch   63: loss=0.174\n",
      "  batch   64: loss=0.116\n",
      "  batch   65: loss=0.146\n",
      "  batch   66: loss=0.090\n",
      "  batch   67: loss=0.282\n",
      "  batch   68: loss=0.331\n",
      "  batch   69: loss=0.106\n",
      "  batch   70: loss=0.410\n",
      "  batch   71: loss=0.068\n",
      "  batch   72: loss=0.131\n",
      "  batch   73: loss=0.299\n",
      "  batch   74: loss=0.281\n",
      "  batch   75: loss=0.202\n",
      "  batch   76: loss=0.282\n",
      "  batch   77: loss=0.211\n",
      "  batch   78: loss=0.300\n",
      "  batch   79: loss=0.211\n",
      "  batch   80: loss=0.399\n",
      "  batch   81: loss=0.330\n",
      "  batch   82: loss=0.461\n",
      "Testing on validation set\n",
      "  acc=0.925\n",
      "Training epoch 32\n",
      "  batch    1: loss=0.149\n",
      "  batch    2: loss=0.253\n",
      "  batch    3: loss=0.184\n",
      "  batch    4: loss=0.138\n",
      "  batch    5: loss=0.265\n",
      "  batch    6: loss=0.298\n",
      "  batch    7: loss=0.247\n",
      "  batch    8: loss=0.133\n",
      "  batch    9: loss=0.305\n",
      "  batch   10: loss=0.274\n",
      "  batch   11: loss=0.237\n",
      "  batch   12: loss=0.242\n",
      "  batch   13: loss=0.115\n",
      "  batch   14: loss=0.155\n",
      "  batch   15: loss=0.054\n",
      "  batch   16: loss=0.230\n",
      "  batch   17: loss=0.337\n",
      "  batch   18: loss=0.302\n",
      "  batch   19: loss=0.265\n",
      "  batch   20: loss=0.168\n",
      "  batch   21: loss=0.210\n",
      "  batch   22: loss=0.226\n",
      "  batch   23: loss=0.297\n",
      "  batch   24: loss=0.395\n",
      "  batch   25: loss=0.511\n",
      "  batch   26: loss=0.162\n",
      "  batch   27: loss=0.158\n",
      "  batch   28: loss=0.083\n",
      "  batch   29: loss=0.218\n",
      "  batch   30: loss=0.181\n",
      "  batch   31: loss=0.239\n",
      "  batch   32: loss=0.239\n",
      "  batch   33: loss=0.216\n",
      "  batch   34: loss=0.125\n",
      "  batch   35: loss=0.211\n",
      "  batch   36: loss=0.190\n",
      "  batch   37: loss=0.372\n",
      "  batch   38: loss=0.229\n",
      "  batch   39: loss=0.117\n",
      "  batch   40: loss=0.292\n",
      "  batch   41: loss=0.263\n",
      "  batch   42: loss=0.327\n",
      "  batch   43: loss=0.183\n",
      "  batch   44: loss=0.213\n",
      "  batch   45: loss=0.221\n",
      "  batch   46: loss=0.377\n",
      "  batch   47: loss=0.164\n",
      "  batch   48: loss=0.240\n",
      "  batch   49: loss=0.139\n",
      "  batch   50: loss=0.354\n",
      "  batch   51: loss=0.043\n",
      "  batch   52: loss=0.270\n",
      "  batch   53: loss=0.476\n",
      "  batch   54: loss=0.354\n",
      "  batch   55: loss=0.342\n",
      "  batch   56: loss=0.221\n",
      "  batch   57: loss=0.070\n",
      "  batch   58: loss=0.208\n",
      "  batch   59: loss=0.124\n",
      "  batch   60: loss=0.138\n",
      "  batch   61: loss=0.158\n",
      "  batch   62: loss=0.212\n",
      "  batch   63: loss=0.292\n",
      "  batch   64: loss=0.182\n",
      "  batch   65: loss=0.190\n",
      "  batch   66: loss=0.140\n",
      "  batch   67: loss=0.267\n",
      "  batch   68: loss=0.183\n",
      "  batch   69: loss=0.402\n",
      "  batch   70: loss=0.334\n",
      "  batch   71: loss=0.173\n",
      "  batch   72: loss=0.070\n",
      "  batch   73: loss=0.108\n",
      "  batch   74: loss=0.221\n",
      "  batch   75: loss=0.204\n",
      "  batch   76: loss=0.332\n",
      "  batch   77: loss=0.221\n",
      "  batch   78: loss=0.205\n",
      "  batch   79: loss=0.249\n",
      "  batch   80: loss=0.157\n",
      "  batch   81: loss=0.250\n",
      "  batch   82: loss=0.352\n",
      "Testing on validation set\n",
      "  acc=0.933\n",
      "Training epoch 33\n",
      "  batch    1: loss=0.138\n",
      "  batch    2: loss=0.169\n",
      "  batch    3: loss=0.244\n",
      "  batch    4: loss=0.224\n",
      "  batch    5: loss=0.311\n",
      "  batch    6: loss=0.088\n",
      "  batch    7: loss=0.101\n",
      "  batch    8: loss=0.082\n",
      "  batch    9: loss=0.324\n",
      "  batch   10: loss=0.290\n",
      "  batch   11: loss=0.136\n",
      "  batch   12: loss=0.100\n",
      "  batch   13: loss=0.209\n",
      "  batch   14: loss=0.379\n",
      "  batch   15: loss=0.236\n",
      "  batch   16: loss=0.167\n",
      "  batch   17: loss=0.168\n",
      "  batch   18: loss=0.254\n",
      "  batch   19: loss=0.462\n",
      "  batch   20: loss=0.243\n",
      "  batch   21: loss=0.138\n",
      "  batch   22: loss=0.374\n",
      "  batch   23: loss=0.241\n",
      "  batch   24: loss=0.124\n",
      "  batch   25: loss=0.359\n",
      "  batch   26: loss=0.178\n",
      "  batch   27: loss=0.356\n",
      "  batch   28: loss=0.217\n",
      "  batch   29: loss=0.141\n",
      "  batch   30: loss=0.357\n",
      "  batch   31: loss=0.226\n",
      "  batch   32: loss=0.188\n",
      "  batch   33: loss=0.199\n",
      "  batch   34: loss=0.322\n",
      "  batch   35: loss=0.398\n",
      "  batch   36: loss=0.221\n",
      "  batch   37: loss=0.178\n",
      "  batch   38: loss=0.297\n",
      "  batch   39: loss=0.280\n",
      "  batch   40: loss=0.313\n",
      "  batch   41: loss=0.383\n",
      "  batch   42: loss=0.139\n",
      "  batch   43: loss=0.176\n",
      "  batch   44: loss=0.301\n",
      "  batch   45: loss=0.171\n",
      "  batch   46: loss=0.163\n",
      "  batch   47: loss=0.586\n",
      "  batch   48: loss=0.292\n",
      "  batch   49: loss=0.313\n",
      "  batch   50: loss=0.346\n",
      "  batch   51: loss=0.244\n",
      "  batch   52: loss=0.248\n",
      "  batch   53: loss=0.182\n",
      "  batch   54: loss=0.305\n",
      "  batch   55: loss=0.067\n",
      "  batch   56: loss=0.195\n",
      "  batch   57: loss=0.203\n",
      "  batch   58: loss=0.197\n",
      "  batch   59: loss=0.201\n",
      "  batch   60: loss=0.343\n",
      "  batch   61: loss=0.298\n",
      "  batch   62: loss=0.299\n",
      "  batch   63: loss=0.190\n",
      "  batch   64: loss=0.466\n",
      "  batch   65: loss=0.186\n",
      "  batch   66: loss=0.201\n",
      "  batch   67: loss=0.143\n",
      "  batch   68: loss=0.137\n",
      "  batch   69: loss=0.288\n",
      "  batch   70: loss=0.395\n",
      "  batch   71: loss=0.218\n",
      "  batch   72: loss=0.294\n",
      "  batch   73: loss=0.230\n",
      "  batch   74: loss=0.219\n",
      "  batch   75: loss=0.163\n",
      "  batch   76: loss=0.164\n",
      "  batch   77: loss=0.239\n",
      "  batch   78: loss=0.211\n",
      "  batch   79: loss=0.336\n",
      "  batch   80: loss=0.191\n",
      "  batch   81: loss=0.309\n",
      "  batch   82: loss=0.477\n",
      "Testing on validation set\n",
      "  acc=0.909\n",
      "Training epoch 34\n",
      "  batch    1: loss=0.174\n",
      "  batch    2: loss=0.160\n",
      "  batch    3: loss=0.277\n",
      "  batch    4: loss=0.047\n",
      "  batch    5: loss=0.245\n",
      "  batch    6: loss=0.247\n",
      "  batch    7: loss=0.205\n",
      "  batch    8: loss=0.123\n",
      "  batch    9: loss=0.315\n",
      "  batch   10: loss=0.154\n",
      "  batch   11: loss=0.224\n",
      "  batch   12: loss=0.105\n",
      "  batch   13: loss=0.343\n",
      "  batch   14: loss=0.470\n",
      "  batch   15: loss=0.139\n",
      "  batch   16: loss=0.142\n",
      "  batch   17: loss=0.302\n",
      "  batch   18: loss=0.104\n",
      "  batch   19: loss=0.160\n",
      "  batch   20: loss=0.132\n",
      "  batch   21: loss=0.248\n",
      "  batch   22: loss=0.052\n",
      "  batch   23: loss=0.412\n",
      "  batch   24: loss=0.132\n",
      "  batch   25: loss=0.356\n",
      "  batch   26: loss=0.145\n",
      "  batch   27: loss=0.257\n",
      "  batch   28: loss=0.195\n",
      "  batch   29: loss=0.241\n",
      "  batch   30: loss=0.207\n",
      "  batch   31: loss=0.140\n",
      "  batch   32: loss=0.213\n",
      "  batch   33: loss=0.286\n",
      "  batch   34: loss=0.143\n",
      "  batch   35: loss=0.363\n",
      "  batch   36: loss=0.324\n",
      "  batch   37: loss=0.200\n",
      "  batch   38: loss=0.082\n",
      "  batch   39: loss=0.237\n",
      "  batch   40: loss=0.191\n",
      "  batch   41: loss=0.163\n",
      "  batch   42: loss=0.220\n",
      "  batch   43: loss=0.387\n",
      "  batch   44: loss=0.326\n",
      "  batch   45: loss=0.232\n",
      "  batch   46: loss=0.282\n",
      "  batch   47: loss=0.429\n",
      "  batch   48: loss=0.114\n",
      "  batch   49: loss=0.156\n",
      "  batch   50: loss=0.059\n",
      "  batch   51: loss=0.347\n",
      "  batch   52: loss=0.140\n",
      "  batch   53: loss=0.389\n",
      "  batch   54: loss=0.205\n",
      "  batch   55: loss=0.396\n",
      "  batch   56: loss=0.468\n",
      "  batch   57: loss=0.130\n",
      "  batch   58: loss=0.168\n",
      "  batch   59: loss=0.196\n",
      "  batch   60: loss=0.222\n",
      "  batch   61: loss=0.117\n",
      "  batch   62: loss=0.150\n",
      "  batch   63: loss=0.082\n",
      "  batch   64: loss=0.125\n",
      "  batch   65: loss=0.216\n",
      "  batch   66: loss=0.251\n",
      "  batch   67: loss=0.204\n",
      "  batch   68: loss=0.158\n",
      "  batch   69: loss=0.246\n",
      "  batch   70: loss=0.332\n",
      "  batch   71: loss=0.151\n",
      "  batch   72: loss=0.295\n",
      "  batch   73: loss=0.096\n",
      "  batch   74: loss=0.296\n",
      "  batch   75: loss=0.217\n",
      "  batch   76: loss=0.362\n",
      "  batch   77: loss=0.115\n",
      "  batch   78: loss=0.161\n",
      "  batch   79: loss=0.288\n",
      "  batch   80: loss=0.375\n",
      "  batch   81: loss=0.118\n",
      "  batch   82: loss=0.046\n",
      "Testing on validation set\n",
      "  acc=0.908\n",
      "Training epoch 35\n",
      "  batch    1: loss=0.287\n",
      "  batch    2: loss=0.410\n",
      "  batch    3: loss=0.177\n",
      "  batch    4: loss=0.265\n",
      "  batch    5: loss=0.324\n",
      "  batch    6: loss=0.133\n",
      "  batch    7: loss=0.122\n",
      "  batch    8: loss=0.067\n",
      "  batch    9: loss=0.254\n",
      "  batch   10: loss=0.212\n",
      "  batch   11: loss=0.341\n",
      "  batch   12: loss=0.206\n",
      "  batch   13: loss=0.307\n",
      "  batch   14: loss=0.126\n",
      "  batch   15: loss=0.337\n",
      "  batch   16: loss=0.155\n",
      "  batch   17: loss=0.131\n",
      "  batch   18: loss=0.220\n",
      "  batch   19: loss=0.080\n",
      "  batch   20: loss=0.309\n",
      "  batch   21: loss=0.155\n",
      "  batch   22: loss=0.364\n",
      "  batch   23: loss=0.181\n",
      "  batch   24: loss=0.263\n",
      "  batch   25: loss=0.046\n",
      "  batch   26: loss=0.382\n",
      "  batch   27: loss=0.194\n",
      "  batch   28: loss=0.302\n",
      "  batch   29: loss=0.186\n",
      "  batch   30: loss=0.119\n",
      "  batch   31: loss=0.182\n",
      "  batch   32: loss=0.371\n",
      "  batch   33: loss=0.218\n",
      "  batch   34: loss=0.333\n",
      "  batch   35: loss=0.306\n",
      "  batch   36: loss=0.203\n",
      "  batch   37: loss=0.244\n",
      "  batch   38: loss=0.330\n",
      "  batch   39: loss=0.055\n",
      "  batch   40: loss=0.114\n",
      "  batch   41: loss=0.185\n",
      "  batch   42: loss=0.125\n",
      "  batch   43: loss=0.117\n",
      "  batch   44: loss=0.216\n",
      "  batch   45: loss=0.485\n",
      "  batch   46: loss=0.150\n",
      "  batch   47: loss=0.412\n",
      "  batch   48: loss=0.164\n",
      "  batch   49: loss=0.104\n",
      "  batch   50: loss=0.216\n",
      "  batch   51: loss=0.116\n",
      "  batch   52: loss=0.358\n",
      "  batch   53: loss=0.273\n",
      "  batch   54: loss=0.265\n",
      "  batch   55: loss=0.220\n",
      "  batch   56: loss=0.292\n",
      "  batch   57: loss=0.131\n",
      "  batch   58: loss=0.227\n",
      "  batch   59: loss=0.075\n",
      "  batch   60: loss=0.190\n",
      "  batch   61: loss=0.136\n",
      "  batch   62: loss=0.336\n",
      "  batch   63: loss=0.231\n",
      "  batch   64: loss=0.168\n",
      "  batch   65: loss=0.153\n",
      "  batch   66: loss=0.229\n",
      "  batch   67: loss=0.256\n",
      "  batch   68: loss=0.261\n",
      "  batch   69: loss=0.279\n",
      "  batch   70: loss=0.202\n",
      "  batch   71: loss=0.320\n",
      "  batch   72: loss=0.126\n",
      "  batch   73: loss=0.186\n",
      "  batch   74: loss=0.258\n",
      "  batch   75: loss=0.125\n",
      "  batch   76: loss=0.219\n",
      "  batch   77: loss=0.362\n",
      "  batch   78: loss=0.107\n",
      "  batch   79: loss=0.383\n",
      "  batch   80: loss=0.266\n",
      "  batch   81: loss=0.173\n",
      "  batch   82: loss=0.212\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 36\n",
      "  batch    1: loss=0.210\n",
      "  batch    2: loss=0.166\n",
      "  batch    3: loss=0.118\n",
      "  batch    4: loss=0.169\n",
      "  batch    5: loss=0.265\n",
      "  batch    6: loss=0.229\n",
      "  batch    7: loss=0.342\n",
      "  batch    8: loss=0.157\n",
      "  batch    9: loss=0.169\n",
      "  batch   10: loss=0.154\n",
      "  batch   11: loss=0.128\n",
      "  batch   12: loss=0.102\n",
      "  batch   13: loss=0.253\n",
      "  batch   14: loss=0.191\n",
      "  batch   15: loss=0.096\n",
      "  batch   16: loss=0.315\n",
      "  batch   17: loss=0.230\n",
      "  batch   18: loss=0.085\n",
      "  batch   19: loss=0.104\n",
      "  batch   20: loss=0.284\n",
      "  batch   21: loss=0.241\n",
      "  batch   22: loss=0.119\n",
      "  batch   23: loss=0.152\n",
      "  batch   24: loss=0.225\n",
      "  batch   25: loss=0.184\n",
      "  batch   26: loss=0.238\n",
      "  batch   27: loss=0.202\n",
      "  batch   28: loss=0.101\n",
      "  batch   29: loss=0.201\n",
      "  batch   30: loss=0.163\n",
      "  batch   31: loss=0.255\n",
      "  batch   32: loss=0.124\n",
      "  batch   33: loss=0.206\n",
      "  batch   34: loss=0.218\n",
      "  batch   35: loss=0.225\n",
      "  batch   36: loss=0.111\n",
      "  batch   37: loss=0.143\n",
      "  batch   38: loss=0.291\n",
      "  batch   39: loss=0.240\n",
      "  batch   40: loss=0.270\n",
      "  batch   41: loss=0.266\n",
      "  batch   42: loss=0.220\n",
      "  batch   43: loss=0.161\n",
      "  batch   44: loss=0.355\n",
      "  batch   45: loss=0.174\n",
      "  batch   46: loss=0.215\n",
      "  batch   47: loss=0.271\n",
      "  batch   48: loss=0.177\n",
      "  batch   49: loss=0.244\n",
      "  batch   50: loss=0.112\n",
      "  batch   51: loss=0.250\n",
      "  batch   52: loss=0.279\n",
      "  batch   53: loss=0.154\n",
      "  batch   54: loss=0.301\n",
      "  batch   55: loss=0.315\n",
      "  batch   56: loss=0.358\n",
      "  batch   57: loss=0.141\n",
      "  batch   58: loss=0.331\n",
      "  batch   59: loss=0.247\n",
      "  batch   60: loss=0.142\n",
      "  batch   61: loss=0.429\n",
      "  batch   62: loss=0.225\n",
      "  batch   63: loss=0.177\n",
      "  batch   64: loss=0.246\n",
      "  batch   65: loss=0.260\n",
      "  batch   66: loss=0.360\n",
      "  batch   67: loss=0.298\n",
      "  batch   68: loss=0.265\n",
      "  batch   69: loss=0.184\n",
      "  batch   70: loss=0.160\n",
      "  batch   71: loss=0.192\n",
      "  batch   72: loss=0.203\n",
      "  batch   73: loss=0.108\n",
      "  batch   74: loss=0.398\n",
      "  batch   75: loss=0.057\n",
      "  batch   76: loss=0.178\n",
      "  batch   77: loss=0.198\n",
      "  batch   78: loss=0.173\n",
      "  batch   79: loss=0.068\n",
      "  batch   80: loss=0.317\n",
      "  batch   81: loss=0.192\n",
      "  batch   82: loss=0.210\n",
      "Testing on validation set\n",
      "  acc=0.913\n",
      "Training epoch 37\n",
      "  batch    1: loss=0.153\n",
      "  batch    2: loss=0.098\n",
      "  batch    3: loss=0.294\n",
      "  batch    4: loss=0.136\n",
      "  batch    5: loss=0.328\n",
      "  batch    6: loss=0.266\n",
      "  batch    7: loss=0.275\n",
      "  batch    8: loss=0.106\n",
      "  batch    9: loss=0.190\n",
      "  batch   10: loss=0.158\n",
      "  batch   11: loss=0.163\n",
      "  batch   12: loss=0.251\n",
      "  batch   13: loss=0.138\n",
      "  batch   14: loss=0.108\n",
      "  batch   15: loss=0.101\n",
      "  batch   16: loss=0.198\n",
      "  batch   17: loss=0.174\n",
      "  batch   18: loss=0.185\n",
      "  batch   19: loss=0.138\n",
      "  batch   20: loss=0.109\n",
      "  batch   21: loss=0.165\n",
      "  batch   22: loss=0.230\n",
      "  batch   23: loss=0.134\n",
      "  batch   24: loss=0.257\n",
      "  batch   25: loss=0.104\n",
      "  batch   26: loss=0.220\n",
      "  batch   27: loss=0.169\n",
      "  batch   28: loss=0.295\n",
      "  batch   29: loss=0.334\n",
      "  batch   30: loss=0.290\n",
      "  batch   31: loss=0.291\n",
      "  batch   32: loss=0.135\n",
      "  batch   33: loss=0.117\n",
      "  batch   34: loss=0.261\n",
      "  batch   35: loss=0.282\n",
      "  batch   36: loss=0.145\n",
      "  batch   37: loss=0.181\n",
      "  batch   38: loss=0.097\n",
      "  batch   39: loss=0.239\n",
      "  batch   40: loss=0.161\n",
      "  batch   41: loss=0.174\n",
      "  batch   42: loss=0.201\n",
      "  batch   43: loss=0.176\n",
      "  batch   44: loss=0.193\n",
      "  batch   45: loss=0.097\n",
      "  batch   46: loss=0.262\n",
      "  batch   47: loss=0.261\n",
      "  batch   48: loss=0.235\n",
      "  batch   49: loss=0.137\n",
      "  batch   50: loss=0.246\n",
      "  batch   51: loss=0.262\n",
      "  batch   52: loss=0.256\n",
      "  batch   53: loss=0.202\n",
      "  batch   54: loss=0.372\n",
      "  batch   55: loss=0.160\n",
      "  batch   56: loss=0.239\n",
      "  batch   57: loss=0.192\n",
      "  batch   58: loss=0.324\n",
      "  batch   59: loss=0.218\n",
      "  batch   60: loss=0.245\n",
      "  batch   61: loss=0.167\n",
      "  batch   62: loss=0.072\n",
      "  batch   63: loss=0.322\n",
      "  batch   64: loss=0.328\n",
      "  batch   65: loss=0.146\n",
      "  batch   66: loss=0.274\n",
      "  batch   67: loss=0.211\n",
      "  batch   68: loss=0.189\n",
      "  batch   69: loss=0.263\n",
      "  batch   70: loss=0.215\n",
      "  batch   71: loss=0.238\n",
      "  batch   72: loss=0.112\n",
      "  batch   73: loss=0.200\n",
      "  batch   74: loss=0.314\n",
      "  batch   75: loss=0.402\n",
      "  batch   76: loss=0.233\n",
      "  batch   77: loss=0.315\n",
      "  batch   78: loss=0.380\n",
      "  batch   79: loss=0.233\n",
      "  batch   80: loss=0.242\n",
      "  batch   81: loss=0.125\n",
      "  batch   82: loss=0.554\n",
      "Testing on validation set\n",
      "  acc=0.915\n",
      "Training epoch 38\n",
      "  batch    1: loss=0.177\n",
      "  batch    2: loss=0.215\n",
      "  batch    3: loss=0.104\n",
      "  batch    4: loss=0.166\n",
      "  batch    5: loss=0.140\n",
      "  batch    6: loss=0.247\n",
      "  batch    7: loss=0.143\n",
      "  batch    8: loss=0.079\n",
      "  batch    9: loss=0.135\n",
      "  batch   10: loss=0.230\n",
      "  batch   11: loss=0.065\n",
      "  batch   12: loss=0.459\n",
      "  batch   13: loss=0.141\n",
      "  batch   14: loss=0.152\n",
      "  batch   15: loss=0.262\n",
      "  batch   16: loss=0.139\n",
      "  batch   17: loss=0.195\n",
      "  batch   18: loss=0.175\n",
      "  batch   19: loss=0.266\n",
      "  batch   20: loss=0.218\n",
      "  batch   21: loss=0.369\n",
      "  batch   22: loss=0.198\n",
      "  batch   23: loss=0.206\n",
      "  batch   24: loss=0.102\n",
      "  batch   25: loss=0.358\n",
      "  batch   26: loss=0.376\n",
      "  batch   27: loss=0.257\n",
      "  batch   28: loss=0.120\n",
      "  batch   29: loss=0.215\n",
      "  batch   30: loss=0.119\n",
      "  batch   31: loss=0.169\n",
      "  batch   32: loss=0.216\n",
      "  batch   33: loss=0.187\n",
      "  batch   34: loss=0.249\n",
      "  batch   35: loss=0.173\n",
      "  batch   36: loss=0.103\n",
      "  batch   37: loss=0.086\n",
      "  batch   38: loss=0.122\n",
      "  batch   39: loss=0.213\n",
      "  batch   40: loss=0.133\n",
      "  batch   41: loss=0.301\n",
      "  batch   42: loss=0.146\n",
      "  batch   43: loss=0.279\n",
      "  batch   44: loss=0.257\n",
      "  batch   45: loss=0.203\n",
      "  batch   46: loss=0.229\n",
      "  batch   47: loss=0.123\n",
      "  batch   48: loss=0.174\n",
      "  batch   49: loss=0.065\n",
      "  batch   50: loss=0.336\n",
      "  batch   51: loss=0.113\n",
      "  batch   52: loss=0.105\n",
      "  batch   53: loss=0.268\n",
      "  batch   54: loss=0.231\n",
      "  batch   55: loss=0.130\n",
      "  batch   56: loss=0.300\n",
      "  batch   57: loss=0.223\n",
      "  batch   58: loss=0.127\n",
      "  batch   59: loss=0.363\n",
      "  batch   60: loss=0.213\n",
      "  batch   61: loss=0.242\n",
      "  batch   62: loss=0.194\n",
      "  batch   63: loss=0.120\n",
      "  batch   64: loss=0.123\n",
      "  batch   65: loss=0.150\n",
      "  batch   66: loss=0.145\n",
      "  batch   67: loss=0.092\n",
      "  batch   68: loss=0.336\n",
      "  batch   69: loss=0.114\n",
      "  batch   70: loss=0.165\n",
      "  batch   71: loss=0.239\n",
      "  batch   72: loss=0.070\n",
      "  batch   73: loss=0.069\n",
      "  batch   74: loss=0.227\n",
      "  batch   75: loss=0.328\n",
      "  batch   76: loss=0.243\n",
      "  batch   77: loss=0.186\n",
      "  batch   78: loss=0.262\n",
      "  batch   79: loss=0.224\n",
      "  batch   80: loss=0.098\n",
      "  batch   81: loss=0.303\n",
      "  batch   82: loss=0.277\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 39\n",
      "  batch    1: loss=0.203\n",
      "  batch    2: loss=0.146\n",
      "  batch    3: loss=0.165\n",
      "  batch    4: loss=0.084\n",
      "  batch    5: loss=0.248\n",
      "  batch    6: loss=0.221\n",
      "  batch    7: loss=0.077\n",
      "  batch    8: loss=0.225\n",
      "  batch    9: loss=0.193\n",
      "  batch   10: loss=0.205\n",
      "  batch   11: loss=0.402\n",
      "  batch   12: loss=0.136\n",
      "  batch   13: loss=0.074\n",
      "  batch   14: loss=0.236\n",
      "  batch   15: loss=0.479\n",
      "  batch   16: loss=0.259\n",
      "  batch   17: loss=0.152\n",
      "  batch   18: loss=0.306\n",
      "  batch   19: loss=0.215\n",
      "  batch   20: loss=0.142\n",
      "  batch   21: loss=0.298\n",
      "  batch   22: loss=0.238\n",
      "  batch   23: loss=0.169\n",
      "  batch   24: loss=0.153\n",
      "  batch   25: loss=0.180\n",
      "  batch   26: loss=0.268\n",
      "  batch   27: loss=0.049\n",
      "  batch   28: loss=0.226\n",
      "  batch   29: loss=0.056\n",
      "  batch   30: loss=0.164\n",
      "  batch   31: loss=0.299\n",
      "  batch   32: loss=0.290\n",
      "  batch   33: loss=0.168\n",
      "  batch   34: loss=0.158\n",
      "  batch   35: loss=0.158\n",
      "  batch   36: loss=0.158\n",
      "  batch   37: loss=0.243\n",
      "  batch   38: loss=0.227\n",
      "  batch   39: loss=0.159\n",
      "  batch   40: loss=0.175\n",
      "  batch   41: loss=0.124\n",
      "  batch   42: loss=0.411\n",
      "  batch   43: loss=0.198\n",
      "  batch   44: loss=0.301\n",
      "  batch   45: loss=0.169\n",
      "  batch   46: loss=0.263\n",
      "  batch   47: loss=0.110\n",
      "  batch   48: loss=0.313\n",
      "  batch   49: loss=0.356\n",
      "  batch   50: loss=0.120\n",
      "  batch   51: loss=0.208\n",
      "  batch   52: loss=0.309\n",
      "  batch   53: loss=0.189\n",
      "  batch   54: loss=0.115\n",
      "  batch   55: loss=0.140\n",
      "  batch   56: loss=0.038\n",
      "  batch   57: loss=0.229\n",
      "  batch   58: loss=0.226\n",
      "  batch   59: loss=0.103\n",
      "  batch   60: loss=0.215\n",
      "  batch   61: loss=0.225\n",
      "  batch   62: loss=0.096\n",
      "  batch   63: loss=0.159\n",
      "  batch   64: loss=0.185\n",
      "  batch   65: loss=0.086\n",
      "  batch   66: loss=0.127\n",
      "  batch   67: loss=0.040\n",
      "  batch   68: loss=0.273\n",
      "  batch   69: loss=0.198\n",
      "  batch   70: loss=0.199\n",
      "  batch   71: loss=0.253\n",
      "  batch   72: loss=0.206\n",
      "  batch   73: loss=0.173\n",
      "  batch   74: loss=0.401\n",
      "  batch   75: loss=0.142\n",
      "  batch   76: loss=0.520\n",
      "  batch   77: loss=0.218\n",
      "  batch   78: loss=0.259\n",
      "  batch   79: loss=0.372\n",
      "  batch   80: loss=0.169\n",
      "  batch   81: loss=0.204\n",
      "  batch   82: loss=0.374\n",
      "Testing on validation set\n",
      "  acc=0.917\n",
      "Training epoch 40\n",
      "  batch    1: loss=0.130\n",
      "  batch    2: loss=0.088\n",
      "  batch    3: loss=0.142\n",
      "  batch    4: loss=0.264\n",
      "  batch    5: loss=0.137\n",
      "  batch    6: loss=0.469\n",
      "  batch    7: loss=0.198\n",
      "  batch    8: loss=0.102\n",
      "  batch    9: loss=0.079\n",
      "  batch   10: loss=0.099\n",
      "  batch   11: loss=0.127\n",
      "  batch   12: loss=0.252\n",
      "  batch   13: loss=0.308\n",
      "  batch   14: loss=0.299\n",
      "  batch   15: loss=0.372\n",
      "  batch   16: loss=0.203\n",
      "  batch   17: loss=0.205\n",
      "  batch   18: loss=0.286\n",
      "  batch   19: loss=0.242\n",
      "  batch   20: loss=0.202\n",
      "  batch   21: loss=0.175\n",
      "  batch   22: loss=0.232\n",
      "  batch   23: loss=0.110\n",
      "  batch   24: loss=0.194\n",
      "  batch   25: loss=0.136\n",
      "  batch   26: loss=0.293\n",
      "  batch   27: loss=0.136\n",
      "  batch   28: loss=0.177\n",
      "  batch   29: loss=0.159\n",
      "  batch   30: loss=0.128\n",
      "  batch   31: loss=0.112\n",
      "  batch   32: loss=0.232\n",
      "  batch   33: loss=0.159\n",
      "  batch   34: loss=0.256\n",
      "  batch   35: loss=0.087\n",
      "  batch   36: loss=0.139\n",
      "  batch   37: loss=0.088\n",
      "  batch   38: loss=0.146\n",
      "  batch   39: loss=0.212\n",
      "  batch   40: loss=0.172\n",
      "  batch   41: loss=0.179\n",
      "  batch   42: loss=0.172\n",
      "  batch   43: loss=0.192\n",
      "  batch   44: loss=0.175\n",
      "  batch   45: loss=0.389\n",
      "  batch   46: loss=0.143\n",
      "  batch   47: loss=0.314\n",
      "  batch   48: loss=0.259\n",
      "  batch   49: loss=0.135\n",
      "  batch   50: loss=0.226\n",
      "  batch   51: loss=0.291\n",
      "  batch   52: loss=0.185\n",
      "  batch   53: loss=0.068\n",
      "  batch   54: loss=0.093\n",
      "  batch   55: loss=0.198\n",
      "  batch   56: loss=0.209\n",
      "  batch   57: loss=0.288\n",
      "  batch   58: loss=0.122\n",
      "  batch   59: loss=0.211\n",
      "  batch   60: loss=0.220\n",
      "  batch   61: loss=0.170\n",
      "  batch   62: loss=0.214\n",
      "  batch   63: loss=0.149\n",
      "  batch   64: loss=0.262\n",
      "  batch   65: loss=0.274\n",
      "  batch   66: loss=0.056\n",
      "  batch   67: loss=0.273\n",
      "  batch   68: loss=0.284\n",
      "  batch   69: loss=0.243\n",
      "  batch   70: loss=0.094\n",
      "  batch   71: loss=0.306\n",
      "  batch   72: loss=0.260\n",
      "  batch   73: loss=0.099\n",
      "  batch   74: loss=0.248\n",
      "  batch   75: loss=0.147\n",
      "  batch   76: loss=0.398\n",
      "  batch   77: loss=0.102\n",
      "  batch   78: loss=0.189\n",
      "  batch   79: loss=0.233\n",
      "  batch   80: loss=0.274\n",
      "  batch   81: loss=0.079\n",
      "  batch   82: loss=0.211\n",
      "Testing on validation set\n",
      "  acc=0.900\n",
      "Training epoch 41\n",
      "  batch    1: loss=0.126\n",
      "  batch    2: loss=0.289\n",
      "  batch    3: loss=0.126\n",
      "  batch    4: loss=0.302\n",
      "  batch    5: loss=0.152\n",
      "  batch    6: loss=0.120\n",
      "  batch    7: loss=0.190\n",
      "  batch    8: loss=0.249\n",
      "  batch    9: loss=0.102\n",
      "  batch   10: loss=0.282\n",
      "  batch   11: loss=0.216\n",
      "  batch   12: loss=0.279\n",
      "  batch   13: loss=0.164\n",
      "  batch   14: loss=0.135\n",
      "  batch   15: loss=0.176\n",
      "  batch   16: loss=0.240\n",
      "  batch   17: loss=0.175\n",
      "  batch   18: loss=0.299\n",
      "  batch   19: loss=0.283\n",
      "  batch   20: loss=0.083\n",
      "  batch   21: loss=0.128\n",
      "  batch   22: loss=0.344\n",
      "  batch   23: loss=0.172\n",
      "  batch   24: loss=0.235\n",
      "  batch   25: loss=0.376\n",
      "  batch   26: loss=0.352\n",
      "  batch   27: loss=0.222\n",
      "  batch   28: loss=0.135\n",
      "  batch   29: loss=0.227\n",
      "  batch   30: loss=0.315\n",
      "  batch   31: loss=0.262\n",
      "  batch   32: loss=0.077\n",
      "  batch   33: loss=0.186\n",
      "  batch   34: loss=0.239\n",
      "  batch   35: loss=0.253\n",
      "  batch   36: loss=0.208\n",
      "  batch   37: loss=0.191\n",
      "  batch   38: loss=0.322\n",
      "  batch   39: loss=0.184\n",
      "  batch   40: loss=0.241\n",
      "  batch   41: loss=0.264\n",
      "  batch   42: loss=0.238\n",
      "  batch   43: loss=0.193\n",
      "  batch   44: loss=0.224\n",
      "  batch   45: loss=0.452\n",
      "  batch   46: loss=0.215\n",
      "  batch   47: loss=0.177\n",
      "  batch   48: loss=0.526\n",
      "  batch   49: loss=0.154\n",
      "  batch   50: loss=0.246\n",
      "  batch   51: loss=0.040\n",
      "  batch   52: loss=0.053\n",
      "  batch   53: loss=0.179\n",
      "  batch   54: loss=0.301\n",
      "  batch   55: loss=0.438\n",
      "  batch   56: loss=0.034\n",
      "  batch   57: loss=0.313\n",
      "  batch   58: loss=0.242\n",
      "  batch   59: loss=0.177\n",
      "  batch   60: loss=0.184\n",
      "  batch   61: loss=0.221\n",
      "  batch   62: loss=0.097\n",
      "  batch   63: loss=0.228\n",
      "  batch   64: loss=0.285\n",
      "  batch   65: loss=0.146\n",
      "  batch   66: loss=0.087\n",
      "  batch   67: loss=0.078\n",
      "  batch   68: loss=0.417\n",
      "  batch   69: loss=0.246\n",
      "  batch   70: loss=0.066\n",
      "  batch   71: loss=0.229\n",
      "  batch   72: loss=0.184\n",
      "  batch   73: loss=0.157\n",
      "  batch   74: loss=0.095\n",
      "  batch   75: loss=0.216\n",
      "  batch   76: loss=0.215\n",
      "  batch   77: loss=0.278\n",
      "  batch   78: loss=0.237\n",
      "  batch   79: loss=0.114\n",
      "  batch   80: loss=0.217\n",
      "  batch   81: loss=0.276\n",
      "  batch   82: loss=0.444\n",
      "Testing on validation set\n",
      "  acc=0.899\n",
      "Training epoch 42\n",
      "  batch    1: loss=0.205\n",
      "  batch    2: loss=0.169\n",
      "  batch    3: loss=0.286\n",
      "  batch    4: loss=0.205\n",
      "  batch    5: loss=0.159\n",
      "  batch    6: loss=0.057\n",
      "  batch    7: loss=0.226\n",
      "  batch    8: loss=0.225\n",
      "  batch    9: loss=0.259\n",
      "  batch   10: loss=0.122\n",
      "  batch   11: loss=0.179\n",
      "  batch   12: loss=0.078\n",
      "  batch   13: loss=0.498\n",
      "  batch   14: loss=0.163\n",
      "  batch   15: loss=0.137\n",
      "  batch   16: loss=0.102\n",
      "  batch   17: loss=0.163\n",
      "  batch   18: loss=0.070\n",
      "  batch   19: loss=0.193\n",
      "  batch   20: loss=0.113\n",
      "  batch   21: loss=0.156\n",
      "  batch   22: loss=0.242\n",
      "  batch   23: loss=0.196\n",
      "  batch   24: loss=0.108\n",
      "  batch   25: loss=0.396\n",
      "  batch   26: loss=0.057\n",
      "  batch   27: loss=0.254\n",
      "  batch   28: loss=0.161\n",
      "  batch   29: loss=0.275\n",
      "  batch   30: loss=0.335\n",
      "  batch   31: loss=0.248\n",
      "  batch   32: loss=0.168\n",
      "  batch   33: loss=0.081\n",
      "  batch   34: loss=0.244\n",
      "  batch   35: loss=0.165\n",
      "  batch   36: loss=0.125\n",
      "  batch   37: loss=0.184\n",
      "  batch   38: loss=0.169\n",
      "  batch   39: loss=0.245\n",
      "  batch   40: loss=0.248\n",
      "  batch   41: loss=0.072\n",
      "  batch   42: loss=0.105\n",
      "  batch   43: loss=0.121\n",
      "  batch   44: loss=0.245\n",
      "  batch   45: loss=0.281\n",
      "  batch   46: loss=0.140\n",
      "  batch   47: loss=0.278\n",
      "  batch   48: loss=0.311\n",
      "  batch   49: loss=0.410\n",
      "  batch   50: loss=0.187\n",
      "  batch   51: loss=0.123\n",
      "  batch   52: loss=0.182\n",
      "  batch   53: loss=0.167\n",
      "  batch   54: loss=0.156\n",
      "  batch   55: loss=0.369\n",
      "  batch   56: loss=0.142\n",
      "  batch   57: loss=0.092\n",
      "  batch   58: loss=0.127\n",
      "  batch   59: loss=0.221\n",
      "  batch   60: loss=0.431\n",
      "  batch   61: loss=0.314\n",
      "  batch   62: loss=0.281\n",
      "  batch   63: loss=0.130\n",
      "  batch   64: loss=0.205\n",
      "  batch   65: loss=0.087\n",
      "  batch   66: loss=0.216\n",
      "  batch   67: loss=0.157\n",
      "  batch   68: loss=0.274\n",
      "  batch   69: loss=0.041\n",
      "  batch   70: loss=0.101\n",
      "  batch   71: loss=0.254\n",
      "  batch   72: loss=0.247\n",
      "  batch   73: loss=0.183\n",
      "  batch   74: loss=0.391\n",
      "  batch   75: loss=0.293\n",
      "  batch   76: loss=0.301\n",
      "  batch   77: loss=0.073\n",
      "  batch   78: loss=0.182\n",
      "  batch   79: loss=0.155\n",
      "  batch   80: loss=0.277\n",
      "  batch   81: loss=0.221\n",
      "  batch   82: loss=0.445\n",
      "Testing on validation set\n",
      "  acc=0.911\n",
      "Training epoch 43\n",
      "  batch    1: loss=0.229\n",
      "  batch    2: loss=0.322\n",
      "  batch    3: loss=0.176\n",
      "  batch    4: loss=0.146\n",
      "  batch    5: loss=0.213\n",
      "  batch    6: loss=0.290\n",
      "  batch    7: loss=0.135\n",
      "  batch    8: loss=0.123\n",
      "  batch    9: loss=0.216\n",
      "  batch   10: loss=0.146\n",
      "  batch   11: loss=0.281\n",
      "  batch   12: loss=0.274\n",
      "  batch   13: loss=0.220\n",
      "  batch   14: loss=0.191\n",
      "  batch   15: loss=0.215\n",
      "  batch   16: loss=0.102\n",
      "  batch   17: loss=0.139\n",
      "  batch   18: loss=0.150\n",
      "  batch   19: loss=0.225\n",
      "  batch   20: loss=0.296\n",
      "  batch   21: loss=0.129\n",
      "  batch   22: loss=0.126\n",
      "  batch   23: loss=0.303\n",
      "  batch   24: loss=0.139\n",
      "  batch   25: loss=0.249\n",
      "  batch   26: loss=0.109\n",
      "  batch   27: loss=0.168\n",
      "  batch   28: loss=0.046\n",
      "  batch   29: loss=0.131\n",
      "  batch   30: loss=0.139\n",
      "  batch   31: loss=0.170\n",
      "  batch   32: loss=0.161\n",
      "  batch   33: loss=0.231\n",
      "  batch   34: loss=0.336\n",
      "  batch   35: loss=0.081\n",
      "  batch   36: loss=0.153\n",
      "  batch   37: loss=0.250\n",
      "  batch   38: loss=0.155\n",
      "  batch   39: loss=0.164\n",
      "  batch   40: loss=0.309\n",
      "  batch   41: loss=0.220\n",
      "  batch   42: loss=0.140\n",
      "  batch   43: loss=0.193\n",
      "  batch   44: loss=0.115\n",
      "  batch   45: loss=0.094\n",
      "  batch   46: loss=0.076\n",
      "  batch   47: loss=0.151\n",
      "  batch   48: loss=0.226\n",
      "  batch   49: loss=0.102\n",
      "  batch   50: loss=0.138\n",
      "  batch   51: loss=0.127\n",
      "  batch   52: loss=0.141\n",
      "  batch   53: loss=0.263\n",
      "  batch   54: loss=0.218\n",
      "  batch   55: loss=0.125\n",
      "  batch   56: loss=0.159\n",
      "  batch   57: loss=0.258\n",
      "  batch   58: loss=0.306\n",
      "  batch   59: loss=0.093\n",
      "  batch   60: loss=0.156\n",
      "  batch   61: loss=0.256\n",
      "  batch   62: loss=0.135\n",
      "  batch   63: loss=0.110\n",
      "  batch   64: loss=0.141\n",
      "  batch   65: loss=0.200\n",
      "  batch   66: loss=0.174\n",
      "  batch   67: loss=0.176\n",
      "  batch   68: loss=0.258\n",
      "  batch   69: loss=0.201\n",
      "  batch   70: loss=0.273\n",
      "  batch   71: loss=0.309\n",
      "  batch   72: loss=0.135\n",
      "  batch   73: loss=0.046\n",
      "  batch   74: loss=0.215\n",
      "  batch   75: loss=0.132\n",
      "  batch   76: loss=0.233\n",
      "  batch   77: loss=0.301\n",
      "  batch   78: loss=0.330\n",
      "  batch   79: loss=0.231\n",
      "  batch   80: loss=0.267\n",
      "  batch   81: loss=0.136\n",
      "  batch   82: loss=0.337\n",
      "Testing on validation set\n",
      "  acc=0.917\n",
      "Training epoch 44\n",
      "  batch    1: loss=0.279\n",
      "  batch    2: loss=0.188\n",
      "  batch    3: loss=0.098\n",
      "  batch    4: loss=0.099\n",
      "  batch    5: loss=0.217\n",
      "  batch    6: loss=0.248\n",
      "  batch    7: loss=0.165\n",
      "  batch    8: loss=0.238\n",
      "  batch    9: loss=0.317\n",
      "  batch   10: loss=0.182\n",
      "  batch   11: loss=0.168\n",
      "  batch   12: loss=0.125\n",
      "  batch   13: loss=0.312\n",
      "  batch   14: loss=0.158\n",
      "  batch   15: loss=0.216\n",
      "  batch   16: loss=0.247\n",
      "  batch   17: loss=0.202\n",
      "  batch   18: loss=0.317\n",
      "  batch   19: loss=0.150\n",
      "  batch   20: loss=0.124\n",
      "  batch   21: loss=0.087\n",
      "  batch   22: loss=0.117\n",
      "  batch   23: loss=0.125\n",
      "  batch   24: loss=0.070\n",
      "  batch   25: loss=0.090\n",
      "  batch   26: loss=0.162\n",
      "  batch   27: loss=0.397\n",
      "  batch   28: loss=0.272\n",
      "  batch   29: loss=0.282\n",
      "  batch   30: loss=0.289\n",
      "  batch   31: loss=0.125\n",
      "  batch   32: loss=0.194\n",
      "  batch   33: loss=0.182\n",
      "  batch   34: loss=0.129\n",
      "  batch   35: loss=0.145\n",
      "  batch   36: loss=0.152\n",
      "  batch   37: loss=0.137\n",
      "  batch   38: loss=0.160\n",
      "  batch   39: loss=0.317\n",
      "  batch   40: loss=0.305\n",
      "  batch   41: loss=0.202\n",
      "  batch   42: loss=0.307\n",
      "  batch   43: loss=0.150\n",
      "  batch   44: loss=0.197\n",
      "  batch   45: loss=0.255\n",
      "  batch   46: loss=0.222\n",
      "  batch   47: loss=0.190\n",
      "  batch   48: loss=0.101\n",
      "  batch   49: loss=0.288\n",
      "  batch   50: loss=0.120\n",
      "  batch   51: loss=0.139\n",
      "  batch   52: loss=0.078\n",
      "  batch   53: loss=0.234\n",
      "  batch   54: loss=0.103\n",
      "  batch   55: loss=0.159\n",
      "  batch   56: loss=0.148\n",
      "  batch   57: loss=0.156\n",
      "  batch   58: loss=0.235\n",
      "  batch   59: loss=0.126\n",
      "  batch   60: loss=0.298\n",
      "  batch   61: loss=0.186\n",
      "  batch   62: loss=0.158\n",
      "  batch   63: loss=0.248\n",
      "  batch   64: loss=0.212\n",
      "  batch   65: loss=0.251\n",
      "  batch   66: loss=0.392\n",
      "  batch   67: loss=0.280\n",
      "  batch   68: loss=0.223\n",
      "  batch   69: loss=0.080\n",
      "  batch   70: loss=0.290\n",
      "  batch   71: loss=0.135\n",
      "  batch   72: loss=0.316\n",
      "  batch   73: loss=0.108\n",
      "  batch   74: loss=0.264\n",
      "  batch   75: loss=0.286\n",
      "  batch   76: loss=0.235\n",
      "  batch   77: loss=0.181\n",
      "  batch   78: loss=0.238\n",
      "  batch   79: loss=0.351\n",
      "  batch   80: loss=0.267\n",
      "  batch   81: loss=0.158\n",
      "  batch   82: loss=0.740\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 45\n",
      "  batch    1: loss=0.147\n",
      "  batch    2: loss=0.089\n",
      "  batch    3: loss=0.114\n",
      "  batch    4: loss=0.105\n",
      "  batch    5: loss=0.252\n",
      "  batch    6: loss=0.275\n",
      "  batch    7: loss=0.172\n",
      "  batch    8: loss=0.144\n",
      "  batch    9: loss=0.237\n",
      "  batch   10: loss=0.241\n",
      "  batch   11: loss=0.240\n",
      "  batch   12: loss=0.299\n",
      "  batch   13: loss=0.106\n",
      "  batch   14: loss=0.120\n",
      "  batch   15: loss=0.061\n",
      "  batch   16: loss=0.221\n",
      "  batch   17: loss=0.155\n",
      "  batch   18: loss=0.167\n",
      "  batch   19: loss=0.109\n",
      "  batch   20: loss=0.276\n",
      "  batch   21: loss=0.280\n",
      "  batch   22: loss=0.330\n",
      "  batch   23: loss=0.153\n",
      "  batch   24: loss=0.141\n",
      "  batch   25: loss=0.126\n",
      "  batch   26: loss=0.092\n",
      "  batch   27: loss=0.264\n",
      "  batch   28: loss=0.067\n",
      "  batch   29: loss=0.259\n",
      "  batch   30: loss=0.246\n",
      "  batch   31: loss=0.335\n",
      "  batch   32: loss=0.193\n",
      "  batch   33: loss=0.126\n",
      "  batch   34: loss=0.188\n",
      "  batch   35: loss=0.105\n",
      "  batch   36: loss=0.168\n",
      "  batch   37: loss=0.160\n",
      "  batch   38: loss=0.152\n",
      "  batch   39: loss=0.205\n",
      "  batch   40: loss=0.231\n",
      "  batch   41: loss=0.210\n",
      "  batch   42: loss=0.191\n",
      "  batch   43: loss=0.286\n",
      "  batch   44: loss=0.110\n",
      "  batch   45: loss=0.195\n",
      "  batch   46: loss=0.164\n",
      "  batch   47: loss=0.208\n",
      "  batch   48: loss=0.094\n",
      "  batch   49: loss=0.155\n",
      "  batch   50: loss=0.190\n",
      "  batch   51: loss=0.162\n",
      "  batch   52: loss=0.223\n",
      "  batch   53: loss=0.178\n",
      "  batch   54: loss=0.245\n",
      "  batch   55: loss=0.205\n",
      "  batch   56: loss=0.280\n",
      "  batch   57: loss=0.098\n",
      "  batch   58: loss=0.220\n",
      "  batch   59: loss=0.115\n",
      "  batch   60: loss=0.187\n",
      "  batch   61: loss=0.347\n",
      "  batch   62: loss=0.231\n",
      "  batch   63: loss=0.212\n",
      "  batch   64: loss=0.151\n",
      "  batch   65: loss=0.164\n",
      "  batch   66: loss=0.254\n",
      "  batch   67: loss=0.150\n",
      "  batch   68: loss=0.103\n",
      "  batch   69: loss=0.113\n",
      "  batch   70: loss=0.212\n",
      "  batch   71: loss=0.044\n",
      "  batch   72: loss=0.197\n",
      "  batch   73: loss=0.201\n",
      "  batch   74: loss=0.170\n",
      "  batch   75: loss=0.283\n",
      "  batch   76: loss=0.244\n",
      "  batch   77: loss=0.090\n",
      "  batch   78: loss=0.235\n",
      "  batch   79: loss=0.260\n",
      "  batch   80: loss=0.193\n",
      "  batch   81: loss=0.220\n",
      "  batch   82: loss=0.096\n",
      "Testing on validation set\n",
      "  acc=0.919\n",
      "Training epoch 46\n",
      "  batch    1: loss=0.227\n",
      "  batch    2: loss=0.386\n",
      "  batch    3: loss=0.060\n",
      "  batch    4: loss=0.216\n",
      "  batch    5: loss=0.104\n",
      "  batch    6: loss=0.197\n",
      "  batch    7: loss=0.186\n",
      "  batch    8: loss=0.150\n",
      "  batch    9: loss=0.218\n",
      "  batch   10: loss=0.293\n",
      "  batch   11: loss=0.178\n",
      "  batch   12: loss=0.106\n",
      "  batch   13: loss=0.240\n",
      "  batch   14: loss=0.156\n",
      "  batch   15: loss=0.250\n",
      "  batch   16: loss=0.247\n",
      "  batch   17: loss=0.138\n",
      "  batch   18: loss=0.252\n",
      "  batch   19: loss=0.195\n",
      "  batch   20: loss=0.130\n",
      "  batch   21: loss=0.246\n",
      "  batch   22: loss=0.251\n",
      "  batch   23: loss=0.226\n",
      "  batch   24: loss=0.313\n",
      "  batch   25: loss=0.127\n",
      "  batch   26: loss=0.177\n",
      "  batch   27: loss=0.110\n",
      "  batch   28: loss=0.243\n",
      "  batch   29: loss=0.177\n",
      "  batch   30: loss=0.115\n",
      "  batch   31: loss=0.187\n",
      "  batch   32: loss=0.177\n",
      "  batch   33: loss=0.183\n",
      "  batch   34: loss=0.087\n",
      "  batch   35: loss=0.078\n",
      "  batch   36: loss=0.038\n",
      "  batch   37: loss=0.228\n",
      "  batch   38: loss=0.155\n",
      "  batch   39: loss=0.310\n",
      "  batch   40: loss=0.183\n",
      "  batch   41: loss=0.157\n",
      "  batch   42: loss=0.107\n",
      "  batch   43: loss=0.175\n",
      "  batch   44: loss=0.227\n",
      "  batch   45: loss=0.180\n",
      "  batch   46: loss=0.179\n",
      "  batch   47: loss=0.182\n",
      "  batch   48: loss=0.244\n",
      "  batch   49: loss=0.237\n",
      "  batch   50: loss=0.178\n",
      "  batch   51: loss=0.222\n",
      "  batch   52: loss=0.311\n",
      "  batch   53: loss=0.210\n",
      "  batch   54: loss=0.224\n",
      "  batch   55: loss=0.262\n",
      "  batch   56: loss=0.283\n",
      "  batch   57: loss=0.160\n",
      "  batch   58: loss=0.184\n",
      "  batch   59: loss=0.276\n",
      "  batch   60: loss=0.194\n",
      "  batch   61: loss=0.128\n",
      "  batch   62: loss=0.328\n",
      "  batch   63: loss=0.254\n",
      "  batch   64: loss=0.163\n",
      "  batch   65: loss=0.282\n",
      "  batch   66: loss=0.195\n",
      "  batch   67: loss=0.226\n",
      "  batch   68: loss=0.153\n",
      "  batch   69: loss=0.243\n",
      "  batch   70: loss=0.263\n",
      "  batch   71: loss=0.110\n",
      "  batch   72: loss=0.052\n",
      "  batch   73: loss=0.215\n",
      "  batch   74: loss=0.145\n",
      "  batch   75: loss=0.177\n",
      "  batch   76: loss=0.275\n",
      "  batch   77: loss=0.158\n",
      "  batch   78: loss=0.193\n",
      "  batch   79: loss=0.179\n",
      "  batch   80: loss=0.107\n",
      "  batch   81: loss=0.392\n",
      "  batch   82: loss=0.144\n",
      "Testing on validation set\n",
      "  acc=0.901\n",
      "Training epoch 47\n",
      "  batch    1: loss=0.152\n",
      "  batch    2: loss=0.193\n",
      "  batch    3: loss=0.083\n",
      "  batch    4: loss=0.214\n",
      "  batch    5: loss=0.210\n",
      "  batch    6: loss=0.098\n",
      "  batch    7: loss=0.131\n",
      "  batch    8: loss=0.168\n",
      "  batch    9: loss=0.092\n",
      "  batch   10: loss=0.212\n",
      "  batch   11: loss=0.253\n",
      "  batch   12: loss=0.246\n",
      "  batch   13: loss=0.268\n",
      "  batch   14: loss=0.170\n",
      "  batch   15: loss=0.198\n",
      "  batch   16: loss=0.359\n",
      "  batch   17: loss=0.105\n",
      "  batch   18: loss=0.038\n",
      "  batch   19: loss=0.131\n",
      "  batch   20: loss=0.203\n",
      "  batch   21: loss=0.183\n",
      "  batch   22: loss=0.241\n",
      "  batch   23: loss=0.288\n",
      "  batch   24: loss=0.182\n",
      "  batch   25: loss=0.125\n",
      "  batch   26: loss=0.225\n",
      "  batch   27: loss=0.214\n",
      "  batch   28: loss=0.302\n",
      "  batch   29: loss=0.160\n",
      "  batch   30: loss=0.078\n",
      "  batch   31: loss=0.159\n",
      "  batch   32: loss=0.086\n",
      "  batch   33: loss=0.109\n",
      "  batch   34: loss=0.291\n",
      "  batch   35: loss=0.230\n",
      "  batch   36: loss=0.189\n",
      "  batch   37: loss=0.244\n",
      "  batch   38: loss=0.258\n",
      "  batch   39: loss=0.330\n",
      "  batch   40: loss=0.046\n",
      "  batch   41: loss=0.284\n",
      "  batch   42: loss=0.061\n",
      "  batch   43: loss=0.197\n",
      "  batch   44: loss=0.115\n",
      "  batch   45: loss=0.184\n",
      "  batch   46: loss=0.275\n",
      "  batch   47: loss=0.176\n",
      "  batch   48: loss=0.509\n",
      "  batch   49: loss=0.229\n",
      "  batch   50: loss=0.173\n",
      "  batch   51: loss=0.186\n",
      "  batch   52: loss=0.286\n",
      "  batch   53: loss=0.249\n",
      "  batch   54: loss=0.257\n",
      "  batch   55: loss=0.098\n",
      "  batch   56: loss=0.156\n",
      "  batch   57: loss=0.233\n",
      "  batch   58: loss=0.116\n",
      "  batch   59: loss=0.061\n",
      "  batch   60: loss=0.187\n",
      "  batch   61: loss=0.166\n",
      "  batch   62: loss=0.280\n",
      "  batch   63: loss=0.162\n",
      "  batch   64: loss=0.230\n",
      "  batch   65: loss=0.234\n",
      "  batch   66: loss=0.119\n",
      "  batch   67: loss=0.331\n",
      "  batch   68: loss=0.234\n",
      "  batch   69: loss=0.227\n",
      "  batch   70: loss=0.124\n",
      "  batch   71: loss=0.061\n",
      "  batch   72: loss=0.224\n",
      "  batch   73: loss=0.267\n",
      "  batch   74: loss=0.103\n",
      "  batch   75: loss=0.453\n",
      "  batch   76: loss=0.118\n",
      "  batch   77: loss=0.202\n",
      "  batch   78: loss=0.132\n",
      "  batch   79: loss=0.336\n",
      "  batch   80: loss=0.205\n",
      "  batch   81: loss=0.147\n",
      "  batch   82: loss=0.774\n",
      "Testing on validation set\n",
      "  acc=0.914\n",
      "Training epoch 48\n",
      "  batch    1: loss=0.138\n",
      "  batch    2: loss=0.386\n",
      "  batch    3: loss=0.211\n",
      "  batch    4: loss=0.314\n",
      "  batch    5: loss=0.211\n",
      "  batch    6: loss=0.095\n",
      "  batch    7: loss=0.128\n",
      "  batch    8: loss=0.131\n",
      "  batch    9: loss=0.074\n",
      "  batch   10: loss=0.246\n",
      "  batch   11: loss=0.254\n",
      "  batch   12: loss=0.214\n",
      "  batch   13: loss=0.212\n",
      "  batch   14: loss=0.255\n",
      "  batch   15: loss=0.099\n",
      "  batch   16: loss=0.295\n",
      "  batch   17: loss=0.449\n",
      "  batch   18: loss=0.344\n",
      "  batch   19: loss=0.494\n",
      "  batch   20: loss=0.126\n",
      "  batch   21: loss=0.202\n",
      "  batch   22: loss=0.105\n",
      "  batch   23: loss=0.184\n",
      "  batch   24: loss=0.402\n",
      "  batch   25: loss=0.179\n",
      "  batch   26: loss=0.372\n",
      "  batch   27: loss=0.270\n",
      "  batch   28: loss=0.360\n",
      "  batch   29: loss=0.156\n",
      "  batch   30: loss=0.251\n",
      "  batch   31: loss=0.187\n",
      "  batch   32: loss=0.189\n",
      "  batch   33: loss=0.104\n",
      "  batch   34: loss=0.163\n",
      "  batch   35: loss=0.210\n",
      "  batch   36: loss=0.185\n",
      "  batch   37: loss=0.133\n",
      "  batch   38: loss=0.270\n",
      "  batch   39: loss=0.221\n",
      "  batch   40: loss=0.057\n",
      "  batch   41: loss=0.117\n",
      "  batch   42: loss=0.348\n",
      "  batch   43: loss=0.124\n",
      "  batch   44: loss=0.198\n",
      "  batch   45: loss=0.205\n",
      "  batch   46: loss=0.176\n",
      "  batch   47: loss=0.198\n",
      "  batch   48: loss=0.249\n",
      "  batch   49: loss=0.174\n",
      "  batch   50: loss=0.158\n",
      "  batch   51: loss=0.154\n",
      "  batch   52: loss=0.175\n",
      "  batch   53: loss=0.237\n",
      "  batch   54: loss=0.207\n",
      "  batch   55: loss=0.206\n",
      "  batch   56: loss=0.208\n",
      "  batch   57: loss=0.154\n",
      "  batch   58: loss=0.288\n",
      "  batch   59: loss=0.249\n",
      "  batch   60: loss=0.041\n",
      "  batch   61: loss=0.236\n",
      "  batch   62: loss=0.320\n",
      "  batch   63: loss=0.243\n",
      "  batch   64: loss=0.270\n",
      "  batch   65: loss=0.111\n",
      "  batch   66: loss=0.281\n",
      "  batch   67: loss=0.333\n",
      "  batch   68: loss=0.202\n",
      "  batch   69: loss=0.167\n",
      "  batch   70: loss=0.212\n",
      "  batch   71: loss=0.211\n",
      "  batch   72: loss=0.223\n",
      "  batch   73: loss=0.233\n",
      "  batch   74: loss=0.115\n",
      "  batch   75: loss=0.056\n",
      "  batch   76: loss=0.184\n",
      "  batch   77: loss=0.188\n",
      "  batch   78: loss=0.161\n",
      "  batch   79: loss=0.133\n",
      "  batch   80: loss=0.156\n",
      "  batch   81: loss=0.134\n",
      "  batch   82: loss=0.188\n",
      "Testing on validation set\n",
      "  acc=0.906\n",
      "Training epoch 49\n",
      "  batch    1: loss=0.231\n",
      "  batch    2: loss=0.211\n",
      "  batch    3: loss=0.157\n",
      "  batch    4: loss=0.159\n",
      "  batch    5: loss=0.062\n",
      "  batch    6: loss=0.156\n",
      "  batch    7: loss=0.133\n",
      "  batch    8: loss=0.098\n",
      "  batch    9: loss=0.237\n",
      "  batch   10: loss=0.122\n",
      "  batch   11: loss=0.213\n",
      "  batch   12: loss=0.201\n",
      "  batch   13: loss=0.130\n",
      "  batch   14: loss=0.129\n",
      "  batch   15: loss=0.207\n",
      "  batch   16: loss=0.118\n",
      "  batch   17: loss=0.034\n",
      "  batch   18: loss=0.310\n",
      "  batch   19: loss=0.139\n",
      "  batch   20: loss=0.165\n",
      "  batch   21: loss=0.197\n",
      "  batch   22: loss=0.164\n",
      "  batch   23: loss=0.195\n",
      "  batch   24: loss=0.103\n",
      "  batch   25: loss=0.274\n",
      "  batch   26: loss=0.218\n",
      "  batch   27: loss=0.197\n",
      "  batch   28: loss=0.213\n",
      "  batch   29: loss=0.090\n",
      "  batch   30: loss=0.117\n",
      "  batch   31: loss=0.142\n",
      "  batch   32: loss=0.061\n",
      "  batch   33: loss=0.056\n",
      "  batch   34: loss=0.253\n",
      "  batch   35: loss=0.189\n",
      "  batch   36: loss=0.253\n",
      "  batch   37: loss=0.090\n",
      "  batch   38: loss=0.264\n",
      "  batch   39: loss=0.151\n",
      "  batch   40: loss=0.056\n",
      "  batch   41: loss=0.225\n",
      "  batch   42: loss=0.252\n",
      "  batch   43: loss=0.070\n",
      "  batch   44: loss=0.115\n",
      "  batch   45: loss=0.217\n",
      "  batch   46: loss=0.102\n",
      "  batch   47: loss=0.058\n",
      "  batch   48: loss=0.083\n",
      "  batch   49: loss=0.038\n",
      "  batch   50: loss=0.244\n",
      "  batch   51: loss=0.148\n",
      "  batch   52: loss=0.195\n",
      "  batch   53: loss=0.333\n",
      "  batch   54: loss=0.130\n",
      "  batch   55: loss=0.045\n",
      "  batch   56: loss=0.410\n",
      "  batch   57: loss=0.042\n",
      "  batch   58: loss=0.135\n",
      "  batch   59: loss=0.178\n",
      "  batch   60: loss=0.223\n",
      "  batch   61: loss=0.136\n",
      "  batch   62: loss=0.246\n",
      "  batch   63: loss=0.177\n",
      "  batch   64: loss=0.170\n",
      "  batch   65: loss=0.274\n",
      "  batch   66: loss=0.210\n",
      "  batch   67: loss=0.098\n",
      "  batch   68: loss=0.493\n",
      "  batch   69: loss=0.196\n",
      "  batch   70: loss=0.052\n",
      "  batch   71: loss=0.177\n",
      "  batch   72: loss=0.145\n",
      "  batch   73: loss=0.072\n",
      "  batch   74: loss=0.129\n",
      "  batch   75: loss=0.182\n",
      "  batch   76: loss=0.078\n",
      "  batch   77: loss=0.147\n",
      "  batch   78: loss=0.142\n",
      "  batch   79: loss=0.100\n",
      "  batch   80: loss=0.420\n",
      "  batch   81: loss=0.083\n",
      "  batch   82: loss=0.244\n",
      "Testing on validation set\n",
      "  acc=0.911\n",
      "  acc=0.907\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[-1] = nn.Linear(model.last_channel, 101)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=args.lr,\n",
    "    momentum=args.momentum\n",
    ")\n",
    "\n",
    "args.lr = 0.005\n",
    "args.num_epochs = 50\n",
    "\n",
    "for e in range(args.num_epochs):\n",
    "  print('Training epoch {}'.format(e))\n",
    "  train(args, model, criterion, train_loader, optimizer, device)\n",
    "  print('Testing on validation set')\n",
    "  test(args, model, val_loader, device)\n",
    "\n",
    "test(args, model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "21a88GkKglx1",
    "outputId": "10019488-00a4-42a8-b646-288ae70d10ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "  batch    1: loss=4.609\n",
      "  batch    2: loss=4.563\n",
      "  batch    3: loss=4.571\n",
      "  batch    4: loss=4.326\n",
      "  batch    5: loss=4.332\n",
      "  batch    6: loss=4.311\n",
      "  batch    7: loss=4.400\n",
      "  batch    8: loss=4.505\n",
      "  batch    9: loss=4.222\n",
      "  batch   10: loss=4.000\n",
      "  batch   11: loss=4.667\n",
      "  batch   12: loss=4.481\n",
      "  batch   13: loss=4.397\n",
      "  batch   14: loss=4.055\n",
      "  batch   15: loss=4.144\n",
      "  batch   16: loss=4.146\n",
      "  batch   17: loss=4.109\n",
      "  batch   18: loss=4.128\n",
      "  batch   19: loss=3.968\n",
      "  batch   20: loss=4.275\n",
      "  batch   21: loss=4.285\n",
      "  batch   22: loss=4.090\n",
      "  batch   23: loss=4.141\n",
      "  batch   24: loss=4.208\n",
      "  batch   25: loss=4.191\n",
      "  batch   26: loss=4.244\n",
      "  batch   27: loss=4.184\n",
      "  batch   28: loss=4.513\n",
      "  batch   29: loss=4.271\n",
      "  batch   30: loss=4.273\n",
      "  batch   31: loss=4.143\n",
      "  batch   32: loss=4.366\n",
      "  batch   33: loss=4.086\n",
      "  batch   34: loss=4.380\n",
      "  batch   35: loss=3.912\n",
      "  batch   36: loss=4.282\n",
      "  batch   37: loss=4.155\n",
      "  batch   38: loss=3.963\n",
      "  batch   39: loss=3.815\n",
      "  batch   40: loss=4.017\n",
      "  batch   41: loss=4.190\n",
      "  batch   42: loss=4.443\n",
      "  batch   43: loss=4.183\n",
      "  batch   44: loss=4.143\n",
      "  batch   45: loss=4.067\n",
      "  batch   46: loss=4.131\n",
      "  batch   47: loss=3.781\n",
      "  batch   48: loss=4.117\n",
      "  batch   49: loss=4.138\n",
      "  batch   50: loss=4.030\n",
      "  batch   51: loss=3.725\n",
      "  batch   52: loss=3.830\n",
      "  batch   53: loss=3.851\n",
      "  batch   54: loss=3.958\n",
      "  batch   55: loss=3.671\n",
      "  batch   56: loss=3.786\n",
      "  batch   57: loss=4.112\n",
      "  batch   58: loss=3.679\n",
      "  batch   59: loss=3.826\n",
      "  batch   60: loss=4.210\n",
      "  batch   61: loss=4.071\n",
      "  batch   62: loss=4.043\n",
      "  batch   63: loss=3.846\n",
      "  batch   64: loss=3.728\n",
      "  batch   65: loss=3.513\n",
      "  batch   66: loss=3.835\n",
      "  batch   67: loss=3.852\n",
      "  batch   68: loss=3.963\n",
      "  batch   69: loss=3.465\n",
      "  batch   70: loss=3.813\n",
      "  batch   71: loss=4.103\n",
      "  batch   72: loss=3.512\n",
      "  batch   73: loss=3.727\n",
      "  batch   74: loss=3.448\n",
      "  batch   75: loss=3.571\n",
      "  batch   76: loss=3.960\n",
      "  batch   77: loss=3.937\n",
      "  batch   78: loss=3.518\n",
      "  batch   79: loss=3.742\n",
      "  batch   80: loss=3.894\n",
      "  batch   81: loss=4.057\n",
      "  batch   82: loss=3.777\n",
      "Testing on validation set\n",
      "  acc=0.192\n",
      "Training epoch 1\n",
      "  batch    1: loss=3.738\n",
      "  batch    2: loss=3.750\n",
      "  batch    3: loss=3.788\n",
      "  batch    4: loss=3.573\n",
      "  batch    5: loss=3.413\n",
      "  batch    6: loss=3.684\n",
      "  batch    7: loss=3.825\n",
      "  batch    8: loss=3.726\n",
      "  batch    9: loss=4.002\n",
      "  batch   10: loss=3.891\n",
      "  batch   11: loss=3.803\n",
      "  batch   12: loss=3.958\n",
      "  batch   13: loss=3.661\n",
      "  batch   14: loss=3.081\n",
      "  batch   15: loss=3.530\n",
      "  batch   16: loss=3.550\n",
      "  batch   17: loss=3.469\n",
      "  batch   18: loss=3.377\n",
      "  batch   19: loss=3.569\n",
      "  batch   20: loss=3.781\n",
      "  batch   21: loss=3.686\n",
      "  batch   22: loss=3.802\n",
      "  batch   23: loss=3.319\n",
      "  batch   24: loss=3.238\n",
      "  batch   25: loss=3.254\n",
      "  batch   26: loss=3.702\n",
      "  batch   27: loss=3.832\n",
      "  batch   28: loss=3.178\n",
      "  batch   29: loss=3.082\n",
      "  batch   30: loss=3.474\n",
      "  batch   31: loss=3.587\n",
      "  batch   32: loss=3.840\n",
      "  batch   33: loss=3.873\n",
      "  batch   34: loss=3.021\n",
      "  batch   35: loss=3.381\n",
      "  batch   36: loss=3.635\n",
      "  batch   37: loss=3.769\n",
      "  batch   38: loss=3.869\n",
      "  batch   39: loss=3.632\n",
      "  batch   40: loss=3.636\n",
      "  batch   41: loss=3.589\n",
      "  batch   42: loss=3.440\n",
      "  batch   43: loss=3.365\n",
      "  batch   44: loss=2.962\n",
      "  batch   45: loss=3.312\n",
      "  batch   46: loss=3.942\n",
      "  batch   47: loss=3.507\n",
      "  batch   48: loss=3.519\n",
      "  batch   49: loss=3.241\n",
      "  batch   50: loss=3.606\n",
      "  batch   51: loss=3.592\n",
      "  batch   52: loss=3.959\n",
      "  batch   53: loss=3.538\n",
      "  batch   54: loss=3.162\n",
      "  batch   55: loss=3.472\n",
      "  batch   56: loss=3.291\n",
      "  batch   57: loss=3.596\n",
      "  batch   58: loss=3.288\n",
      "  batch   59: loss=3.585\n",
      "  batch   60: loss=3.412\n",
      "  batch   61: loss=3.713\n",
      "  batch   62: loss=3.462\n",
      "  batch   63: loss=3.548\n",
      "  batch   64: loss=3.149\n",
      "  batch   65: loss=3.366\n",
      "  batch   66: loss=3.488\n",
      "  batch   67: loss=3.071\n",
      "  batch   68: loss=3.527\n",
      "  batch   69: loss=3.201\n",
      "  batch   70: loss=3.334\n",
      "  batch   71: loss=3.937\n",
      "  batch   72: loss=3.689\n",
      "  batch   73: loss=3.349\n",
      "  batch   74: loss=3.202\n",
      "  batch   75: loss=3.280\n",
      "  batch   76: loss=3.518\n",
      "  batch   77: loss=3.306\n",
      "  batch   78: loss=3.493\n",
      "  batch   79: loss=3.604\n",
      "  batch   80: loss=3.584\n",
      "  batch   81: loss=3.168\n",
      "  batch   82: loss=3.273\n",
      "Testing on validation set\n",
      "  acc=0.274\n",
      "Training epoch 2\n",
      "  batch    1: loss=2.976\n",
      "  batch    2: loss=3.363\n",
      "  batch    3: loss=3.576\n",
      "  batch    4: loss=3.318\n",
      "  batch    5: loss=3.443\n",
      "  batch    6: loss=3.124\n",
      "  batch    7: loss=3.373\n",
      "  batch    8: loss=3.223\n",
      "  batch    9: loss=3.378\n",
      "  batch   10: loss=3.507\n",
      "  batch   11: loss=3.472\n",
      "  batch   12: loss=3.698\n",
      "  batch   13: loss=3.170\n",
      "  batch   14: loss=2.929\n",
      "  batch   15: loss=3.375\n",
      "  batch   16: loss=3.501\n",
      "  batch   17: loss=3.069\n",
      "  batch   18: loss=3.263\n",
      "  batch   19: loss=3.017\n",
      "  batch   20: loss=3.483\n",
      "  batch   21: loss=3.219\n",
      "  batch   22: loss=3.037\n",
      "  batch   23: loss=3.516\n",
      "  batch   24: loss=3.272\n",
      "  batch   25: loss=3.545\n",
      "  batch   26: loss=3.347\n",
      "  batch   27: loss=3.057\n",
      "  batch   28: loss=3.278\n",
      "  batch   29: loss=3.343\n",
      "  batch   30: loss=2.651\n",
      "  batch   31: loss=3.111\n",
      "  batch   32: loss=3.550\n",
      "  batch   33: loss=3.496\n",
      "  batch   34: loss=3.781\n",
      "  batch   35: loss=2.971\n",
      "  batch   36: loss=3.440\n",
      "  batch   37: loss=3.335\n",
      "  batch   38: loss=3.306\n",
      "  batch   39: loss=3.386\n",
      "  batch   40: loss=3.662\n",
      "  batch   41: loss=3.083\n",
      "  batch   42: loss=3.018\n",
      "  batch   43: loss=3.208\n",
      "  batch   44: loss=3.362\n",
      "  batch   45: loss=3.347\n",
      "  batch   46: loss=3.496\n",
      "  batch   47: loss=3.181\n",
      "  batch   48: loss=3.173\n",
      "  batch   49: loss=3.272\n",
      "  batch   50: loss=3.233\n",
      "  batch   51: loss=3.364\n",
      "  batch   52: loss=2.854\n",
      "  batch   53: loss=3.279\n",
      "  batch   54: loss=3.331\n",
      "  batch   55: loss=3.222\n",
      "  batch   56: loss=2.972\n",
      "  batch   57: loss=2.898\n",
      "  batch   58: loss=3.533\n",
      "  batch   59: loss=3.341\n",
      "  batch   60: loss=2.963\n",
      "  batch   61: loss=2.992\n",
      "  batch   62: loss=3.074\n",
      "  batch   63: loss=3.077\n",
      "  batch   64: loss=3.317\n",
      "  batch   65: loss=3.130\n",
      "  batch   66: loss=3.321\n",
      "  batch   67: loss=3.022\n",
      "  batch   68: loss=2.806\n",
      "  batch   69: loss=3.426\n",
      "  batch   70: loss=3.437\n",
      "  batch   71: loss=3.226\n",
      "  batch   72: loss=3.650\n",
      "  batch   73: loss=2.989\n",
      "  batch   74: loss=2.940\n",
      "  batch   75: loss=3.127\n",
      "  batch   76: loss=2.982\n",
      "  batch   77: loss=3.324\n",
      "  batch   78: loss=3.313\n",
      "  batch   79: loss=3.485\n",
      "  batch   80: loss=3.317\n",
      "  batch   81: loss=3.098\n",
      "  batch   82: loss=3.245\n",
      "Testing on validation set\n",
      "  acc=0.247\n",
      "Training epoch 3\n",
      "  batch    1: loss=3.581\n",
      "  batch    2: loss=3.432\n",
      "  batch    3: loss=3.310\n",
      "  batch    4: loss=2.778\n",
      "  batch    5: loss=3.456\n",
      "  batch    6: loss=3.477\n",
      "  batch    7: loss=3.346\n",
      "  batch    8: loss=3.480\n",
      "  batch    9: loss=3.070\n",
      "  batch   10: loss=3.007\n",
      "  batch   11: loss=3.212\n",
      "  batch   12: loss=2.866\n",
      "  batch   13: loss=3.099\n",
      "  batch   14: loss=3.037\n",
      "  batch   15: loss=3.003\n",
      "  batch   16: loss=3.113\n",
      "  batch   17: loss=3.178\n",
      "  batch   18: loss=2.905\n",
      "  batch   19: loss=3.026\n",
      "  batch   20: loss=3.292\n",
      "  batch   21: loss=3.207\n",
      "  batch   22: loss=3.175\n",
      "  batch   23: loss=3.296\n",
      "  batch   24: loss=3.085\n",
      "  batch   25: loss=3.965\n",
      "  batch   26: loss=3.041\n",
      "  batch   27: loss=2.987\n",
      "  batch   28: loss=3.151\n",
      "  batch   29: loss=3.041\n",
      "  batch   30: loss=3.089\n",
      "  batch   31: loss=3.203\n",
      "  batch   32: loss=3.020\n",
      "  batch   33: loss=2.695\n",
      "  batch   34: loss=3.120\n",
      "  batch   35: loss=3.259\n",
      "  batch   36: loss=3.053\n",
      "  batch   37: loss=2.862\n",
      "  batch   38: loss=3.316\n",
      "  batch   39: loss=3.325\n",
      "  batch   40: loss=3.349\n",
      "  batch   41: loss=2.828\n",
      "  batch   42: loss=3.260\n",
      "  batch   43: loss=3.245\n",
      "  batch   44: loss=3.223\n",
      "  batch   45: loss=3.143\n",
      "  batch   46: loss=3.536\n",
      "  batch   47: loss=2.957\n",
      "  batch   48: loss=3.328\n",
      "  batch   49: loss=3.000\n",
      "  batch   50: loss=3.070\n",
      "  batch   51: loss=2.718\n",
      "  batch   52: loss=2.750\n",
      "  batch   53: loss=2.714\n",
      "  batch   54: loss=2.536\n",
      "  batch   55: loss=2.933\n",
      "  batch   56: loss=2.712\n",
      "  batch   57: loss=2.984\n",
      "  batch   58: loss=3.100\n",
      "  batch   59: loss=3.120\n",
      "  batch   60: loss=3.242\n",
      "  batch   61: loss=2.803\n",
      "  batch   62: loss=3.175\n",
      "  batch   63: loss=2.881\n",
      "  batch   64: loss=3.155\n",
      "  batch   65: loss=3.051\n",
      "  batch   66: loss=3.022\n",
      "  batch   67: loss=3.510\n",
      "  batch   68: loss=2.760\n",
      "  batch   69: loss=3.467\n",
      "  batch   70: loss=2.858\n",
      "  batch   71: loss=3.091\n",
      "  batch   72: loss=2.757\n",
      "  batch   73: loss=2.742\n",
      "  batch   74: loss=2.777\n",
      "  batch   75: loss=2.913\n",
      "  batch   76: loss=2.868\n",
      "  batch   77: loss=3.312\n",
      "  batch   78: loss=2.926\n",
      "  batch   79: loss=2.594\n",
      "  batch   80: loss=3.376\n",
      "  batch   81: loss=3.150\n",
      "  batch   82: loss=3.404\n",
      "Testing on validation set\n",
      "  acc=0.314\n",
      "Training epoch 4\n",
      "  batch    1: loss=3.396\n",
      "  batch    2: loss=3.066\n",
      "  batch    3: loss=2.545\n",
      "  batch    4: loss=3.083\n",
      "  batch    5: loss=2.738\n",
      "  batch    6: loss=3.172\n",
      "  batch    7: loss=2.901\n",
      "  batch    8: loss=2.843\n",
      "  batch    9: loss=2.862\n",
      "  batch   10: loss=2.895\n",
      "  batch   11: loss=2.833\n",
      "  batch   12: loss=2.938\n",
      "  batch   13: loss=2.847\n",
      "  batch   14: loss=2.827\n",
      "  batch   15: loss=2.426\n",
      "  batch   16: loss=3.219\n",
      "  batch   17: loss=2.996\n",
      "  batch   18: loss=3.401\n",
      "  batch   19: loss=2.749\n",
      "  batch   20: loss=3.161\n",
      "  batch   21: loss=2.748\n",
      "  batch   22: loss=3.031\n",
      "  batch   23: loss=2.832\n",
      "  batch   24: loss=2.851\n",
      "  batch   25: loss=3.118\n",
      "  batch   26: loss=2.706\n",
      "  batch   27: loss=2.572\n",
      "  batch   28: loss=2.789\n",
      "  batch   29: loss=2.647\n",
      "  batch   30: loss=2.792\n",
      "  batch   31: loss=2.674\n",
      "  batch   32: loss=3.247\n",
      "  batch   33: loss=2.967\n",
      "  batch   34: loss=2.912\n",
      "  batch   35: loss=3.322\n",
      "  batch   36: loss=2.910\n",
      "  batch   37: loss=3.201\n",
      "  batch   38: loss=3.287\n",
      "  batch   39: loss=3.030\n",
      "  batch   40: loss=3.130\n",
      "  batch   41: loss=2.974\n",
      "  batch   42: loss=2.656\n",
      "  batch   43: loss=3.030\n",
      "  batch   44: loss=3.107\n",
      "  batch   45: loss=2.804\n",
      "  batch   46: loss=2.944\n",
      "  batch   47: loss=3.032\n",
      "  batch   48: loss=3.349\n",
      "  batch   49: loss=2.802\n",
      "  batch   50: loss=3.271\n",
      "  batch   51: loss=2.840\n",
      "  batch   52: loss=2.799\n",
      "  batch   53: loss=2.956\n",
      "  batch   54: loss=3.368\n",
      "  batch   55: loss=2.825\n",
      "  batch   56: loss=2.852\n",
      "  batch   57: loss=2.730\n",
      "  batch   58: loss=2.747\n",
      "  batch   59: loss=3.298\n",
      "  batch   60: loss=2.976\n",
      "  batch   61: loss=2.655\n",
      "  batch   62: loss=3.136\n",
      "  batch   63: loss=2.511\n",
      "  batch   64: loss=2.584\n",
      "  batch   65: loss=3.201\n",
      "  batch   66: loss=2.956\n",
      "  batch   67: loss=2.908\n",
      "  batch   68: loss=2.316\n",
      "  batch   69: loss=3.326\n",
      "  batch   70: loss=3.263\n",
      "  batch   71: loss=2.795\n",
      "  batch   72: loss=3.064\n",
      "  batch   73: loss=3.277\n",
      "  batch   74: loss=2.932\n",
      "  batch   75: loss=3.062\n",
      "  batch   76: loss=2.632\n",
      "  batch   77: loss=2.852\n",
      "  batch   78: loss=2.884\n",
      "  batch   79: loss=3.279\n",
      "  batch   80: loss=2.804\n",
      "  batch   81: loss=3.149\n",
      "  batch   82: loss=3.246\n",
      "Testing on validation set\n",
      "  acc=0.350\n",
      "Training epoch 5\n",
      "  batch    1: loss=2.833\n",
      "  batch    2: loss=2.809\n",
      "  batch    3: loss=2.799\n",
      "  batch    4: loss=3.344\n",
      "  batch    5: loss=2.683\n",
      "  batch    6: loss=2.585\n",
      "  batch    7: loss=3.017\n",
      "  batch    8: loss=2.694\n",
      "  batch    9: loss=2.831\n",
      "  batch   10: loss=2.847\n",
      "  batch   11: loss=3.010\n",
      "  batch   12: loss=2.932\n",
      "  batch   13: loss=3.094\n",
      "  batch   14: loss=3.132\n",
      "  batch   15: loss=2.944\n",
      "  batch   16: loss=2.851\n",
      "  batch   17: loss=3.005\n",
      "  batch   18: loss=2.640\n",
      "  batch   19: loss=3.084\n",
      "  batch   20: loss=2.893\n",
      "  batch   21: loss=2.865\n",
      "  batch   22: loss=2.649\n",
      "  batch   23: loss=2.704\n",
      "  batch   24: loss=2.730\n",
      "  batch   25: loss=2.658\n",
      "  batch   26: loss=2.949\n",
      "  batch   27: loss=3.097\n",
      "  batch   28: loss=3.123\n",
      "  batch   29: loss=2.567\n",
      "  batch   30: loss=2.403\n",
      "  batch   31: loss=2.432\n",
      "  batch   32: loss=2.626\n",
      "  batch   33: loss=2.927\n",
      "  batch   34: loss=2.597\n",
      "  batch   35: loss=2.726\n",
      "  batch   36: loss=2.196\n",
      "  batch   37: loss=3.037\n",
      "  batch   38: loss=2.755\n",
      "  batch   39: loss=2.710\n",
      "  batch   40: loss=3.280\n",
      "  batch   41: loss=2.535\n",
      "  batch   42: loss=2.606\n",
      "  batch   43: loss=2.663\n",
      "  batch   44: loss=3.257\n",
      "  batch   45: loss=3.055\n",
      "  batch   46: loss=2.752\n",
      "  batch   47: loss=2.928\n",
      "  batch   48: loss=2.797\n",
      "  batch   49: loss=2.709\n",
      "  batch   50: loss=2.862\n",
      "  batch   51: loss=2.606\n",
      "  batch   52: loss=2.947\n",
      "  batch   53: loss=2.994\n",
      "  batch   54: loss=2.783\n",
      "  batch   55: loss=2.363\n",
      "  batch   56: loss=3.015\n",
      "  batch   57: loss=3.052\n",
      "  batch   58: loss=2.871\n",
      "  batch   59: loss=2.877\n",
      "  batch   60: loss=2.618\n",
      "  batch   61: loss=2.774\n",
      "  batch   62: loss=2.788\n",
      "  batch   63: loss=2.942\n",
      "  batch   64: loss=2.898\n",
      "  batch   65: loss=2.411\n",
      "  batch   66: loss=3.253\n",
      "  batch   67: loss=2.958\n",
      "  batch   68: loss=2.564\n",
      "  batch   69: loss=2.330\n",
      "  batch   70: loss=2.951\n",
      "  batch   71: loss=2.578\n",
      "  batch   72: loss=2.788\n",
      "  batch   73: loss=2.637\n",
      "  batch   74: loss=2.854\n",
      "  batch   75: loss=2.593\n",
      "  batch   76: loss=2.735\n",
      "  batch   77: loss=2.808\n",
      "  batch   78: loss=2.707\n",
      "  batch   79: loss=3.046\n",
      "  batch   80: loss=3.121\n",
      "  batch   81: loss=2.736\n",
      "  batch   82: loss=3.112\n",
      "Testing on validation set\n",
      "  acc=0.367\n",
      "Training epoch 6\n",
      "  batch    1: loss=2.828\n",
      "  batch    2: loss=2.573\n",
      "  batch    3: loss=2.399\n",
      "  batch    4: loss=2.615\n",
      "  batch    5: loss=2.448\n",
      "  batch    6: loss=2.873\n",
      "  batch    7: loss=2.499\n",
      "  batch    8: loss=2.916\n",
      "  batch    9: loss=2.801\n",
      "  batch   10: loss=2.731\n",
      "  batch   11: loss=2.691\n",
      "  batch   12: loss=2.776\n",
      "  batch   13: loss=2.824\n",
      "  batch   14: loss=2.785\n",
      "  batch   15: loss=2.467\n",
      "  batch   16: loss=2.686\n",
      "  batch   17: loss=2.638\n",
      "  batch   18: loss=2.941\n",
      "  batch   19: loss=2.634\n",
      "  batch   20: loss=2.475\n",
      "  batch   21: loss=2.805\n",
      "  batch   22: loss=2.703\n",
      "  batch   23: loss=2.482\n",
      "  batch   24: loss=2.487\n",
      "  batch   25: loss=2.577\n",
      "  batch   26: loss=2.572\n",
      "  batch   27: loss=2.772\n",
      "  batch   28: loss=2.755\n",
      "  batch   29: loss=2.432\n",
      "  batch   30: loss=2.504\n",
      "  batch   31: loss=2.498\n",
      "  batch   32: loss=2.620\n",
      "  batch   33: loss=2.740\n",
      "  batch   34: loss=2.648\n",
      "  batch   35: loss=2.863\n",
      "  batch   36: loss=2.635\n",
      "  batch   37: loss=2.705\n",
      "  batch   38: loss=2.347\n",
      "  batch   39: loss=2.811\n",
      "  batch   40: loss=2.717\n",
      "  batch   41: loss=2.202\n",
      "  batch   42: loss=2.415\n",
      "  batch   43: loss=2.268\n",
      "  batch   44: loss=2.580\n",
      "  batch   45: loss=2.675\n",
      "  batch   46: loss=2.767\n",
      "  batch   47: loss=2.547\n",
      "  batch   48: loss=2.491\n",
      "  batch   49: loss=2.879\n",
      "  batch   50: loss=3.110\n",
      "  batch   51: loss=2.844\n",
      "  batch   52: loss=2.600\n",
      "  batch   53: loss=2.790\n",
      "  batch   54: loss=2.885\n",
      "  batch   55: loss=2.326\n",
      "  batch   56: loss=3.030\n",
      "  batch   57: loss=2.521\n",
      "  batch   58: loss=2.590\n",
      "  batch   59: loss=2.829\n",
      "  batch   60: loss=2.608\n",
      "  batch   61: loss=2.556\n",
      "  batch   62: loss=2.536\n",
      "  batch   63: loss=3.220\n",
      "  batch   64: loss=2.965\n",
      "  batch   65: loss=2.858\n",
      "  batch   66: loss=2.787\n",
      "  batch   67: loss=2.724\n",
      "  batch   68: loss=2.363\n",
      "  batch   69: loss=2.715\n",
      "  batch   70: loss=2.877\n",
      "  batch   71: loss=2.465\n",
      "  batch   72: loss=2.466\n",
      "  batch   73: loss=2.639\n",
      "  batch   74: loss=2.730\n",
      "  batch   75: loss=2.833\n",
      "  batch   76: loss=2.218\n",
      "  batch   77: loss=2.614\n",
      "  batch   78: loss=2.472\n",
      "  batch   79: loss=2.805\n",
      "  batch   80: loss=3.144\n",
      "  batch   81: loss=2.425\n",
      "  batch   82: loss=1.987\n",
      "Testing on validation set\n",
      "  acc=0.406\n",
      "Training epoch 7\n",
      "  batch    1: loss=2.484\n",
      "  batch    2: loss=2.512\n",
      "  batch    3: loss=2.397\n",
      "  batch    4: loss=2.453\n",
      "  batch    5: loss=2.465\n",
      "  batch    6: loss=2.383\n",
      "  batch    7: loss=2.430\n",
      "  batch    8: loss=2.532\n",
      "  batch    9: loss=2.891\n",
      "  batch   10: loss=2.496\n",
      "  batch   11: loss=2.259\n",
      "  batch   12: loss=2.393\n",
      "  batch   13: loss=2.190\n",
      "  batch   14: loss=2.659\n",
      "  batch   15: loss=2.731\n",
      "  batch   16: loss=2.743\n",
      "  batch   17: loss=2.925\n",
      "  batch   18: loss=2.338\n",
      "  batch   19: loss=2.498\n",
      "  batch   20: loss=2.545\n",
      "  batch   21: loss=2.746\n",
      "  batch   22: loss=2.477\n",
      "  batch   23: loss=2.588\n",
      "  batch   24: loss=3.134\n",
      "  batch   25: loss=2.509\n",
      "  batch   26: loss=2.537\n",
      "  batch   27: loss=2.806\n",
      "  batch   28: loss=2.801\n",
      "  batch   29: loss=2.673\n",
      "  batch   30: loss=2.642\n",
      "  batch   31: loss=3.009\n",
      "  batch   32: loss=2.651\n",
      "  batch   33: loss=2.367\n",
      "  batch   34: loss=2.589\n",
      "  batch   35: loss=2.260\n",
      "  batch   36: loss=2.143\n",
      "  batch   37: loss=2.771\n",
      "  batch   38: loss=2.574\n",
      "  batch   39: loss=2.005\n",
      "  batch   40: loss=2.555\n",
      "  batch   41: loss=2.484\n",
      "  batch   42: loss=2.784\n",
      "  batch   43: loss=2.601\n",
      "  batch   44: loss=2.660\n",
      "  batch   45: loss=2.856\n",
      "  batch   46: loss=2.599\n",
      "  batch   47: loss=2.779\n",
      "  batch   48: loss=2.629\n",
      "  batch   49: loss=2.939\n",
      "  batch   50: loss=2.437\n",
      "  batch   51: loss=2.470\n",
      "  batch   52: loss=2.650\n",
      "  batch   53: loss=2.461\n",
      "  batch   54: loss=2.891\n",
      "  batch   55: loss=3.035\n",
      "  batch   56: loss=2.296\n",
      "  batch   57: loss=2.728\n",
      "  batch   58: loss=2.658\n",
      "  batch   59: loss=2.393\n",
      "  batch   60: loss=2.334\n",
      "  batch   61: loss=2.724\n",
      "  batch   62: loss=2.507\n",
      "  batch   63: loss=2.714\n",
      "  batch   64: loss=2.721\n",
      "  batch   65: loss=2.677\n",
      "  batch   66: loss=2.665\n",
      "  batch   67: loss=2.628\n",
      "  batch   68: loss=2.833\n",
      "  batch   69: loss=2.344\n",
      "  batch   70: loss=3.007\n",
      "  batch   71: loss=2.454\n",
      "  batch   72: loss=2.829\n",
      "  batch   73: loss=2.227\n",
      "  batch   74: loss=2.359\n",
      "  batch   75: loss=2.561\n",
      "  batch   76: loss=2.617\n",
      "  batch   77: loss=2.553\n",
      "  batch   78: loss=2.421\n",
      "  batch   79: loss=2.665\n",
      "  batch   80: loss=2.471\n",
      "  batch   81: loss=3.022\n",
      "  batch   82: loss=2.453\n",
      "Testing on validation set\n",
      "  acc=0.422\n",
      "Training epoch 8\n",
      "  batch    1: loss=2.438\n",
      "  batch    2: loss=2.246\n",
      "  batch    3: loss=2.517\n",
      "  batch    4: loss=2.319\n",
      "  batch    5: loss=2.408\n",
      "  batch    6: loss=2.455\n",
      "  batch    7: loss=2.853\n",
      "  batch    8: loss=2.543\n",
      "  batch    9: loss=2.818\n",
      "  batch   10: loss=2.550\n",
      "  batch   11: loss=2.688\n",
      "  batch   12: loss=2.469\n",
      "  batch   13: loss=2.645\n",
      "  batch   14: loss=2.381\n",
      "  batch   15: loss=2.540\n",
      "  batch   16: loss=2.420\n",
      "  batch   17: loss=2.526\n",
      "  batch   18: loss=2.437\n",
      "  batch   19: loss=2.786\n",
      "  batch   20: loss=2.338\n",
      "  batch   21: loss=2.682\n",
      "  batch   22: loss=2.164\n",
      "  batch   23: loss=2.207\n",
      "  batch   24: loss=2.695\n",
      "  batch   25: loss=2.473\n",
      "  batch   26: loss=2.241\n",
      "  batch   27: loss=2.587\n",
      "  batch   28: loss=2.621\n",
      "  batch   29: loss=2.732\n",
      "  batch   30: loss=2.637\n",
      "  batch   31: loss=2.449\n",
      "  batch   32: loss=2.058\n",
      "  batch   33: loss=2.442\n",
      "  batch   34: loss=2.551\n",
      "  batch   35: loss=2.881\n",
      "  batch   36: loss=2.345\n",
      "  batch   37: loss=2.113\n",
      "  batch   38: loss=2.667\n",
      "  batch   39: loss=2.584\n",
      "  batch   40: loss=2.505\n",
      "  batch   41: loss=1.999\n",
      "  batch   42: loss=2.514\n",
      "  batch   43: loss=2.390\n",
      "  batch   44: loss=2.553\n",
      "  batch   45: loss=2.809\n",
      "  batch   46: loss=2.192\n",
      "  batch   47: loss=2.445\n",
      "  batch   48: loss=2.680\n",
      "  batch   49: loss=2.456\n",
      "  batch   50: loss=2.377\n",
      "  batch   51: loss=2.434\n",
      "  batch   52: loss=2.674\n",
      "  batch   53: loss=2.474\n",
      "  batch   54: loss=2.416\n",
      "  batch   55: loss=2.325\n",
      "  batch   56: loss=2.825\n",
      "  batch   57: loss=2.349\n",
      "  batch   58: loss=2.267\n",
      "  batch   59: loss=2.838\n",
      "  batch   60: loss=2.645\n",
      "  batch   61: loss=2.305\n",
      "  batch   62: loss=2.659\n",
      "  batch   63: loss=2.891\n",
      "  batch   64: loss=2.535\n",
      "  batch   65: loss=2.512\n",
      "  batch   66: loss=2.544\n",
      "  batch   67: loss=2.693\n",
      "  batch   68: loss=2.628\n",
      "  batch   69: loss=2.365\n",
      "  batch   70: loss=2.091\n",
      "  batch   71: loss=2.302\n",
      "  batch   72: loss=2.395\n",
      "  batch   73: loss=2.731\n",
      "  batch   74: loss=2.148\n",
      "  batch   75: loss=2.617\n",
      "  batch   76: loss=2.274\n",
      "  batch   77: loss=2.590\n",
      "  batch   78: loss=2.682\n",
      "  batch   79: loss=2.323\n",
      "  batch   80: loss=2.287\n",
      "  batch   81: loss=2.764\n",
      "  batch   82: loss=2.409\n",
      "Testing on validation set\n",
      "  acc=0.443\n",
      "Training epoch 9\n",
      "  batch    1: loss=2.259\n",
      "  batch    2: loss=2.027\n",
      "  batch    3: loss=1.844\n",
      "  batch    4: loss=2.479\n",
      "  batch    5: loss=2.653\n",
      "  batch    6: loss=2.292\n",
      "  batch    7: loss=2.178\n",
      "  batch    8: loss=2.444\n",
      "  batch    9: loss=2.486\n",
      "  batch   10: loss=2.373\n",
      "  batch   11: loss=2.288\n",
      "  batch   12: loss=1.957\n",
      "  batch   13: loss=2.650\n",
      "  batch   14: loss=2.431\n",
      "  batch   15: loss=2.647\n",
      "  batch   16: loss=2.280\n",
      "  batch   17: loss=2.119\n",
      "  batch   18: loss=2.400\n",
      "  batch   19: loss=2.474\n",
      "  batch   20: loss=1.984\n",
      "  batch   21: loss=2.541\n",
      "  batch   22: loss=2.553\n",
      "  batch   23: loss=2.208\n",
      "  batch   24: loss=1.890\n",
      "  batch   25: loss=2.218\n",
      "  batch   26: loss=2.164\n",
      "  batch   27: loss=2.101\n",
      "  batch   28: loss=2.220\n",
      "  batch   29: loss=2.256\n",
      "  batch   30: loss=2.173\n",
      "  batch   31: loss=2.316\n",
      "  batch   32: loss=2.738\n",
      "  batch   33: loss=2.203\n",
      "  batch   34: loss=1.998\n",
      "  batch   35: loss=2.241\n",
      "  batch   36: loss=2.609\n",
      "  batch   37: loss=2.128\n",
      "  batch   38: loss=2.852\n",
      "  batch   39: loss=2.365\n",
      "  batch   40: loss=2.549\n",
      "  batch   41: loss=1.906\n",
      "  batch   42: loss=2.427\n",
      "  batch   43: loss=2.227\n",
      "  batch   44: loss=2.471\n",
      "  batch   45: loss=2.480\n",
      "  batch   46: loss=2.436\n",
      "  batch   47: loss=2.756\n",
      "  batch   48: loss=2.426\n",
      "  batch   49: loss=2.421\n",
      "  batch   50: loss=2.297\n",
      "  batch   51: loss=2.085\n",
      "  batch   52: loss=2.874\n",
      "  batch   53: loss=2.656\n",
      "  batch   54: loss=2.383\n",
      "  batch   55: loss=2.448\n",
      "  batch   56: loss=2.507\n",
      "  batch   57: loss=2.541\n",
      "  batch   58: loss=2.355\n",
      "  batch   59: loss=2.298\n",
      "  batch   60: loss=2.184\n",
      "  batch   61: loss=2.326\n",
      "  batch   62: loss=2.596\n",
      "  batch   63: loss=2.822\n",
      "  batch   64: loss=2.627\n",
      "  batch   65: loss=2.367\n",
      "  batch   66: loss=2.253\n",
      "  batch   67: loss=2.212\n",
      "  batch   68: loss=2.153\n",
      "  batch   69: loss=2.479\n",
      "  batch   70: loss=2.402\n",
      "  batch   71: loss=2.718\n",
      "  batch   72: loss=2.412\n",
      "  batch   73: loss=2.251\n",
      "  batch   74: loss=2.306\n",
      "  batch   75: loss=2.543\n",
      "  batch   76: loss=2.206\n",
      "  batch   77: loss=2.224\n",
      "  batch   78: loss=3.047\n",
      "  batch   79: loss=2.301\n",
      "  batch   80: loss=2.664\n",
      "  batch   81: loss=2.194\n",
      "  batch   82: loss=1.711\n",
      "Testing on validation set\n",
      "  acc=0.439\n",
      "Training epoch 10\n",
      "  batch    1: loss=2.234\n",
      "  batch    2: loss=1.865\n",
      "  batch    3: loss=2.022\n",
      "  batch    4: loss=2.290\n",
      "  batch    5: loss=2.142\n",
      "  batch    6: loss=1.762\n",
      "  batch    7: loss=2.657\n",
      "  batch    8: loss=2.181\n",
      "  batch    9: loss=2.461\n",
      "  batch   10: loss=2.123\n",
      "  batch   11: loss=2.537\n",
      "  batch   12: loss=2.163\n",
      "  batch   13: loss=1.981\n",
      "  batch   14: loss=2.142\n",
      "  batch   15: loss=2.253\n",
      "  batch   16: loss=2.483\n",
      "  batch   17: loss=2.358\n",
      "  batch   18: loss=2.586\n",
      "  batch   19: loss=2.242\n",
      "  batch   20: loss=2.617\n",
      "  batch   21: loss=2.289\n",
      "  batch   22: loss=2.281\n",
      "  batch   23: loss=2.198\n",
      "  batch   24: loss=2.171\n",
      "  batch   25: loss=2.528\n",
      "  batch   26: loss=2.107\n",
      "  batch   27: loss=2.484\n",
      "  batch   28: loss=2.762\n",
      "  batch   29: loss=1.934\n",
      "  batch   30: loss=2.097\n",
      "  batch   31: loss=2.158\n",
      "  batch   32: loss=2.476\n",
      "  batch   33: loss=2.009\n",
      "  batch   34: loss=2.299\n",
      "  batch   35: loss=2.025\n",
      "  batch   36: loss=2.605\n",
      "  batch   37: loss=2.339\n",
      "  batch   38: loss=2.312\n",
      "  batch   39: loss=1.945\n",
      "  batch   40: loss=2.596\n",
      "  batch   41: loss=2.391\n",
      "  batch   42: loss=2.273\n",
      "  batch   43: loss=2.134\n",
      "  batch   44: loss=2.236\n",
      "  batch   45: loss=2.192\n",
      "  batch   46: loss=2.170\n",
      "  batch   47: loss=2.047\n",
      "  batch   48: loss=2.452\n",
      "  batch   49: loss=2.229\n",
      "  batch   50: loss=2.283\n",
      "  batch   51: loss=2.741\n",
      "  batch   52: loss=2.330\n",
      "  batch   53: loss=2.061\n",
      "  batch   54: loss=2.248\n",
      "  batch   55: loss=2.192\n",
      "  batch   56: loss=2.231\n",
      "  batch   57: loss=1.976\n",
      "  batch   58: loss=2.161\n",
      "  batch   59: loss=2.316\n",
      "  batch   60: loss=1.809\n",
      "  batch   61: loss=2.733\n",
      "  batch   62: loss=2.301\n",
      "  batch   63: loss=2.474\n",
      "  batch   64: loss=2.442\n",
      "  batch   65: loss=2.221\n",
      "  batch   66: loss=2.646\n",
      "  batch   67: loss=2.068\n",
      "  batch   68: loss=2.123\n",
      "  batch   69: loss=2.297\n",
      "  batch   70: loss=2.160\n",
      "  batch   71: loss=2.147\n",
      "  batch   72: loss=1.991\n",
      "  batch   73: loss=2.117\n",
      "  batch   74: loss=2.725\n",
      "  batch   75: loss=1.966\n",
      "  batch   76: loss=2.096\n",
      "  batch   77: loss=2.289\n",
      "  batch   78: loss=2.273\n",
      "  batch   79: loss=2.075\n",
      "  batch   80: loss=2.163\n",
      "  batch   81: loss=2.188\n",
      "  batch   82: loss=3.283\n",
      "Testing on validation set\n",
      "  acc=0.447\n",
      "Training epoch 11\n",
      "  batch    1: loss=2.101\n",
      "  batch    2: loss=1.875\n",
      "  batch    3: loss=2.190\n",
      "  batch    4: loss=2.139\n",
      "  batch    5: loss=2.112\n",
      "  batch    6: loss=2.220\n",
      "  batch    7: loss=2.255\n",
      "  batch    8: loss=2.058\n",
      "  batch    9: loss=2.274\n",
      "  batch   10: loss=2.198\n",
      "  batch   11: loss=1.954\n",
      "  batch   12: loss=2.013\n",
      "  batch   13: loss=1.946\n",
      "  batch   14: loss=2.120\n",
      "  batch   15: loss=2.447\n",
      "  batch   16: loss=2.185\n",
      "  batch   17: loss=2.307\n",
      "  batch   18: loss=2.149\n",
      "  batch   19: loss=2.440\n",
      "  batch   20: loss=2.102\n",
      "  batch   21: loss=2.249\n",
      "  batch   22: loss=2.314\n",
      "  batch   23: loss=2.272\n",
      "  batch   24: loss=2.921\n",
      "  batch   25: loss=2.151\n",
      "  batch   26: loss=1.884\n",
      "  batch   27: loss=2.488\n",
      "  batch   28: loss=2.018\n",
      "  batch   29: loss=1.774\n",
      "  batch   30: loss=2.708\n",
      "  batch   31: loss=2.358\n",
      "  batch   32: loss=2.040\n",
      "  batch   33: loss=2.640\n",
      "  batch   34: loss=2.638\n",
      "  batch   35: loss=2.531\n",
      "  batch   36: loss=2.161\n",
      "  batch   37: loss=2.396\n",
      "  batch   38: loss=2.294\n",
      "  batch   39: loss=2.070\n",
      "  batch   40: loss=1.929\n",
      "  batch   41: loss=2.538\n",
      "  batch   42: loss=2.854\n",
      "  batch   43: loss=2.435\n",
      "  batch   44: loss=2.637\n",
      "  batch   45: loss=2.427\n",
      "  batch   46: loss=2.425\n",
      "  batch   47: loss=1.829\n",
      "  batch   48: loss=2.175\n",
      "  batch   49: loss=2.392\n",
      "  batch   50: loss=2.502\n",
      "  batch   51: loss=2.077\n",
      "  batch   52: loss=2.027\n",
      "  batch   53: loss=1.689\n",
      "  batch   54: loss=2.235\n",
      "  batch   55: loss=2.310\n",
      "  batch   56: loss=1.924\n",
      "  batch   57: loss=2.039\n",
      "  batch   58: loss=2.145\n",
      "  batch   59: loss=2.614\n",
      "  batch   60: loss=2.244\n",
      "  batch   61: loss=2.250\n",
      "  batch   62: loss=2.312\n",
      "  batch   63: loss=2.426\n",
      "  batch   64: loss=2.421\n",
      "  batch   65: loss=2.248\n",
      "  batch   66: loss=2.556\n",
      "  batch   67: loss=2.388\n",
      "  batch   68: loss=1.848\n",
      "  batch   69: loss=2.367\n",
      "  batch   70: loss=2.191\n",
      "  batch   71: loss=2.140\n",
      "  batch   72: loss=1.959\n",
      "  batch   73: loss=1.876\n",
      "  batch   74: loss=2.149\n",
      "  batch   75: loss=2.023\n",
      "  batch   76: loss=2.400\n",
      "  batch   77: loss=2.541\n",
      "  batch   78: loss=2.665\n",
      "  batch   79: loss=2.157\n",
      "  batch   80: loss=1.901\n",
      "  batch   81: loss=2.073\n",
      "  batch   82: loss=2.990\n",
      "Testing on validation set\n",
      "  acc=0.472\n",
      "Training epoch 12\n",
      "  batch    1: loss=1.999\n",
      "  batch    2: loss=1.913\n",
      "  batch    3: loss=2.057\n",
      "  batch    4: loss=2.660\n",
      "  batch    5: loss=1.918\n",
      "  batch    6: loss=2.116\n",
      "  batch    7: loss=2.204\n",
      "  batch    8: loss=2.019\n",
      "  batch    9: loss=2.077\n",
      "  batch   10: loss=1.937\n",
      "  batch   11: loss=2.705\n",
      "  batch   12: loss=2.136\n",
      "  batch   13: loss=2.024\n",
      "  batch   14: loss=2.193\n",
      "  batch   15: loss=2.266\n",
      "  batch   16: loss=2.251\n",
      "  batch   17: loss=2.583\n",
      "  batch   18: loss=1.980\n",
      "  batch   19: loss=1.946\n",
      "  batch   20: loss=1.952\n",
      "  batch   21: loss=2.207\n",
      "  batch   22: loss=2.137\n",
      "  batch   23: loss=2.346\n",
      "  batch   24: loss=2.412\n",
      "  batch   25: loss=2.077\n",
      "  batch   26: loss=2.182\n",
      "  batch   27: loss=1.948\n",
      "  batch   28: loss=2.402\n",
      "  batch   29: loss=2.180\n",
      "  batch   30: loss=1.937\n",
      "  batch   31: loss=2.190\n",
      "  batch   32: loss=1.956\n",
      "  batch   33: loss=2.339\n",
      "  batch   34: loss=2.024\n",
      "  batch   35: loss=1.902\n",
      "  batch   36: loss=1.941\n",
      "  batch   37: loss=2.226\n",
      "  batch   38: loss=2.107\n",
      "  batch   39: loss=2.255\n",
      "  batch   40: loss=2.271\n",
      "  batch   41: loss=2.281\n",
      "  batch   42: loss=2.397\n",
      "  batch   43: loss=1.965\n",
      "  batch   44: loss=1.717\n",
      "  batch   45: loss=2.007\n",
      "  batch   46: loss=2.200\n",
      "  batch   47: loss=2.087\n",
      "  batch   48: loss=1.513\n",
      "  batch   49: loss=2.318\n",
      "  batch   50: loss=2.090\n",
      "  batch   51: loss=2.475\n",
      "  batch   52: loss=2.363\n",
      "  batch   53: loss=2.165\n",
      "  batch   54: loss=2.294\n",
      "  batch   55: loss=2.406\n",
      "  batch   56: loss=2.095\n",
      "  batch   57: loss=2.008\n",
      "  batch   58: loss=2.065\n",
      "  batch   59: loss=2.058\n",
      "  batch   60: loss=2.087\n",
      "  batch   61: loss=2.036\n",
      "  batch   62: loss=2.680\n",
      "  batch   63: loss=2.001\n",
      "  batch   64: loss=2.076\n",
      "  batch   65: loss=1.854\n",
      "  batch   66: loss=2.035\n",
      "  batch   67: loss=2.580\n",
      "  batch   68: loss=2.141\n",
      "  batch   69: loss=2.171\n",
      "  batch   70: loss=2.184\n",
      "  batch   71: loss=2.088\n",
      "  batch   72: loss=2.277\n",
      "  batch   73: loss=2.269\n",
      "  batch   74: loss=1.876\n",
      "  batch   75: loss=2.372\n",
      "  batch   76: loss=2.006\n",
      "  batch   77: loss=1.667\n",
      "  batch   78: loss=2.149\n",
      "  batch   79: loss=2.350\n",
      "  batch   80: loss=2.438\n",
      "  batch   81: loss=2.325\n",
      "  batch   82: loss=2.267\n",
      "Testing on validation set\n",
      "  acc=0.478\n",
      "Training epoch 13\n",
      "  batch    1: loss=2.075\n",
      "  batch    2: loss=1.846\n",
      "  batch    3: loss=1.981\n",
      "  batch    4: loss=2.212\n",
      "  batch    5: loss=2.013\n",
      "  batch    6: loss=1.702\n",
      "  batch    7: loss=1.907\n",
      "  batch    8: loss=1.985\n",
      "  batch    9: loss=2.055\n",
      "  batch   10: loss=2.163\n",
      "  batch   11: loss=2.011\n",
      "  batch   12: loss=2.186\n",
      "  batch   13: loss=2.198\n",
      "  batch   14: loss=1.962\n",
      "  batch   15: loss=2.042\n",
      "  batch   16: loss=2.144\n",
      "  batch   17: loss=2.165\n",
      "  batch   18: loss=1.848\n",
      "  batch   19: loss=2.288\n",
      "  batch   20: loss=2.253\n",
      "  batch   21: loss=2.248\n",
      "  batch   22: loss=1.938\n",
      "  batch   23: loss=1.753\n",
      "  batch   24: loss=2.072\n",
      "  batch   25: loss=2.233\n",
      "  batch   26: loss=2.048\n",
      "  batch   27: loss=2.467\n",
      "  batch   28: loss=2.555\n",
      "  batch   29: loss=1.873\n",
      "  batch   30: loss=1.987\n",
      "  batch   31: loss=2.028\n",
      "  batch   32: loss=2.065\n",
      "  batch   33: loss=2.082\n",
      "  batch   34: loss=1.874\n",
      "  batch   35: loss=1.929\n",
      "  batch   36: loss=1.976\n",
      "  batch   37: loss=1.964\n",
      "  batch   38: loss=2.161\n",
      "  batch   39: loss=1.809\n",
      "  batch   40: loss=2.280\n",
      "  batch   41: loss=2.340\n",
      "  batch   42: loss=1.867\n",
      "  batch   43: loss=2.044\n",
      "  batch   44: loss=1.861\n",
      "  batch   45: loss=2.191\n",
      "  batch   46: loss=2.121\n",
      "  batch   47: loss=1.787\n",
      "  batch   48: loss=2.118\n",
      "  batch   49: loss=1.818\n",
      "  batch   50: loss=2.332\n",
      "  batch   51: loss=2.250\n",
      "  batch   52: loss=2.145\n",
      "  batch   53: loss=1.874\n",
      "  batch   54: loss=2.249\n",
      "  batch   55: loss=2.149\n",
      "  batch   56: loss=2.162\n",
      "  batch   57: loss=2.124\n",
      "  batch   58: loss=2.182\n",
      "  batch   59: loss=2.345\n",
      "  batch   60: loss=1.821\n",
      "  batch   61: loss=1.991\n",
      "  batch   62: loss=1.985\n",
      "  batch   63: loss=2.092\n",
      "  batch   64: loss=2.050\n",
      "  batch   65: loss=1.688\n",
      "  batch   66: loss=2.074\n",
      "  batch   67: loss=1.973\n",
      "  batch   68: loss=2.244\n",
      "  batch   69: loss=1.853\n",
      "  batch   70: loss=2.270\n",
      "  batch   71: loss=2.251\n",
      "  batch   72: loss=2.327\n",
      "  batch   73: loss=1.954\n",
      "  batch   74: loss=2.696\n",
      "  batch   75: loss=2.071\n",
      "  batch   76: loss=2.598\n",
      "  batch   77: loss=2.324\n",
      "  batch   78: loss=1.858\n",
      "  batch   79: loss=1.991\n",
      "  batch   80: loss=2.113\n",
      "  batch   81: loss=1.866\n",
      "  batch   82: loss=3.036\n",
      "Testing on validation set\n",
      "  acc=0.518\n",
      "Training epoch 14\n",
      "  batch    1: loss=1.932\n",
      "  batch    2: loss=1.905\n",
      "  batch    3: loss=1.867\n",
      "  batch    4: loss=1.756\n",
      "  batch    5: loss=2.032\n",
      "  batch    6: loss=2.271\n",
      "  batch    7: loss=1.953\n",
      "  batch    8: loss=1.935\n",
      "  batch    9: loss=2.110\n",
      "  batch   10: loss=1.986\n",
      "  batch   11: loss=1.602\n",
      "  batch   12: loss=2.055\n",
      "  batch   13: loss=1.944\n",
      "  batch   14: loss=2.161\n",
      "  batch   15: loss=1.868\n",
      "  batch   16: loss=2.003\n",
      "  batch   17: loss=2.053\n",
      "  batch   18: loss=1.754\n",
      "  batch   19: loss=2.235\n",
      "  batch   20: loss=1.489\n",
      "  batch   21: loss=1.579\n",
      "  batch   22: loss=1.722\n",
      "  batch   23: loss=1.692\n",
      "  batch   24: loss=2.276\n",
      "  batch   25: loss=2.089\n",
      "  batch   26: loss=1.647\n",
      "  batch   27: loss=1.939\n",
      "  batch   28: loss=2.363\n",
      "  batch   29: loss=2.032\n",
      "  batch   30: loss=2.501\n",
      "  batch   31: loss=2.077\n",
      "  batch   32: loss=2.060\n",
      "  batch   33: loss=2.062\n",
      "  batch   34: loss=1.987\n",
      "  batch   35: loss=1.822\n",
      "  batch   36: loss=1.871\n",
      "  batch   37: loss=2.244\n",
      "  batch   38: loss=2.325\n",
      "  batch   39: loss=1.821\n",
      "  batch   40: loss=2.399\n",
      "  batch   41: loss=2.109\n",
      "  batch   42: loss=1.957\n",
      "  batch   43: loss=2.057\n",
      "  batch   44: loss=1.766\n",
      "  batch   45: loss=2.120\n",
      "  batch   46: loss=1.986\n",
      "  batch   47: loss=1.992\n",
      "  batch   48: loss=1.795\n",
      "  batch   49: loss=1.879\n",
      "  batch   50: loss=1.960\n",
      "  batch   51: loss=1.742\n",
      "  batch   52: loss=1.685\n",
      "  batch   53: loss=1.997\n",
      "  batch   54: loss=1.610\n",
      "  batch   55: loss=2.327\n",
      "  batch   56: loss=1.791\n",
      "  batch   57: loss=2.131\n",
      "  batch   58: loss=2.194\n",
      "  batch   59: loss=2.095\n",
      "  batch   60: loss=2.197\n",
      "  batch   61: loss=1.637\n",
      "  batch   62: loss=1.856\n",
      "  batch   63: loss=2.137\n",
      "  batch   64: loss=2.261\n",
      "  batch   65: loss=1.851\n",
      "  batch   66: loss=2.203\n",
      "  batch   67: loss=1.978\n",
      "  batch   68: loss=1.890\n",
      "  batch   69: loss=1.905\n",
      "  batch   70: loss=2.576\n",
      "  batch   71: loss=2.039\n",
      "  batch   72: loss=1.980\n",
      "  batch   73: loss=1.958\n",
      "  batch   74: loss=2.257\n",
      "  batch   75: loss=2.194\n",
      "  batch   76: loss=2.357\n",
      "  batch   77: loss=1.709\n",
      "  batch   78: loss=1.913\n",
      "  batch   79: loss=2.169\n",
      "  batch   80: loss=2.415\n",
      "  batch   81: loss=2.434\n",
      "  batch   82: loss=2.071\n",
      "Testing on validation set\n",
      "  acc=0.513\n",
      "Training epoch 15\n",
      "  batch    1: loss=2.240\n",
      "  batch    2: loss=1.786\n",
      "  batch    3: loss=2.301\n",
      "  batch    4: loss=1.813\n",
      "  batch    5: loss=2.066\n",
      "  batch    6: loss=1.937\n",
      "  batch    7: loss=1.565\n",
      "  batch    8: loss=1.929\n",
      "  batch    9: loss=1.914\n",
      "  batch   10: loss=2.248\n",
      "  batch   11: loss=1.906\n",
      "  batch   12: loss=1.974\n",
      "  batch   13: loss=1.995\n",
      "  batch   14: loss=1.721\n",
      "  batch   15: loss=1.650\n",
      "  batch   16: loss=2.300\n",
      "  batch   17: loss=1.927\n",
      "  batch   18: loss=1.780\n",
      "  batch   19: loss=1.758\n",
      "  batch   20: loss=2.294\n",
      "  batch   21: loss=2.150\n",
      "  batch   22: loss=1.617\n",
      "  batch   23: loss=2.137\n",
      "  batch   24: loss=2.144\n",
      "  batch   25: loss=2.100\n",
      "  batch   26: loss=1.842\n",
      "  batch   27: loss=1.968\n",
      "  batch   28: loss=1.568\n",
      "  batch   29: loss=1.944\n",
      "  batch   30: loss=2.487\n",
      "  batch   31: loss=1.935\n",
      "  batch   32: loss=1.863\n",
      "  batch   33: loss=1.764\n",
      "  batch   34: loss=1.728\n",
      "  batch   35: loss=2.007\n",
      "  batch   36: loss=1.817\n",
      "  batch   37: loss=1.535\n",
      "  batch   38: loss=2.061\n",
      "  batch   39: loss=2.163\n",
      "  batch   40: loss=1.890\n",
      "  batch   41: loss=1.837\n",
      "  batch   42: loss=2.001\n",
      "  batch   43: loss=1.600\n",
      "  batch   44: loss=2.086\n",
      "  batch   45: loss=2.336\n",
      "  batch   46: loss=2.042\n",
      "  batch   47: loss=2.127\n",
      "  batch   48: loss=1.719\n",
      "  batch   49: loss=1.991\n",
      "  batch   50: loss=1.903\n",
      "  batch   51: loss=1.917\n",
      "  batch   52: loss=2.156\n",
      "  batch   53: loss=1.970\n",
      "  batch   54: loss=1.878\n",
      "  batch   55: loss=2.512\n",
      "  batch   56: loss=2.092\n",
      "  batch   57: loss=1.799\n",
      "  batch   58: loss=2.090\n",
      "  batch   59: loss=2.064\n",
      "  batch   60: loss=2.098\n",
      "  batch   61: loss=1.826\n",
      "  batch   62: loss=1.529\n",
      "  batch   63: loss=1.938\n",
      "  batch   64: loss=1.771\n",
      "  batch   65: loss=1.795\n",
      "  batch   66: loss=1.911\n",
      "  batch   67: loss=1.976\n",
      "  batch   68: loss=1.773\n",
      "  batch   69: loss=2.524\n",
      "  batch   70: loss=1.797\n",
      "  batch   71: loss=2.558\n",
      "  batch   72: loss=1.755\n",
      "  batch   73: loss=2.026\n",
      "  batch   74: loss=1.851\n",
      "  batch   75: loss=2.091\n",
      "  batch   76: loss=2.282\n",
      "  batch   77: loss=1.754\n",
      "  batch   78: loss=1.974\n",
      "  batch   79: loss=2.057\n",
      "  batch   80: loss=1.496\n",
      "  batch   81: loss=2.111\n",
      "  batch   82: loss=1.962\n",
      "Testing on validation set\n",
      "  acc=0.550\n",
      "Training epoch 16\n",
      "  batch    1: loss=1.832\n",
      "  batch    2: loss=1.503\n",
      "  batch    3: loss=2.046\n",
      "  batch    4: loss=2.129\n",
      "  batch    5: loss=1.806\n",
      "  batch    6: loss=1.866\n",
      "  batch    7: loss=1.945\n",
      "  batch    8: loss=2.082\n",
      "  batch    9: loss=2.040\n",
      "  batch   10: loss=1.727\n",
      "  batch   11: loss=1.805\n",
      "  batch   12: loss=1.697\n",
      "  batch   13: loss=1.741\n",
      "  batch   14: loss=1.762\n",
      "  batch   15: loss=1.757\n",
      "  batch   16: loss=2.551\n",
      "  batch   17: loss=1.756\n",
      "  batch   18: loss=1.536\n",
      "  batch   19: loss=2.206\n",
      "  batch   20: loss=1.505\n",
      "  batch   21: loss=1.856\n",
      "  batch   22: loss=2.116\n",
      "  batch   23: loss=1.675\n",
      "  batch   24: loss=2.287\n",
      "  batch   25: loss=1.864\n",
      "  batch   26: loss=2.124\n",
      "  batch   27: loss=1.825\n",
      "  batch   28: loss=1.754\n",
      "  batch   29: loss=2.130\n",
      "  batch   30: loss=1.976\n",
      "  batch   31: loss=1.652\n",
      "  batch   32: loss=1.680\n",
      "  batch   33: loss=2.076\n",
      "  batch   34: loss=2.085\n",
      "  batch   35: loss=1.920\n",
      "  batch   36: loss=1.820\n",
      "  batch   37: loss=2.284\n",
      "  batch   38: loss=1.964\n",
      "  batch   39: loss=1.824\n",
      "  batch   40: loss=2.053\n",
      "  batch   41: loss=1.864\n",
      "  batch   42: loss=1.793\n",
      "  batch   43: loss=2.155\n",
      "  batch   44: loss=1.916\n",
      "  batch   45: loss=1.734\n",
      "  batch   46: loss=1.689\n",
      "  batch   47: loss=1.839\n",
      "  batch   48: loss=2.179\n",
      "  batch   49: loss=1.973\n",
      "  batch   50: loss=1.951\n",
      "  batch   51: loss=1.617\n",
      "  batch   52: loss=1.923\n",
      "  batch   53: loss=2.093\n",
      "  batch   54: loss=2.110\n",
      "  batch   55: loss=1.888\n",
      "  batch   56: loss=2.167\n",
      "  batch   57: loss=2.027\n",
      "  batch   58: loss=1.745\n",
      "  batch   59: loss=1.967\n",
      "  batch   60: loss=1.885\n",
      "  batch   61: loss=1.980\n",
      "  batch   62: loss=2.055\n",
      "  batch   63: loss=1.837\n",
      "  batch   64: loss=1.948\n",
      "  batch   65: loss=1.689\n",
      "  batch   66: loss=2.168\n",
      "  batch   67: loss=2.368\n",
      "  batch   68: loss=1.591\n",
      "  batch   69: loss=1.949\n",
      "  batch   70: loss=1.956\n",
      "  batch   71: loss=2.175\n",
      "  batch   72: loss=1.536\n",
      "  batch   73: loss=2.182\n",
      "  batch   74: loss=1.493\n",
      "  batch   75: loss=2.034\n",
      "  batch   76: loss=2.023\n",
      "  batch   77: loss=2.143\n",
      "  batch   78: loss=1.667\n",
      "  batch   79: loss=2.062\n",
      "  batch   80: loss=2.064\n",
      "  batch   81: loss=1.969\n",
      "  batch   82: loss=2.817\n",
      "Testing on validation set\n",
      "  acc=0.518\n",
      "Training epoch 17\n",
      "  batch    1: loss=1.605\n",
      "  batch    2: loss=1.464\n",
      "  batch    3: loss=1.519\n",
      "  batch    4: loss=1.977\n",
      "  batch    5: loss=1.767\n",
      "  batch    6: loss=1.722\n",
      "  batch    7: loss=1.466\n",
      "  batch    8: loss=1.967\n",
      "  batch    9: loss=1.953\n",
      "  batch   10: loss=2.033\n",
      "  batch   11: loss=1.537\n",
      "  batch   12: loss=1.810\n",
      "  batch   13: loss=1.860\n",
      "  batch   14: loss=1.874\n",
      "  batch   15: loss=2.364\n",
      "  batch   16: loss=1.970\n",
      "  batch   17: loss=1.844\n",
      "  batch   18: loss=2.096\n",
      "  batch   19: loss=2.345\n",
      "  batch   20: loss=1.784\n",
      "  batch   21: loss=1.649\n",
      "  batch   22: loss=1.781\n",
      "  batch   23: loss=2.057\n",
      "  batch   24: loss=1.729\n",
      "  batch   25: loss=1.586\n",
      "  batch   26: loss=1.849\n",
      "  batch   27: loss=1.959\n",
      "  batch   28: loss=1.687\n",
      "  batch   29: loss=1.580\n",
      "  batch   30: loss=1.434\n",
      "  batch   31: loss=2.489\n",
      "  batch   32: loss=2.045\n",
      "  batch   33: loss=1.718\n",
      "  batch   34: loss=1.708\n",
      "  batch   35: loss=1.851\n",
      "  batch   36: loss=1.464\n",
      "  batch   37: loss=1.621\n",
      "  batch   38: loss=1.770\n",
      "  batch   39: loss=1.685\n",
      "  batch   40: loss=1.863\n",
      "  batch   41: loss=1.968\n",
      "  batch   42: loss=1.832\n",
      "  batch   43: loss=2.151\n",
      "  batch   44: loss=1.879\n",
      "  batch   45: loss=1.848\n",
      "  batch   46: loss=2.162\n",
      "  batch   47: loss=1.632\n",
      "  batch   48: loss=1.462\n",
      "  batch   49: loss=1.691\n",
      "  batch   50: loss=1.642\n",
      "  batch   51: loss=1.853\n",
      "  batch   52: loss=1.853\n",
      "  batch   53: loss=1.927\n",
      "  batch   54: loss=1.706\n",
      "  batch   55: loss=1.598\n",
      "  batch   56: loss=1.923\n",
      "  batch   57: loss=1.946\n",
      "  batch   58: loss=1.571\n",
      "  batch   59: loss=1.937\n",
      "  batch   60: loss=2.192\n",
      "  batch   61: loss=1.837\n",
      "  batch   62: loss=1.936\n",
      "  batch   63: loss=2.088\n",
      "  batch   64: loss=2.228\n",
      "  batch   65: loss=1.725\n",
      "  batch   66: loss=1.863\n",
      "  batch   67: loss=1.760\n",
      "  batch   68: loss=1.658\n",
      "  batch   69: loss=1.426\n",
      "  batch   70: loss=1.856\n",
      "  batch   71: loss=1.888\n",
      "  batch   72: loss=2.105\n",
      "  batch   73: loss=2.342\n",
      "  batch   74: loss=1.727\n",
      "  batch   75: loss=1.979\n",
      "  batch   76: loss=2.028\n",
      "  batch   77: loss=2.047\n",
      "  batch   78: loss=1.752\n",
      "  batch   79: loss=1.752\n",
      "  batch   80: loss=2.095\n",
      "  batch   81: loss=1.872\n",
      "  batch   82: loss=2.536\n",
      "Testing on validation set\n",
      "  acc=0.510\n",
      "Training epoch 18\n",
      "  batch    1: loss=1.902\n",
      "  batch    2: loss=1.772\n",
      "  batch    3: loss=1.794\n",
      "  batch    4: loss=1.923\n",
      "  batch    5: loss=1.861\n",
      "  batch    6: loss=1.956\n",
      "  batch    7: loss=1.947\n",
      "  batch    8: loss=1.684\n",
      "  batch    9: loss=1.890\n",
      "  batch   10: loss=2.027\n",
      "  batch   11: loss=1.792\n",
      "  batch   12: loss=1.903\n",
      "  batch   13: loss=1.797\n",
      "  batch   14: loss=2.067\n",
      "  batch   15: loss=1.713\n",
      "  batch   16: loss=1.598\n",
      "  batch   17: loss=1.564\n",
      "  batch   18: loss=1.956\n",
      "  batch   19: loss=2.117\n",
      "  batch   20: loss=1.550\n",
      "  batch   21: loss=1.940\n",
      "  batch   22: loss=1.840\n",
      "  batch   23: loss=1.881\n",
      "  batch   24: loss=1.711\n",
      "  batch   25: loss=1.624\n",
      "  batch   26: loss=1.853\n",
      "  batch   27: loss=1.626\n",
      "  batch   28: loss=1.574\n",
      "  batch   29: loss=1.374\n",
      "  batch   30: loss=1.987\n",
      "  batch   31: loss=1.503\n",
      "  batch   32: loss=1.486\n",
      "  batch   33: loss=2.357\n",
      "  batch   34: loss=1.858\n",
      "  batch   35: loss=2.132\n",
      "  batch   36: loss=2.194\n",
      "  batch   37: loss=1.696\n",
      "  batch   38: loss=1.777\n",
      "  batch   39: loss=1.494\n",
      "  batch   40: loss=1.753\n",
      "  batch   41: loss=1.408\n",
      "  batch   42: loss=1.978\n",
      "  batch   43: loss=1.653\n",
      "  batch   44: loss=2.063\n",
      "  batch   45: loss=1.876\n",
      "  batch   46: loss=1.672\n",
      "  batch   47: loss=1.614\n",
      "  batch   48: loss=2.023\n",
      "  batch   49: loss=1.445\n",
      "  batch   50: loss=1.962\n",
      "  batch   51: loss=1.810\n",
      "  batch   52: loss=1.857\n",
      "  batch   53: loss=1.800\n",
      "  batch   54: loss=2.295\n",
      "  batch   55: loss=1.701\n",
      "  batch   56: loss=1.691\n",
      "  batch   57: loss=1.775\n",
      "  batch   58: loss=1.686\n",
      "  batch   59: loss=1.902\n",
      "  batch   60: loss=1.573\n",
      "  batch   61: loss=1.234\n",
      "  batch   62: loss=1.496\n",
      "  batch   63: loss=1.920\n",
      "  batch   64: loss=1.981\n",
      "  batch   65: loss=1.907\n",
      "  batch   66: loss=1.779\n",
      "  batch   67: loss=1.549\n",
      "  batch   68: loss=1.756\n",
      "  batch   69: loss=2.094\n",
      "  batch   70: loss=1.756\n",
      "  batch   71: loss=2.050\n",
      "  batch   72: loss=1.741\n",
      "  batch   73: loss=1.755\n",
      "  batch   74: loss=1.502\n",
      "  batch   75: loss=1.415\n",
      "  batch   76: loss=1.719\n",
      "  batch   77: loss=1.841\n",
      "  batch   78: loss=1.774\n",
      "  batch   79: loss=2.261\n",
      "  batch   80: loss=1.686\n",
      "  batch   81: loss=1.534\n",
      "  batch   82: loss=2.144\n",
      "Testing on validation set\n",
      "  acc=0.549\n",
      "Training epoch 19\n",
      "  batch    1: loss=1.748\n",
      "  batch    2: loss=1.900\n",
      "  batch    3: loss=1.974\n",
      "  batch    4: loss=1.595\n",
      "  batch    5: loss=1.722\n",
      "  batch    6: loss=1.951\n",
      "  batch    7: loss=1.566\n",
      "  batch    8: loss=1.396\n",
      "  batch    9: loss=1.779\n",
      "  batch   10: loss=1.660\n",
      "  batch   11: loss=1.788\n",
      "  batch   12: loss=1.436\n",
      "  batch   13: loss=1.592\n",
      "  batch   14: loss=1.675\n",
      "  batch   15: loss=1.688\n",
      "  batch   16: loss=1.311\n",
      "  batch   17: loss=1.440\n",
      "  batch   18: loss=1.330\n",
      "  batch   19: loss=1.860\n",
      "  batch   20: loss=1.847\n",
      "  batch   21: loss=1.827\n",
      "  batch   22: loss=1.780\n",
      "  batch   23: loss=1.833\n",
      "  batch   24: loss=1.794\n",
      "  batch   25: loss=1.641\n",
      "  batch   26: loss=1.561\n",
      "  batch   27: loss=1.743\n",
      "  batch   28: loss=1.544\n",
      "  batch   29: loss=1.625\n",
      "  batch   30: loss=1.741\n",
      "  batch   31: loss=1.853\n",
      "  batch   32: loss=1.788\n",
      "  batch   33: loss=1.534\n",
      "  batch   34: loss=1.353\n",
      "  batch   35: loss=1.423\n",
      "  batch   36: loss=1.338\n",
      "  batch   37: loss=1.603\n",
      "  batch   38: loss=2.128\n",
      "  batch   39: loss=1.814\n",
      "  batch   40: loss=1.938\n",
      "  batch   41: loss=1.929\n",
      "  batch   42: loss=2.293\n",
      "  batch   43: loss=1.612\n",
      "  batch   44: loss=1.573\n",
      "  batch   45: loss=1.417\n",
      "  batch   46: loss=1.837\n",
      "  batch   47: loss=1.819\n",
      "  batch   48: loss=1.846\n",
      "  batch   49: loss=1.738\n",
      "  batch   50: loss=1.516\n",
      "  batch   51: loss=1.187\n",
      "  batch   52: loss=1.721\n",
      "  batch   53: loss=1.693\n",
      "  batch   54: loss=1.758\n",
      "  batch   55: loss=1.486\n",
      "  batch   56: loss=1.709\n",
      "  batch   57: loss=1.759\n",
      "  batch   58: loss=2.156\n",
      "  batch   59: loss=1.696\n",
      "  batch   60: loss=1.943\n",
      "  batch   61: loss=1.650\n",
      "  batch   62: loss=1.709\n",
      "  batch   63: loss=1.942\n",
      "  batch   64: loss=1.906\n",
      "  batch   65: loss=1.841\n",
      "  batch   66: loss=1.652\n",
      "  batch   67: loss=1.714\n",
      "  batch   68: loss=1.415\n",
      "  batch   69: loss=1.635\n",
      "  batch   70: loss=2.137\n",
      "  batch   71: loss=1.816\n",
      "  batch   72: loss=1.950\n",
      "  batch   73: loss=1.896\n",
      "  batch   74: loss=1.437\n",
      "  batch   75: loss=1.700\n",
      "  batch   76: loss=1.881\n",
      "  batch   77: loss=1.978\n",
      "  batch   78: loss=1.872\n",
      "  batch   79: loss=2.287\n",
      "  batch   80: loss=1.660\n",
      "  batch   81: loss=1.976\n",
      "  batch   82: loss=2.776\n",
      "Testing on validation set\n",
      "  acc=0.558\n",
      "Training epoch 20\n",
      "  batch    1: loss=1.090\n",
      "  batch    2: loss=1.783\n",
      "  batch    3: loss=1.588\n",
      "  batch    4: loss=1.802\n",
      "  batch    5: loss=1.832\n",
      "  batch    6: loss=1.622\n",
      "  batch    7: loss=1.763\n",
      "  batch    8: loss=1.766\n",
      "  batch    9: loss=1.606\n",
      "  batch   10: loss=1.628\n",
      "  batch   11: loss=1.810\n",
      "  batch   12: loss=1.567\n",
      "  batch   13: loss=1.831\n",
      "  batch   14: loss=1.589\n",
      "  batch   15: loss=1.726\n",
      "  batch   16: loss=1.911\n",
      "  batch   17: loss=1.812\n",
      "  batch   18: loss=1.863\n",
      "  batch   19: loss=1.796\n",
      "  batch   20: loss=1.650\n",
      "  batch   21: loss=1.787\n",
      "  batch   22: loss=1.442\n",
      "  batch   23: loss=1.372\n",
      "  batch   24: loss=1.734\n",
      "  batch   25: loss=1.860\n",
      "  batch   26: loss=1.653\n",
      "  batch   27: loss=1.794\n",
      "  batch   28: loss=1.625\n",
      "  batch   29: loss=1.306\n",
      "  batch   30: loss=1.785\n",
      "  batch   31: loss=2.023\n",
      "  batch   32: loss=1.728\n",
      "  batch   33: loss=1.455\n",
      "  batch   34: loss=1.647\n",
      "  batch   35: loss=1.342\n",
      "  batch   36: loss=1.969\n",
      "  batch   37: loss=1.972\n",
      "  batch   38: loss=1.884\n",
      "  batch   39: loss=1.983\n",
      "  batch   40: loss=1.674\n",
      "  batch   41: loss=1.679\n",
      "  batch   42: loss=1.833\n",
      "  batch   43: loss=1.716\n",
      "  batch   44: loss=1.681\n",
      "  batch   45: loss=1.720\n",
      "  batch   46: loss=1.653\n",
      "  batch   47: loss=1.681\n",
      "  batch   48: loss=2.095\n",
      "  batch   49: loss=2.195\n",
      "  batch   50: loss=1.885\n",
      "  batch   51: loss=1.511\n",
      "  batch   52: loss=1.765\n",
      "  batch   53: loss=2.097\n",
      "  batch   54: loss=1.577\n",
      "  batch   55: loss=2.286\n",
      "  batch   56: loss=1.484\n",
      "  batch   57: loss=1.840\n",
      "  batch   58: loss=1.306\n",
      "  batch   59: loss=1.552\n",
      "  batch   60: loss=1.926\n",
      "  batch   61: loss=1.572\n",
      "  batch   62: loss=1.592\n",
      "  batch   63: loss=1.676\n",
      "  batch   64: loss=1.263\n",
      "  batch   65: loss=1.997\n",
      "  batch   66: loss=1.450\n",
      "  batch   67: loss=1.768\n",
      "  batch   68: loss=1.808\n",
      "  batch   69: loss=1.321\n",
      "  batch   70: loss=1.742\n",
      "  batch   71: loss=1.152\n",
      "  batch   72: loss=1.521\n",
      "  batch   73: loss=1.477\n",
      "  batch   74: loss=1.646\n",
      "  batch   75: loss=1.622\n",
      "  batch   76: loss=1.398\n",
      "  batch   77: loss=1.720\n",
      "  batch   78: loss=2.061\n",
      "  batch   79: loss=1.536\n",
      "  batch   80: loss=1.312\n",
      "  batch   81: loss=2.124\n",
      "  batch   82: loss=1.270\n",
      "Testing on validation set\n",
      "  acc=0.570\n",
      "Training epoch 21\n",
      "  batch    1: loss=1.868\n",
      "  batch    2: loss=1.463\n",
      "  batch    3: loss=1.651\n",
      "  batch    4: loss=1.715\n",
      "  batch    5: loss=1.504\n",
      "  batch    6: loss=1.576\n",
      "  batch    7: loss=1.666\n",
      "  batch    8: loss=1.742\n",
      "  batch    9: loss=1.693\n",
      "  batch   10: loss=1.523\n",
      "  batch   11: loss=1.862\n",
      "  batch   12: loss=1.292\n",
      "  batch   13: loss=1.425\n",
      "  batch   14: loss=1.729\n",
      "  batch   15: loss=1.887\n",
      "  batch   16: loss=1.839\n",
      "  batch   17: loss=1.444\n",
      "  batch   18: loss=2.106\n",
      "  batch   19: loss=1.533\n",
      "  batch   20: loss=1.601\n",
      "  batch   21: loss=1.607\n",
      "  batch   22: loss=1.636\n",
      "  batch   23: loss=1.727\n",
      "  batch   24: loss=1.828\n",
      "  batch   25: loss=1.620\n",
      "  batch   26: loss=1.751\n",
      "  batch   27: loss=1.568\n",
      "  batch   28: loss=1.525\n",
      "  batch   29: loss=1.679\n",
      "  batch   30: loss=1.025\n",
      "  batch   31: loss=1.594\n",
      "  batch   32: loss=1.635\n",
      "  batch   33: loss=1.740\n",
      "  batch   34: loss=1.357\n",
      "  batch   35: loss=1.688\n",
      "  batch   36: loss=1.874\n",
      "  batch   37: loss=1.828\n",
      "  batch   38: loss=1.770\n",
      "  batch   39: loss=2.099\n",
      "  batch   40: loss=2.056\n",
      "  batch   41: loss=1.359\n",
      "  batch   42: loss=2.011\n",
      "  batch   43: loss=1.449\n",
      "  batch   44: loss=1.656\n",
      "  batch   45: loss=1.834\n",
      "  batch   46: loss=1.359\n",
      "  batch   47: loss=1.682\n",
      "  batch   48: loss=1.841\n",
      "  batch   49: loss=1.652\n",
      "  batch   50: loss=1.546\n",
      "  batch   51: loss=1.734\n",
      "  batch   52: loss=1.838\n",
      "  batch   53: loss=1.839\n",
      "  batch   54: loss=2.001\n",
      "  batch   55: loss=1.377\n",
      "  batch   56: loss=1.508\n",
      "  batch   57: loss=1.635\n",
      "  batch   58: loss=1.637\n",
      "  batch   59: loss=1.716\n",
      "  batch   60: loss=1.619\n",
      "  batch   61: loss=1.437\n",
      "  batch   62: loss=1.591\n",
      "  batch   63: loss=1.861\n",
      "  batch   64: loss=1.635\n",
      "  batch   65: loss=1.673\n",
      "  batch   66: loss=1.486\n",
      "  batch   67: loss=1.742\n",
      "  batch   68: loss=1.465\n",
      "  batch   69: loss=1.670\n",
      "  batch   70: loss=1.826\n",
      "  batch   71: loss=1.568\n",
      "  batch   72: loss=1.510\n",
      "  batch   73: loss=1.768\n",
      "  batch   74: loss=1.566\n",
      "  batch   75: loss=1.456\n",
      "  batch   76: loss=1.457\n",
      "  batch   77: loss=1.875\n",
      "  batch   78: loss=1.781\n",
      "  batch   79: loss=1.984\n",
      "  batch   80: loss=1.565\n",
      "  batch   81: loss=1.478\n",
      "  batch   82: loss=1.048\n",
      "Testing on validation set\n",
      "  acc=0.551\n",
      "Training epoch 22\n",
      "  batch    1: loss=1.788\n",
      "  batch    2: loss=1.304\n",
      "  batch    3: loss=1.725\n",
      "  batch    4: loss=1.522\n",
      "  batch    5: loss=1.434\n",
      "  batch    6: loss=1.728\n",
      "  batch    7: loss=1.293\n",
      "  batch    8: loss=1.436\n",
      "  batch    9: loss=1.727\n",
      "  batch   10: loss=1.110\n",
      "  batch   11: loss=1.257\n",
      "  batch   12: loss=1.791\n",
      "  batch   13: loss=1.761\n",
      "  batch   14: loss=1.758\n",
      "  batch   15: loss=1.569\n",
      "  batch   16: loss=1.826\n",
      "  batch   17: loss=1.764\n",
      "  batch   18: loss=1.524\n",
      "  batch   19: loss=1.312\n",
      "  batch   20: loss=1.574\n",
      "  batch   21: loss=1.517\n",
      "  batch   22: loss=1.880\n",
      "  batch   23: loss=1.523\n",
      "  batch   24: loss=1.271\n",
      "  batch   25: loss=1.726\n",
      "  batch   26: loss=1.655\n",
      "  batch   27: loss=1.550\n",
      "  batch   28: loss=1.965\n",
      "  batch   29: loss=1.473\n",
      "  batch   30: loss=1.638\n",
      "  batch   31: loss=1.354\n",
      "  batch   32: loss=1.415\n",
      "  batch   33: loss=1.267\n",
      "  batch   34: loss=1.558\n",
      "  batch   35: loss=1.676\n",
      "  batch   36: loss=1.556\n",
      "  batch   37: loss=2.087\n",
      "  batch   38: loss=2.073\n",
      "  batch   39: loss=1.864\n",
      "  batch   40: loss=1.952\n",
      "  batch   41: loss=1.635\n",
      "  batch   42: loss=1.938\n",
      "  batch   43: loss=1.390\n",
      "  batch   44: loss=1.619\n",
      "  batch   45: loss=1.532\n",
      "  batch   46: loss=1.445\n",
      "  batch   47: loss=1.624\n",
      "  batch   48: loss=1.554\n",
      "  batch   49: loss=2.075\n",
      "  batch   50: loss=1.724\n",
      "  batch   51: loss=1.540\n",
      "  batch   52: loss=1.604\n",
      "  batch   53: loss=1.974\n",
      "  batch   54: loss=1.684\n",
      "  batch   55: loss=1.588\n",
      "  batch   56: loss=1.516\n",
      "  batch   57: loss=1.797\n",
      "  batch   58: loss=1.540\n",
      "  batch   59: loss=1.364\n",
      "  batch   60: loss=1.760\n",
      "  batch   61: loss=1.372\n",
      "  batch   62: loss=2.135\n",
      "  batch   63: loss=2.027\n",
      "  batch   64: loss=1.518\n",
      "  batch   65: loss=1.582\n",
      "  batch   66: loss=2.204\n",
      "  batch   67: loss=1.678\n",
      "  batch   68: loss=1.211\n",
      "  batch   69: loss=1.418\n",
      "  batch   70: loss=1.507\n",
      "  batch   71: loss=1.442\n",
      "  batch   72: loss=1.429\n",
      "  batch   73: loss=1.297\n",
      "  batch   74: loss=1.623\n",
      "  batch   75: loss=2.144\n",
      "  batch   76: loss=1.506\n",
      "  batch   77: loss=1.721\n",
      "  batch   78: loss=1.627\n",
      "  batch   79: loss=1.545\n",
      "  batch   80: loss=1.373\n",
      "  batch   81: loss=1.783\n",
      "  batch   82: loss=1.369\n",
      "Testing on validation set\n",
      "  acc=0.585\n",
      "Training epoch 23\n",
      "  batch    1: loss=1.509\n",
      "  batch    2: loss=1.295\n",
      "  batch    3: loss=1.550\n",
      "  batch    4: loss=1.718\n",
      "  batch    5: loss=1.694\n",
      "  batch    6: loss=1.517\n",
      "  batch    7: loss=1.694\n",
      "  batch    8: loss=1.744\n",
      "  batch    9: loss=1.561\n",
      "  batch   10: loss=1.453\n",
      "  batch   11: loss=1.465\n",
      "  batch   12: loss=1.698\n",
      "  batch   13: loss=1.844\n",
      "  batch   14: loss=1.651\n",
      "  batch   15: loss=1.695\n",
      "  batch   16: loss=1.545\n",
      "  batch   17: loss=1.371\n",
      "  batch   18: loss=1.651\n",
      "  batch   19: loss=1.643\n",
      "  batch   20: loss=1.211\n",
      "  batch   21: loss=1.648\n",
      "  batch   22: loss=1.733\n",
      "  batch   23: loss=1.293\n",
      "  batch   24: loss=1.688\n",
      "  batch   25: loss=2.032\n",
      "  batch   26: loss=1.766\n",
      "  batch   27: loss=1.762\n",
      "  batch   28: loss=1.635\n",
      "  batch   29: loss=1.673\n",
      "  batch   30: loss=1.503\n",
      "  batch   31: loss=1.557\n",
      "  batch   32: loss=1.279\n",
      "  batch   33: loss=1.347\n",
      "  batch   34: loss=1.483\n",
      "  batch   35: loss=1.526\n",
      "  batch   36: loss=1.590\n",
      "  batch   37: loss=1.742\n",
      "  batch   38: loss=2.075\n",
      "  batch   39: loss=1.819\n",
      "  batch   40: loss=1.404\n",
      "  batch   41: loss=1.774\n",
      "  batch   42: loss=1.425\n",
      "  batch   43: loss=1.522\n",
      "  batch   44: loss=1.571\n",
      "  batch   45: loss=1.949\n",
      "  batch   46: loss=1.120\n",
      "  batch   47: loss=1.795\n",
      "  batch   48: loss=1.510\n",
      "  batch   49: loss=1.819\n",
      "  batch   50: loss=1.624\n",
      "  batch   51: loss=1.683\n",
      "  batch   52: loss=1.422\n",
      "  batch   53: loss=1.326\n",
      "  batch   54: loss=1.380\n",
      "  batch   55: loss=1.747\n",
      "  batch   56: loss=1.511\n",
      "  batch   57: loss=1.294\n",
      "  batch   58: loss=1.340\n",
      "  batch   59: loss=1.838\n",
      "  batch   60: loss=1.308\n",
      "  batch   61: loss=1.715\n",
      "  batch   62: loss=1.500\n",
      "  batch   63: loss=1.567\n",
      "  batch   64: loss=1.674\n",
      "  batch   65: loss=1.910\n",
      "  batch   66: loss=1.552\n",
      "  batch   67: loss=1.677\n",
      "  batch   68: loss=1.268\n",
      "  batch   69: loss=1.740\n",
      "  batch   70: loss=1.643\n",
      "  batch   71: loss=1.370\n",
      "  batch   72: loss=1.568\n",
      "  batch   73: loss=1.284\n",
      "  batch   74: loss=1.560\n",
      "  batch   75: loss=1.510\n",
      "  batch   76: loss=1.410\n",
      "  batch   77: loss=1.740\n",
      "  batch   78: loss=1.750\n",
      "  batch   79: loss=1.571\n",
      "  batch   80: loss=1.292\n",
      "  batch   81: loss=1.640\n",
      "  batch   82: loss=1.048\n",
      "Testing on validation set\n",
      "  acc=0.591\n",
      "Training epoch 24\n",
      "  batch    1: loss=1.586\n",
      "  batch    2: loss=1.000\n",
      "  batch    3: loss=1.568\n",
      "  batch    4: loss=1.334\n",
      "  batch    5: loss=1.496\n",
      "  batch    6: loss=1.639\n",
      "  batch    7: loss=1.320\n",
      "  batch    8: loss=1.166\n",
      "  batch    9: loss=1.972\n",
      "  batch   10: loss=1.421\n",
      "  batch   11: loss=1.260\n",
      "  batch   12: loss=1.442\n",
      "  batch   13: loss=1.673\n",
      "  batch   14: loss=1.739\n",
      "  batch   15: loss=1.529\n",
      "  batch   16: loss=1.160\n",
      "  batch   17: loss=1.667\n",
      "  batch   18: loss=1.266\n",
      "  batch   19: loss=1.710\n",
      "  batch   20: loss=1.530\n",
      "  batch   21: loss=1.232\n",
      "  batch   22: loss=1.130\n",
      "  batch   23: loss=1.479\n",
      "  batch   24: loss=1.529\n",
      "  batch   25: loss=1.556\n",
      "  batch   26: loss=1.244\n",
      "  batch   27: loss=1.863\n",
      "  batch   28: loss=1.447\n",
      "  batch   29: loss=1.435\n",
      "  batch   30: loss=1.750\n",
      "  batch   31: loss=1.697\n",
      "  batch   32: loss=1.691\n",
      "  batch   33: loss=1.690\n",
      "  batch   34: loss=1.613\n",
      "  batch   35: loss=1.821\n",
      "  batch   36: loss=1.652\n",
      "  batch   37: loss=1.654\n",
      "  batch   38: loss=1.709\n",
      "  batch   39: loss=1.677\n",
      "  batch   40: loss=1.641\n",
      "  batch   41: loss=1.230\n",
      "  batch   42: loss=1.645\n",
      "  batch   43: loss=1.766\n",
      "  batch   44: loss=2.025\n",
      "  batch   45: loss=2.046\n",
      "  batch   46: loss=1.505\n",
      "  batch   47: loss=1.775\n",
      "  batch   48: loss=1.429\n",
      "  batch   49: loss=1.558\n",
      "  batch   50: loss=1.979\n",
      "  batch   51: loss=1.502\n",
      "  batch   52: loss=1.659\n",
      "  batch   53: loss=1.385\n",
      "  batch   54: loss=1.223\n",
      "  batch   55: loss=1.314\n",
      "  batch   56: loss=1.609\n",
      "  batch   57: loss=1.758\n",
      "  batch   58: loss=1.893\n",
      "  batch   59: loss=1.652\n",
      "  batch   60: loss=1.609\n",
      "  batch   61: loss=1.709\n",
      "  batch   62: loss=1.529\n",
      "  batch   63: loss=1.828\n",
      "  batch   64: loss=1.906\n",
      "  batch   65: loss=1.253\n",
      "  batch   66: loss=1.567\n",
      "  batch   67: loss=1.889\n",
      "  batch   68: loss=1.089\n",
      "  batch   69: loss=1.604\n",
      "  batch   70: loss=1.797\n",
      "  batch   71: loss=1.547\n",
      "  batch   72: loss=1.953\n",
      "  batch   73: loss=1.580\n",
      "  batch   74: loss=1.827\n",
      "  batch   75: loss=1.205\n",
      "  batch   76: loss=1.365\n",
      "  batch   77: loss=1.413\n",
      "  batch   78: loss=1.616\n",
      "  batch   79: loss=1.689\n",
      "  batch   80: loss=1.609\n",
      "  batch   81: loss=1.580\n",
      "  batch   82: loss=2.596\n",
      "Testing on validation set\n",
      "  acc=0.604\n",
      "Training epoch 25\n",
      "  batch    1: loss=1.525\n",
      "  batch    2: loss=1.335\n",
      "  batch    3: loss=1.283\n",
      "  batch    4: loss=1.599\n",
      "  batch    5: loss=1.155\n",
      "  batch    6: loss=1.596\n",
      "  batch    7: loss=1.054\n",
      "  batch    8: loss=1.598\n",
      "  batch    9: loss=1.132\n",
      "  batch   10: loss=1.514\n",
      "  batch   11: loss=1.546\n",
      "  batch   12: loss=1.626\n",
      "  batch   13: loss=1.177\n",
      "  batch   14: loss=1.882\n",
      "  batch   15: loss=1.507\n",
      "  batch   16: loss=1.216\n",
      "  batch   17: loss=1.323\n",
      "  batch   18: loss=1.514\n",
      "  batch   19: loss=1.393\n",
      "  batch   20: loss=1.509\n",
      "  batch   21: loss=1.649\n",
      "  batch   22: loss=1.303\n",
      "  batch   23: loss=1.818\n",
      "  batch   24: loss=1.642\n",
      "  batch   25: loss=1.385\n",
      "  batch   26: loss=1.332\n",
      "  batch   27: loss=1.593\n",
      "  batch   28: loss=1.520\n",
      "  batch   29: loss=1.533\n",
      "  batch   30: loss=1.524\n",
      "  batch   31: loss=1.185\n",
      "  batch   32: loss=1.448\n",
      "  batch   33: loss=1.629\n",
      "  batch   34: loss=1.492\n",
      "  batch   35: loss=1.873\n",
      "  batch   36: loss=1.685\n",
      "  batch   37: loss=1.793\n",
      "  batch   38: loss=1.451\n",
      "  batch   39: loss=1.845\n",
      "  batch   40: loss=1.460\n",
      "  batch   41: loss=1.419\n",
      "  batch   42: loss=1.395\n",
      "  batch   43: loss=1.239\n",
      "  batch   44: loss=1.402\n",
      "  batch   45: loss=1.088\n",
      "  batch   46: loss=1.513\n",
      "  batch   47: loss=1.494\n",
      "  batch   48: loss=1.410\n",
      "  batch   49: loss=1.219\n",
      "  batch   50: loss=1.614\n",
      "  batch   51: loss=1.570\n",
      "  batch   52: loss=1.639\n",
      "  batch   53: loss=1.268\n",
      "  batch   54: loss=1.786\n",
      "  batch   55: loss=1.598\n",
      "  batch   56: loss=1.499\n",
      "  batch   57: loss=1.372\n",
      "  batch   58: loss=1.529\n",
      "  batch   59: loss=1.626\n",
      "  batch   60: loss=1.357\n",
      "  batch   61: loss=1.852\n",
      "  batch   62: loss=1.627\n",
      "  batch   63: loss=1.787\n",
      "  batch   64: loss=1.404\n",
      "  batch   65: loss=1.363\n",
      "  batch   66: loss=1.409\n",
      "  batch   67: loss=1.491\n",
      "  batch   68: loss=1.573\n",
      "  batch   69: loss=1.228\n",
      "  batch   70: loss=1.553\n",
      "  batch   71: loss=1.398\n",
      "  batch   72: loss=1.533\n",
      "  batch   73: loss=1.454\n",
      "  batch   74: loss=1.456\n",
      "  batch   75: loss=1.846\n",
      "  batch   76: loss=1.782\n",
      "  batch   77: loss=1.446\n",
      "  batch   78: loss=1.374\n",
      "  batch   79: loss=1.196\n",
      "  batch   80: loss=1.374\n",
      "  batch   81: loss=1.167\n",
      "  batch   82: loss=1.727\n",
      "Testing on validation set\n",
      "  acc=0.599\n",
      "Training epoch 26\n",
      "  batch    1: loss=1.487\n",
      "  batch    2: loss=1.649\n",
      "  batch    3: loss=1.221\n",
      "  batch    4: loss=1.692\n",
      "  batch    5: loss=1.460\n",
      "  batch    6: loss=1.286\n",
      "  batch    7: loss=1.550\n",
      "  batch    8: loss=1.474\n",
      "  batch    9: loss=1.291\n",
      "  batch   10: loss=1.419\n",
      "  batch   11: loss=1.822\n",
      "  batch   12: loss=1.332\n",
      "  batch   13: loss=1.587\n",
      "  batch   14: loss=1.789\n",
      "  batch   15: loss=1.296\n",
      "  batch   16: loss=1.340\n",
      "  batch   17: loss=1.548\n",
      "  batch   18: loss=1.695\n",
      "  batch   19: loss=1.420\n",
      "  batch   20: loss=1.269\n",
      "  batch   21: loss=1.433\n",
      "  batch   22: loss=1.484\n",
      "  batch   23: loss=1.602\n",
      "  batch   24: loss=1.166\n",
      "  batch   25: loss=1.360\n",
      "  batch   26: loss=1.562\n",
      "  batch   27: loss=1.094\n",
      "  batch   28: loss=1.152\n",
      "  batch   29: loss=1.625\n",
      "  batch   30: loss=1.398\n",
      "  batch   31: loss=1.397\n",
      "  batch   32: loss=1.758\n",
      "  batch   33: loss=1.443\n",
      "  batch   34: loss=1.472\n",
      "  batch   35: loss=0.937\n",
      "  batch   36: loss=1.068\n",
      "  batch   37: loss=1.250\n",
      "  batch   38: loss=1.495\n",
      "  batch   39: loss=1.379\n",
      "  batch   40: loss=1.307\n",
      "  batch   41: loss=1.432\n",
      "  batch   42: loss=1.335\n",
      "  batch   43: loss=1.590\n",
      "  batch   44: loss=1.345\n",
      "  batch   45: loss=1.350\n",
      "  batch   46: loss=1.299\n",
      "  batch   47: loss=1.699\n",
      "  batch   48: loss=1.687\n",
      "  batch   49: loss=1.578\n",
      "  batch   50: loss=1.599\n",
      "  batch   51: loss=1.326\n",
      "  batch   52: loss=1.816\n",
      "  batch   53: loss=1.418\n",
      "  batch   54: loss=1.534\n",
      "  batch   55: loss=1.046\n",
      "  batch   56: loss=1.459\n",
      "  batch   57: loss=1.197\n",
      "  batch   58: loss=1.599\n",
      "  batch   59: loss=1.387\n",
      "  batch   60: loss=1.591\n",
      "  batch   61: loss=1.535\n",
      "  batch   62: loss=1.399\n",
      "  batch   63: loss=1.635\n",
      "  batch   64: loss=1.475\n",
      "  batch   65: loss=1.135\n",
      "  batch   66: loss=1.125\n",
      "  batch   67: loss=1.279\n",
      "  batch   68: loss=1.480\n",
      "  batch   69: loss=1.867\n",
      "  batch   70: loss=1.401\n",
      "  batch   71: loss=1.547\n",
      "  batch   72: loss=1.273\n",
      "  batch   73: loss=1.566\n",
      "  batch   74: loss=1.945\n",
      "  batch   75: loss=1.452\n",
      "  batch   76: loss=1.270\n",
      "  batch   77: loss=1.430\n",
      "  batch   78: loss=1.649\n",
      "  batch   79: loss=1.427\n",
      "  batch   80: loss=1.537\n",
      "  batch   81: loss=1.396\n",
      "  batch   82: loss=1.270\n",
      "Testing on validation set\n",
      "  acc=0.601\n",
      "Training epoch 27\n",
      "  batch    1: loss=1.459\n",
      "  batch    2: loss=1.244\n",
      "  batch    3: loss=1.402\n",
      "  batch    4: loss=1.394\n",
      "  batch    5: loss=1.655\n",
      "  batch    6: loss=1.283\n",
      "  batch    7: loss=1.166\n",
      "  batch    8: loss=1.947\n",
      "  batch    9: loss=1.853\n",
      "  batch   10: loss=1.666\n",
      "  batch   11: loss=1.278\n",
      "  batch   12: loss=1.119\n",
      "  batch   13: loss=1.067\n",
      "  batch   14: loss=1.419\n",
      "  batch   15: loss=1.224\n",
      "  batch   16: loss=1.252\n",
      "  batch   17: loss=1.616\n",
      "  batch   18: loss=1.233\n",
      "  batch   19: loss=1.461\n",
      "  batch   20: loss=1.628\n",
      "  batch   21: loss=1.386\n",
      "  batch   22: loss=1.378\n",
      "  batch   23: loss=1.676\n",
      "  batch   24: loss=1.306\n",
      "  batch   25: loss=1.382\n",
      "  batch   26: loss=1.155\n",
      "  batch   27: loss=1.110\n",
      "  batch   28: loss=1.574\n",
      "  batch   29: loss=1.288\n",
      "  batch   30: loss=1.634\n",
      "  batch   31: loss=1.586\n",
      "  batch   32: loss=1.430\n",
      "  batch   33: loss=1.561\n",
      "  batch   34: loss=1.355\n",
      "  batch   35: loss=1.493\n",
      "  batch   36: loss=1.392\n",
      "  batch   37: loss=1.395\n",
      "  batch   38: loss=1.406\n",
      "  batch   39: loss=1.416\n",
      "  batch   40: loss=1.462\n",
      "  batch   41: loss=1.612\n",
      "  batch   42: loss=1.127\n",
      "  batch   43: loss=1.455\n",
      "  batch   44: loss=1.238\n",
      "  batch   45: loss=1.113\n",
      "  batch   46: loss=1.675\n",
      "  batch   47: loss=1.469\n",
      "  batch   48: loss=1.337\n",
      "  batch   49: loss=1.445\n",
      "  batch   50: loss=1.188\n",
      "  batch   51: loss=1.410\n",
      "  batch   52: loss=1.200\n",
      "  batch   53: loss=1.267\n",
      "  batch   54: loss=1.722\n",
      "  batch   55: loss=1.286\n",
      "  batch   56: loss=1.341\n",
      "  batch   57: loss=1.373\n",
      "  batch   58: loss=1.527\n",
      "  batch   59: loss=1.233\n",
      "  batch   60: loss=1.786\n",
      "  batch   61: loss=1.131\n",
      "  batch   62: loss=1.458\n",
      "  batch   63: loss=1.678\n",
      "  batch   64: loss=1.538\n",
      "  batch   65: loss=1.403\n",
      "  batch   66: loss=0.839\n",
      "  batch   67: loss=1.090\n",
      "  batch   68: loss=1.157\n",
      "  batch   69: loss=0.987\n",
      "  batch   70: loss=1.435\n",
      "  batch   71: loss=1.153\n",
      "  batch   72: loss=1.343\n",
      "  batch   73: loss=1.300\n",
      "  batch   74: loss=1.362\n",
      "  batch   75: loss=1.484\n",
      "  batch   76: loss=1.628\n",
      "  batch   77: loss=1.533\n",
      "  batch   78: loss=1.143\n",
      "  batch   79: loss=1.137\n",
      "  batch   80: loss=1.696\n",
      "  batch   81: loss=1.514\n",
      "  batch   82: loss=1.635\n",
      "Testing on validation set\n",
      "  acc=0.652\n",
      "Training epoch 28\n",
      "  batch    1: loss=1.288\n",
      "  batch    2: loss=0.937\n",
      "  batch    3: loss=1.253\n",
      "  batch    4: loss=1.402\n",
      "  batch    5: loss=1.193\n",
      "  batch    6: loss=1.199\n",
      "  batch    7: loss=1.417\n",
      "  batch    8: loss=1.349\n",
      "  batch    9: loss=1.442\n",
      "  batch   10: loss=1.569\n",
      "  batch   11: loss=1.261\n",
      "  batch   12: loss=1.301\n",
      "  batch   13: loss=1.152\n",
      "  batch   14: loss=1.531\n",
      "  batch   15: loss=1.159\n",
      "  batch   16: loss=1.052\n",
      "  batch   17: loss=1.309\n",
      "  batch   18: loss=1.673\n",
      "  batch   19: loss=1.551\n",
      "  batch   20: loss=1.528\n",
      "  batch   21: loss=1.357\n",
      "  batch   22: loss=1.165\n",
      "  batch   23: loss=1.637\n",
      "  batch   24: loss=1.452\n",
      "  batch   25: loss=1.103\n",
      "  batch   26: loss=1.443\n",
      "  batch   27: loss=1.236\n",
      "  batch   28: loss=1.596\n",
      "  batch   29: loss=1.470\n",
      "  batch   30: loss=1.483\n",
      "  batch   31: loss=1.496\n",
      "  batch   32: loss=1.516\n",
      "  batch   33: loss=1.296\n",
      "  batch   34: loss=1.537\n",
      "  batch   35: loss=1.738\n",
      "  batch   36: loss=1.747\n",
      "  batch   37: loss=1.552\n",
      "  batch   38: loss=1.437\n",
      "  batch   39: loss=1.676\n",
      "  batch   40: loss=1.694\n",
      "  batch   41: loss=1.210\n",
      "  batch   42: loss=1.503\n",
      "  batch   43: loss=1.437\n",
      "  batch   44: loss=1.618\n",
      "  batch   45: loss=1.318\n",
      "  batch   46: loss=1.214\n",
      "  batch   47: loss=1.403\n",
      "  batch   48: loss=1.503\n",
      "  batch   49: loss=1.443\n",
      "  batch   50: loss=1.914\n",
      "  batch   51: loss=1.551\n",
      "  batch   52: loss=1.368\n",
      "  batch   53: loss=1.403\n",
      "  batch   54: loss=1.535\n",
      "  batch   55: loss=1.274\n",
      "  batch   56: loss=1.341\n",
      "  batch   57: loss=1.398\n",
      "  batch   58: loss=1.172\n",
      "  batch   59: loss=1.190\n",
      "  batch   60: loss=1.522\n",
      "  batch   61: loss=1.368\n",
      "  batch   62: loss=1.413\n",
      "  batch   63: loss=1.568\n",
      "  batch   64: loss=1.381\n",
      "  batch   65: loss=1.304\n",
      "  batch   66: loss=1.419\n",
      "  batch   67: loss=1.112\n",
      "  batch   68: loss=1.571\n",
      "  batch   69: loss=1.202\n",
      "  batch   70: loss=1.427\n",
      "  batch   71: loss=1.209\n",
      "  batch   72: loss=1.269\n",
      "  batch   73: loss=1.258\n",
      "  batch   74: loss=1.496\n",
      "  batch   75: loss=1.406\n",
      "  batch   76: loss=1.553\n",
      "  batch   77: loss=1.414\n",
      "  batch   78: loss=1.443\n",
      "  batch   79: loss=0.923\n",
      "  batch   80: loss=1.327\n",
      "  batch   81: loss=1.425\n",
      "  batch   82: loss=1.870\n",
      "Testing on validation set\n",
      "  acc=0.630\n",
      "Training epoch 29\n",
      "  batch    1: loss=1.699\n",
      "  batch    2: loss=1.520\n",
      "  batch    3: loss=1.110\n",
      "  batch    4: loss=1.673\n",
      "  batch    5: loss=1.215\n",
      "  batch    6: loss=1.060\n",
      "  batch    7: loss=1.207\n",
      "  batch    8: loss=1.292\n",
      "  batch    9: loss=1.110\n",
      "  batch   10: loss=1.358\n",
      "  batch   11: loss=1.341\n",
      "  batch   12: loss=1.211\n",
      "  batch   13: loss=1.424\n",
      "  batch   14: loss=1.218\n",
      "  batch   15: loss=1.366\n",
      "  batch   16: loss=1.244\n",
      "  batch   17: loss=1.176\n",
      "  batch   18: loss=1.275\n",
      "  batch   19: loss=1.422\n",
      "  batch   20: loss=1.285\n",
      "  batch   21: loss=1.459\n",
      "  batch   22: loss=1.382\n",
      "  batch   23: loss=1.171\n",
      "  batch   24: loss=1.322\n",
      "  batch   25: loss=0.834\n",
      "  batch   26: loss=1.399\n",
      "  batch   27: loss=1.101\n",
      "  batch   28: loss=1.455\n",
      "  batch   29: loss=1.167\n",
      "  batch   30: loss=1.469\n",
      "  batch   31: loss=1.314\n",
      "  batch   32: loss=1.288\n",
      "  batch   33: loss=1.056\n",
      "  batch   34: loss=1.156\n",
      "  batch   35: loss=1.468\n",
      "  batch   36: loss=1.255\n",
      "  batch   37: loss=1.333\n",
      "  batch   38: loss=1.593\n",
      "  batch   39: loss=1.309\n",
      "  batch   40: loss=1.187\n",
      "  batch   41: loss=1.177\n",
      "  batch   42: loss=1.026\n",
      "  batch   43: loss=1.079\n",
      "  batch   44: loss=1.254\n",
      "  batch   45: loss=1.561\n",
      "  batch   46: loss=1.414\n",
      "  batch   47: loss=1.248\n",
      "  batch   48: loss=1.077\n",
      "  batch   49: loss=1.342\n",
      "  batch   50: loss=1.423\n",
      "  batch   51: loss=1.607\n",
      "  batch   52: loss=1.430\n",
      "  batch   53: loss=1.026\n",
      "  batch   54: loss=1.569\n",
      "  batch   55: loss=1.478\n",
      "  batch   56: loss=1.231\n",
      "  batch   57: loss=1.781\n",
      "  batch   58: loss=1.736\n",
      "  batch   59: loss=1.540\n",
      "  batch   60: loss=1.450\n",
      "  batch   61: loss=1.288\n",
      "  batch   62: loss=1.381\n",
      "  batch   63: loss=1.304\n",
      "  batch   64: loss=1.158\n",
      "  batch   65: loss=1.070\n",
      "  batch   66: loss=1.231\n",
      "  batch   67: loss=1.244\n",
      "  batch   68: loss=1.423\n",
      "  batch   69: loss=1.044\n",
      "  batch   70: loss=1.101\n",
      "  batch   71: loss=1.428\n",
      "  batch   72: loss=1.078\n",
      "  batch   73: loss=1.301\n",
      "  batch   74: loss=1.228\n",
      "  batch   75: loss=1.704\n",
      "  batch   76: loss=1.169\n",
      "  batch   77: loss=1.414\n",
      "  batch   78: loss=1.447\n",
      "  batch   79: loss=1.322\n",
      "  batch   80: loss=1.436\n",
      "  batch   81: loss=1.673\n",
      "  batch   82: loss=1.179\n",
      "Testing on validation set\n",
      "  acc=0.643\n",
      "Training epoch 30\n",
      "  batch    1: loss=1.276\n",
      "  batch    2: loss=1.280\n",
      "  batch    3: loss=1.457\n",
      "  batch    4: loss=1.103\n",
      "  batch    5: loss=1.614\n",
      "  batch    6: loss=1.147\n",
      "  batch    7: loss=1.419\n",
      "  batch    8: loss=1.004\n",
      "  batch    9: loss=1.331\n",
      "  batch   10: loss=1.410\n",
      "  batch   11: loss=1.257\n",
      "  batch   12: loss=0.966\n",
      "  batch   13: loss=1.008\n",
      "  batch   14: loss=0.984\n",
      "  batch   15: loss=1.778\n",
      "  batch   16: loss=1.435\n",
      "  batch   17: loss=1.350\n",
      "  batch   18: loss=1.416\n",
      "  batch   19: loss=1.436\n",
      "  batch   20: loss=1.391\n",
      "  batch   21: loss=1.369\n",
      "  batch   22: loss=1.416\n",
      "  batch   23: loss=1.090\n",
      "  batch   24: loss=1.329\n",
      "  batch   25: loss=1.107\n",
      "  batch   26: loss=1.222\n",
      "  batch   27: loss=1.450\n",
      "  batch   28: loss=1.340\n",
      "  batch   29: loss=1.139\n",
      "  batch   30: loss=1.442\n",
      "  batch   31: loss=1.062\n",
      "  batch   32: loss=1.456\n",
      "  batch   33: loss=1.276\n",
      "  batch   34: loss=1.093\n",
      "  batch   35: loss=1.300\n",
      "  batch   36: loss=1.643\n",
      "  batch   37: loss=1.274\n",
      "  batch   38: loss=1.074\n",
      "  batch   39: loss=1.227\n",
      "  batch   40: loss=1.296\n",
      "  batch   41: loss=0.912\n",
      "  batch   42: loss=1.384\n",
      "  batch   43: loss=1.075\n",
      "  batch   44: loss=1.410\n",
      "  batch   45: loss=1.113\n",
      "  batch   46: loss=1.201\n",
      "  batch   47: loss=1.189\n",
      "  batch   48: loss=1.474\n",
      "  batch   49: loss=1.518\n",
      "  batch   50: loss=1.556\n",
      "  batch   51: loss=1.745\n",
      "  batch   52: loss=1.205\n",
      "  batch   53: loss=1.291\n",
      "  batch   54: loss=1.029\n",
      "  batch   55: loss=1.264\n",
      "  batch   56: loss=1.017\n",
      "  batch   57: loss=0.919\n",
      "  batch   58: loss=1.506\n",
      "  batch   59: loss=1.579\n",
      "  batch   60: loss=1.184\n",
      "  batch   61: loss=1.023\n",
      "  batch   62: loss=1.355\n",
      "  batch   63: loss=1.346\n",
      "  batch   64: loss=1.324\n",
      "  batch   65: loss=1.069\n",
      "  batch   66: loss=1.076\n",
      "  batch   67: loss=1.022\n",
      "  batch   68: loss=1.015\n",
      "  batch   69: loss=1.592\n",
      "  batch   70: loss=1.254\n",
      "  batch   71: loss=1.027\n",
      "  batch   72: loss=1.472\n",
      "  batch   73: loss=1.360\n",
      "  batch   74: loss=1.264\n",
      "  batch   75: loss=1.483\n",
      "  batch   76: loss=1.291\n",
      "  batch   77: loss=1.457\n",
      "  batch   78: loss=1.310\n",
      "  batch   79: loss=1.367\n",
      "  batch   80: loss=1.223\n",
      "  batch   81: loss=1.560\n",
      "  batch   82: loss=1.876\n",
      "Testing on validation set\n",
      "  acc=0.645\n",
      "Training epoch 31\n",
      "  batch    1: loss=1.349\n",
      "  batch    2: loss=1.548\n",
      "  batch    3: loss=1.049\n",
      "  batch    4: loss=1.380\n",
      "  batch    5: loss=1.153\n",
      "  batch    6: loss=1.287\n",
      "  batch    7: loss=1.205\n",
      "  batch    8: loss=1.233\n",
      "  batch    9: loss=1.229\n",
      "  batch   10: loss=1.042\n",
      "  batch   11: loss=1.110\n",
      "  batch   12: loss=1.369\n",
      "  batch   13: loss=1.101\n",
      "  batch   14: loss=1.632\n",
      "  batch   15: loss=1.156\n",
      "  batch   16: loss=1.363\n",
      "  batch   17: loss=1.370\n",
      "  batch   18: loss=1.497\n",
      "  batch   19: loss=1.074\n",
      "  batch   20: loss=1.374\n",
      "  batch   21: loss=1.473\n",
      "  batch   22: loss=1.270\n",
      "  batch   23: loss=0.922\n",
      "  batch   24: loss=1.214\n",
      "  batch   25: loss=1.365\n",
      "  batch   26: loss=0.978\n",
      "  batch   27: loss=1.392\n",
      "  batch   28: loss=1.266\n",
      "  batch   29: loss=1.108\n",
      "  batch   30: loss=1.076\n",
      "  batch   31: loss=1.569\n",
      "  batch   32: loss=1.012\n",
      "  batch   33: loss=1.363\n",
      "  batch   34: loss=1.297\n",
      "  batch   35: loss=1.392\n",
      "  batch   36: loss=1.461\n",
      "  batch   37: loss=1.136\n",
      "  batch   38: loss=1.137\n",
      "  batch   39: loss=1.261\n",
      "  batch   40: loss=0.912\n",
      "  batch   41: loss=1.212\n",
      "  batch   42: loss=1.488\n",
      "  batch   43: loss=1.431\n",
      "  batch   44: loss=1.246\n",
      "  batch   45: loss=1.418\n",
      "  batch   46: loss=1.030\n",
      "  batch   47: loss=1.284\n",
      "  batch   48: loss=1.251\n",
      "  batch   49: loss=1.440\n",
      "  batch   50: loss=1.134\n",
      "  batch   51: loss=1.224\n",
      "  batch   52: loss=1.343\n",
      "  batch   53: loss=1.057\n",
      "  batch   54: loss=1.435\n",
      "  batch   55: loss=1.901\n",
      "  batch   56: loss=1.377\n",
      "  batch   57: loss=1.420\n",
      "  batch   58: loss=1.095\n",
      "  batch   59: loss=1.314\n",
      "  batch   60: loss=1.256\n",
      "  batch   61: loss=1.147\n",
      "  batch   62: loss=1.746\n",
      "  batch   63: loss=1.544\n",
      "  batch   64: loss=0.977\n",
      "  batch   65: loss=1.039\n",
      "  batch   66: loss=1.222\n",
      "  batch   67: loss=1.440\n",
      "  batch   68: loss=1.143\n",
      "  batch   69: loss=1.162\n",
      "  batch   70: loss=1.248\n",
      "  batch   71: loss=1.711\n",
      "  batch   72: loss=1.239\n",
      "  batch   73: loss=1.424\n",
      "  batch   74: loss=1.194\n",
      "  batch   75: loss=1.173\n",
      "  batch   76: loss=1.304\n",
      "  batch   77: loss=1.019\n",
      "  batch   78: loss=0.788\n",
      "  batch   79: loss=1.000\n",
      "  batch   80: loss=1.086\n",
      "  batch   81: loss=1.587\n",
      "  batch   82: loss=1.500\n",
      "Testing on validation set\n",
      "  acc=0.645\n",
      "Training epoch 32\n",
      "  batch    1: loss=0.805\n",
      "  batch    2: loss=1.021\n",
      "  batch    3: loss=1.080\n",
      "  batch    4: loss=1.066\n",
      "  batch    5: loss=0.879\n",
      "  batch    6: loss=1.183\n",
      "  batch    7: loss=1.126\n",
      "  batch    8: loss=0.813\n",
      "  batch    9: loss=0.903\n",
      "  batch   10: loss=2.022\n",
      "  batch   11: loss=1.320\n",
      "  batch   12: loss=0.806\n",
      "  batch   13: loss=1.348\n",
      "  batch   14: loss=1.404\n",
      "  batch   15: loss=1.433\n",
      "  batch   16: loss=1.211\n",
      "  batch   17: loss=1.669\n",
      "  batch   18: loss=1.518\n",
      "  batch   19: loss=1.072\n",
      "  batch   20: loss=0.967\n",
      "  batch   21: loss=1.165\n",
      "  batch   22: loss=1.256\n",
      "  batch   23: loss=1.467\n",
      "  batch   24: loss=1.006\n",
      "  batch   25: loss=1.536\n",
      "  batch   26: loss=1.228\n",
      "  batch   27: loss=1.002\n",
      "  batch   28: loss=1.390\n",
      "  batch   29: loss=1.676\n",
      "  batch   30: loss=1.347\n",
      "  batch   31: loss=1.386\n",
      "  batch   32: loss=1.109\n",
      "  batch   33: loss=1.426\n",
      "  batch   34: loss=1.324\n",
      "  batch   35: loss=1.033\n",
      "  batch   36: loss=1.163\n",
      "  batch   37: loss=0.992\n",
      "  batch   38: loss=1.479\n",
      "  batch   39: loss=1.374\n",
      "  batch   40: loss=1.385\n",
      "  batch   41: loss=1.377\n",
      "  batch   42: loss=1.195\n",
      "  batch   43: loss=1.272\n",
      "  batch   44: loss=1.540\n",
      "  batch   45: loss=0.944\n",
      "  batch   46: loss=1.348\n",
      "  batch   47: loss=0.907\n",
      "  batch   48: loss=1.347\n",
      "  batch   49: loss=1.276\n",
      "  batch   50: loss=1.095\n",
      "  batch   51: loss=1.346\n",
      "  batch   52: loss=1.581\n",
      "  batch   53: loss=1.192\n",
      "  batch   54: loss=1.167\n",
      "  batch   55: loss=1.105\n",
      "  batch   56: loss=1.142\n",
      "  batch   57: loss=1.316\n",
      "  batch   58: loss=1.183\n",
      "  batch   59: loss=1.454\n",
      "  batch   60: loss=1.537\n",
      "  batch   61: loss=1.413\n",
      "  batch   62: loss=1.397\n",
      "  batch   63: loss=1.019\n",
      "  batch   64: loss=1.013\n",
      "  batch   65: loss=1.144\n",
      "  batch   66: loss=0.960\n",
      "  batch   67: loss=1.659\n",
      "  batch   68: loss=1.281\n",
      "  batch   69: loss=1.477\n",
      "  batch   70: loss=1.121\n",
      "  batch   71: loss=1.453\n",
      "  batch   72: loss=1.155\n",
      "  batch   73: loss=1.399\n",
      "  batch   74: loss=1.164\n",
      "  batch   75: loss=1.246\n",
      "  batch   76: loss=1.222\n",
      "  batch   77: loss=1.347\n",
      "  batch   78: loss=1.016\n",
      "  batch   79: loss=1.295\n",
      "  batch   80: loss=1.253\n",
      "  batch   81: loss=1.677\n",
      "  batch   82: loss=1.337\n",
      "Testing on validation set\n",
      "  acc=0.622\n",
      "Training epoch 33\n",
      "  batch    1: loss=0.936\n",
      "  batch    2: loss=1.106\n",
      "  batch    3: loss=1.062\n",
      "  batch    4: loss=1.259\n",
      "  batch    5: loss=1.364\n",
      "  batch    6: loss=1.163\n",
      "  batch    7: loss=1.503\n",
      "  batch    8: loss=0.950\n",
      "  batch    9: loss=1.380\n",
      "  batch   10: loss=0.978\n",
      "  batch   11: loss=1.608\n",
      "  batch   12: loss=1.260\n",
      "  batch   13: loss=0.878\n",
      "  batch   14: loss=1.060\n",
      "  batch   15: loss=1.360\n",
      "  batch   16: loss=1.376\n",
      "  batch   17: loss=1.464\n",
      "  batch   18: loss=1.309\n",
      "  batch   19: loss=1.080\n",
      "  batch   20: loss=1.540\n",
      "  batch   21: loss=1.276\n",
      "  batch   22: loss=1.248\n",
      "  batch   23: loss=1.209\n",
      "  batch   24: loss=1.736\n",
      "  batch   25: loss=1.100\n",
      "  batch   26: loss=1.122\n",
      "  batch   27: loss=1.439\n",
      "  batch   28: loss=1.183\n",
      "  batch   29: loss=0.993\n",
      "  batch   30: loss=1.060\n",
      "  batch   31: loss=1.279\n",
      "  batch   32: loss=1.502\n",
      "  batch   33: loss=1.229\n",
      "  batch   34: loss=1.187\n",
      "  batch   35: loss=1.531\n",
      "  batch   36: loss=1.149\n",
      "  batch   37: loss=1.590\n",
      "  batch   38: loss=1.156\n",
      "  batch   39: loss=1.323\n",
      "  batch   40: loss=1.096\n",
      "  batch   41: loss=1.165\n",
      "  batch   42: loss=1.276\n",
      "  batch   43: loss=0.961\n",
      "  batch   44: loss=1.234\n",
      "  batch   45: loss=1.250\n",
      "  batch   46: loss=1.121\n",
      "  batch   47: loss=1.319\n",
      "  batch   48: loss=1.153\n",
      "  batch   49: loss=1.232\n",
      "  batch   50: loss=1.377\n",
      "  batch   51: loss=1.343\n",
      "  batch   52: loss=0.895\n",
      "  batch   53: loss=1.085\n",
      "  batch   54: loss=1.285\n",
      "  batch   55: loss=1.267\n",
      "  batch   56: loss=1.448\n",
      "  batch   57: loss=1.507\n",
      "  batch   58: loss=1.314\n",
      "  batch   59: loss=1.147\n",
      "  batch   60: loss=1.446\n",
      "  batch   61: loss=1.252\n",
      "  batch   62: loss=1.540\n",
      "  batch   63: loss=0.906\n",
      "  batch   64: loss=1.245\n",
      "  batch   65: loss=1.224\n",
      "  batch   66: loss=1.288\n",
      "  batch   67: loss=1.264\n",
      "  batch   68: loss=0.983\n",
      "  batch   69: loss=1.351\n",
      "  batch   70: loss=1.188\n",
      "  batch   71: loss=1.420\n",
      "  batch   72: loss=1.309\n",
      "  batch   73: loss=1.353\n",
      "  batch   74: loss=1.482\n",
      "  batch   75: loss=1.266\n",
      "  batch   76: loss=1.070\n",
      "  batch   77: loss=1.374\n",
      "  batch   78: loss=0.952\n",
      "  batch   79: loss=1.395\n",
      "  batch   80: loss=1.242\n",
      "  batch   81: loss=1.337\n",
      "  batch   82: loss=1.535\n",
      "Testing on validation set\n",
      "  acc=0.654\n",
      "Training epoch 34\n",
      "  batch    1: loss=1.222\n",
      "  batch    2: loss=1.395\n",
      "  batch    3: loss=1.041\n",
      "  batch    4: loss=0.878\n",
      "  batch    5: loss=1.430\n",
      "  batch    6: loss=1.473\n",
      "  batch    7: loss=0.783\n",
      "  batch    8: loss=0.905\n",
      "  batch    9: loss=1.074\n",
      "  batch   10: loss=0.963\n",
      "  batch   11: loss=1.041\n",
      "  batch   12: loss=1.507\n",
      "  batch   13: loss=1.515\n",
      "  batch   14: loss=1.401\n",
      "  batch   15: loss=1.193\n",
      "  batch   16: loss=1.177\n",
      "  batch   17: loss=1.597\n",
      "  batch   18: loss=1.634\n",
      "  batch   19: loss=1.328\n",
      "  batch   20: loss=1.156\n",
      "  batch   21: loss=1.145\n",
      "  batch   22: loss=1.165\n",
      "  batch   23: loss=1.228\n",
      "  batch   24: loss=1.150\n",
      "  batch   25: loss=0.862\n",
      "  batch   26: loss=1.083\n",
      "  batch   27: loss=1.463\n",
      "  batch   28: loss=1.239\n",
      "  batch   29: loss=1.044\n",
      "  batch   30: loss=1.434\n",
      "  batch   31: loss=1.146\n",
      "  batch   32: loss=1.103\n",
      "  batch   33: loss=1.374\n",
      "  batch   34: loss=1.781\n",
      "  batch   35: loss=0.883\n",
      "  batch   36: loss=1.156\n",
      "  batch   37: loss=1.319\n",
      "  batch   38: loss=1.525\n",
      "  batch   39: loss=1.219\n",
      "  batch   40: loss=1.068\n",
      "  batch   41: loss=1.226\n",
      "  batch   42: loss=1.111\n",
      "  batch   43: loss=0.999\n",
      "  batch   44: loss=1.108\n",
      "  batch   45: loss=1.045\n",
      "  batch   46: loss=1.667\n",
      "  batch   47: loss=1.115\n",
      "  batch   48: loss=1.032\n",
      "  batch   49: loss=1.261\n",
      "  batch   50: loss=1.438\n",
      "  batch   51: loss=0.847\n",
      "  batch   52: loss=1.164\n",
      "  batch   53: loss=1.143\n",
      "  batch   54: loss=0.790\n",
      "  batch   55: loss=0.877\n",
      "  batch   56: loss=1.552\n",
      "  batch   57: loss=1.250\n",
      "  batch   58: loss=1.344\n",
      "  batch   59: loss=1.378\n",
      "  batch   60: loss=1.072\n",
      "  batch   61: loss=1.133\n",
      "  batch   62: loss=1.608\n",
      "  batch   63: loss=1.312\n",
      "  batch   64: loss=1.433\n",
      "  batch   65: loss=1.205\n",
      "  batch   66: loss=1.004\n",
      "  batch   67: loss=1.546\n",
      "  batch   68: loss=1.249\n",
      "  batch   69: loss=0.995\n",
      "  batch   70: loss=1.104\n",
      "  batch   71: loss=1.038\n",
      "  batch   72: loss=1.434\n",
      "  batch   73: loss=1.169\n",
      "  batch   74: loss=1.192\n",
      "  batch   75: loss=1.336\n",
      "  batch   76: loss=1.246\n",
      "  batch   77: loss=1.248\n",
      "  batch   78: loss=1.124\n",
      "  batch   79: loss=1.146\n",
      "  batch   80: loss=1.505\n",
      "  batch   81: loss=1.313\n",
      "  batch   82: loss=1.285\n",
      "Testing on validation set\n",
      "  acc=0.643\n",
      "Training epoch 35\n",
      "  batch    1: loss=0.861\n",
      "  batch    2: loss=1.562\n",
      "  batch    3: loss=1.243\n",
      "  batch    4: loss=1.061\n",
      "  batch    5: loss=1.056\n",
      "  batch    6: loss=1.570\n",
      "  batch    7: loss=0.838\n",
      "  batch    8: loss=1.279\n",
      "  batch    9: loss=1.145\n",
      "  batch   10: loss=1.254\n",
      "  batch   11: loss=1.056\n",
      "  batch   12: loss=1.010\n",
      "  batch   13: loss=1.381\n",
      "  batch   14: loss=1.394\n",
      "  batch   15: loss=1.114\n",
      "  batch   16: loss=1.346\n",
      "  batch   17: loss=0.986\n",
      "  batch   18: loss=1.055\n",
      "  batch   19: loss=1.487\n",
      "  batch   20: loss=0.963\n",
      "  batch   21: loss=1.056\n",
      "  batch   22: loss=0.958\n",
      "  batch   23: loss=1.243\n",
      "  batch   24: loss=1.123\n",
      "  batch   25: loss=1.014\n",
      "  batch   26: loss=0.964\n",
      "  batch   27: loss=0.938\n",
      "  batch   28: loss=0.821\n",
      "  batch   29: loss=1.022\n",
      "  batch   30: loss=1.057\n",
      "  batch   31: loss=1.022\n",
      "  batch   32: loss=1.401\n",
      "  batch   33: loss=0.998\n",
      "  batch   34: loss=1.141\n",
      "  batch   35: loss=1.113\n",
      "  batch   36: loss=1.077\n",
      "  batch   37: loss=0.956\n",
      "  batch   38: loss=1.281\n",
      "  batch   39: loss=1.307\n",
      "  batch   40: loss=0.750\n",
      "  batch   41: loss=1.232\n",
      "  batch   42: loss=1.294\n",
      "  batch   43: loss=1.194\n",
      "  batch   44: loss=0.625\n",
      "  batch   45: loss=0.783\n",
      "  batch   46: loss=1.210\n",
      "  batch   47: loss=1.167\n",
      "  batch   48: loss=1.651\n",
      "  batch   49: loss=1.317\n",
      "  batch   50: loss=1.065\n",
      "  batch   51: loss=1.520\n",
      "  batch   52: loss=1.117\n",
      "  batch   53: loss=0.950\n",
      "  batch   54: loss=1.007\n",
      "  batch   55: loss=1.141\n",
      "  batch   56: loss=1.110\n",
      "  batch   57: loss=1.220\n",
      "  batch   58: loss=1.292\n",
      "  batch   59: loss=0.926\n",
      "  batch   60: loss=0.973\n",
      "  batch   61: loss=1.567\n",
      "  batch   62: loss=1.267\n",
      "  batch   63: loss=0.939\n",
      "  batch   64: loss=1.261\n",
      "  batch   65: loss=1.071\n",
      "  batch   66: loss=0.894\n",
      "  batch   67: loss=1.193\n",
      "  batch   68: loss=1.145\n",
      "  batch   69: loss=1.243\n",
      "  batch   70: loss=0.867\n",
      "  batch   71: loss=0.863\n",
      "  batch   72: loss=0.980\n",
      "  batch   73: loss=1.105\n",
      "  batch   74: loss=1.180\n",
      "  batch   75: loss=1.105\n",
      "  batch   76: loss=1.222\n",
      "  batch   77: loss=1.164\n",
      "  batch   78: loss=0.982\n",
      "  batch   79: loss=1.196\n",
      "  batch   80: loss=1.157\n",
      "  batch   81: loss=1.053\n",
      "  batch   82: loss=0.686\n",
      "Testing on validation set\n",
      "  acc=0.660\n",
      "Training epoch 36\n",
      "  batch    1: loss=0.958\n",
      "  batch    2: loss=0.900\n",
      "  batch    3: loss=0.847\n",
      "  batch    4: loss=1.309\n",
      "  batch    5: loss=1.279\n",
      "  batch    6: loss=1.257\n",
      "  batch    7: loss=1.086\n",
      "  batch    8: loss=1.065\n",
      "  batch    9: loss=0.985\n",
      "  batch   10: loss=1.265\n",
      "  batch   11: loss=1.165\n",
      "  batch   12: loss=1.156\n",
      "  batch   13: loss=1.303\n",
      "  batch   14: loss=0.888\n",
      "  batch   15: loss=1.132\n",
      "  batch   16: loss=0.973\n",
      "  batch   17: loss=1.382\n",
      "  batch   18: loss=1.132\n",
      "  batch   19: loss=1.252\n",
      "  batch   20: loss=1.250\n",
      "  batch   21: loss=0.993\n",
      "  batch   22: loss=1.146\n",
      "  batch   23: loss=0.919\n",
      "  batch   24: loss=1.050\n",
      "  batch   25: loss=1.088\n",
      "  batch   26: loss=0.883\n",
      "  batch   27: loss=1.300\n",
      "  batch   28: loss=1.145\n",
      "  batch   29: loss=1.243\n",
      "  batch   30: loss=1.101\n",
      "  batch   31: loss=0.899\n",
      "  batch   32: loss=0.923\n",
      "  batch   33: loss=0.928\n",
      "  batch   34: loss=0.968\n",
      "  batch   35: loss=1.503\n",
      "  batch   36: loss=1.141\n",
      "  batch   37: loss=1.211\n",
      "  batch   38: loss=0.819\n",
      "  batch   39: loss=1.393\n",
      "  batch   40: loss=1.033\n",
      "  batch   41: loss=0.858\n",
      "  batch   42: loss=0.950\n",
      "  batch   43: loss=1.105\n",
      "  batch   44: loss=0.843\n",
      "  batch   45: loss=1.097\n",
      "  batch   46: loss=1.203\n",
      "  batch   47: loss=1.153\n",
      "  batch   48: loss=0.764\n",
      "  batch   49: loss=0.815\n",
      "  batch   50: loss=1.106\n",
      "  batch   51: loss=1.366\n",
      "  batch   52: loss=1.068\n",
      "  batch   53: loss=1.064\n",
      "  batch   54: loss=1.184\n",
      "  batch   55: loss=1.096\n",
      "  batch   56: loss=1.529\n",
      "  batch   57: loss=1.374\n",
      "  batch   58: loss=1.297\n",
      "  batch   59: loss=1.289\n",
      "  batch   60: loss=1.220\n",
      "  batch   61: loss=1.328\n",
      "  batch   62: loss=0.911\n",
      "  batch   63: loss=1.322\n",
      "  batch   64: loss=1.009\n",
      "  batch   65: loss=1.377\n",
      "  batch   66: loss=1.045\n",
      "  batch   67: loss=1.210\n",
      "  batch   68: loss=1.379\n",
      "  batch   69: loss=1.276\n",
      "  batch   70: loss=0.907\n",
      "  batch   71: loss=1.105\n",
      "  batch   72: loss=1.205\n",
      "  batch   73: loss=0.843\n",
      "  batch   74: loss=1.176\n",
      "  batch   75: loss=0.985\n",
      "  batch   76: loss=1.308\n",
      "  batch   77: loss=1.377\n",
      "  batch   78: loss=1.267\n",
      "  batch   79: loss=1.122\n",
      "  batch   80: loss=1.163\n",
      "  batch   81: loss=1.284\n",
      "  batch   82: loss=1.199\n",
      "Testing on validation set\n",
      "  acc=0.680\n",
      "Training epoch 37\n",
      "  batch    1: loss=1.230\n",
      "  batch    2: loss=0.900\n",
      "  batch    3: loss=1.057\n",
      "  batch    4: loss=1.030\n",
      "  batch    5: loss=0.977\n",
      "  batch    6: loss=0.811\n",
      "  batch    7: loss=1.138\n",
      "  batch    8: loss=0.913\n",
      "  batch    9: loss=1.074\n",
      "  batch   10: loss=1.294\n",
      "  batch   11: loss=1.031\n",
      "  batch   12: loss=1.329\n",
      "  batch   13: loss=0.851\n",
      "  batch   14: loss=0.929\n",
      "  batch   15: loss=1.006\n",
      "  batch   16: loss=1.341\n",
      "  batch   17: loss=1.107\n",
      "  batch   18: loss=1.087\n",
      "  batch   19: loss=1.167\n",
      "  batch   20: loss=0.876\n",
      "  batch   21: loss=1.197\n",
      "  batch   22: loss=0.887\n",
      "  batch   23: loss=1.316\n",
      "  batch   24: loss=1.224\n",
      "  batch   25: loss=1.419\n",
      "  batch   26: loss=1.265\n",
      "  batch   27: loss=1.065\n",
      "  batch   28: loss=0.761\n",
      "  batch   29: loss=1.499\n",
      "  batch   30: loss=1.095\n",
      "  batch   31: loss=1.246\n",
      "  batch   32: loss=0.987\n",
      "  batch   33: loss=0.906\n",
      "  batch   34: loss=1.020\n",
      "  batch   35: loss=0.975\n",
      "  batch   36: loss=1.051\n",
      "  batch   37: loss=1.274\n",
      "  batch   38: loss=1.198\n",
      "  batch   39: loss=1.054\n",
      "  batch   40: loss=0.940\n",
      "  batch   41: loss=0.926\n",
      "  batch   42: loss=0.832\n",
      "  batch   43: loss=1.190\n",
      "  batch   44: loss=0.841\n",
      "  batch   45: loss=0.869\n",
      "  batch   46: loss=1.310\n",
      "  batch   47: loss=1.111\n",
      "  batch   48: loss=1.175\n",
      "  batch   49: loss=0.953\n",
      "  batch   50: loss=1.202\n",
      "  batch   51: loss=1.055\n",
      "  batch   52: loss=1.655\n",
      "  batch   53: loss=1.081\n",
      "  batch   54: loss=1.004\n",
      "  batch   55: loss=1.001\n",
      "  batch   56: loss=1.243\n",
      "  batch   57: loss=0.927\n",
      "  batch   58: loss=0.915\n",
      "  batch   59: loss=1.036\n",
      "  batch   60: loss=1.551\n",
      "  batch   61: loss=0.678\n",
      "  batch   62: loss=1.707\n",
      "  batch   63: loss=0.846\n",
      "  batch   64: loss=0.873\n",
      "  batch   65: loss=1.374\n",
      "  batch   66: loss=1.457\n",
      "  batch   67: loss=1.334\n",
      "  batch   68: loss=1.043\n",
      "  batch   69: loss=1.306\n",
      "  batch   70: loss=1.125\n",
      "  batch   71: loss=1.392\n",
      "  batch   72: loss=1.136\n",
      "  batch   73: loss=1.192\n",
      "  batch   74: loss=1.220\n",
      "  batch   75: loss=1.277\n",
      "  batch   76: loss=0.880\n",
      "  batch   77: loss=0.876\n",
      "  batch   78: loss=1.460\n",
      "  batch   79: loss=1.133\n",
      "  batch   80: loss=1.007\n",
      "  batch   81: loss=1.152\n",
      "  batch   82: loss=1.539\n",
      "Testing on validation set\n",
      "  acc=0.658\n",
      "Training epoch 38\n",
      "  batch    1: loss=1.026\n",
      "  batch    2: loss=1.344\n",
      "  batch    3: loss=0.798\n",
      "  batch    4: loss=0.688\n",
      "  batch    5: loss=1.104\n",
      "  batch    6: loss=1.416\n",
      "  batch    7: loss=1.185\n",
      "  batch    8: loss=1.332\n",
      "  batch    9: loss=1.180\n",
      "  batch   10: loss=0.864\n",
      "  batch   11: loss=1.154\n",
      "  batch   12: loss=1.071\n",
      "  batch   13: loss=0.952\n",
      "  batch   14: loss=1.565\n",
      "  batch   15: loss=1.114\n",
      "  batch   16: loss=0.991\n",
      "  batch   17: loss=1.062\n",
      "  batch   18: loss=1.239\n",
      "  batch   19: loss=0.846\n",
      "  batch   20: loss=1.094\n",
      "  batch   21: loss=1.036\n",
      "  batch   22: loss=1.123\n",
      "  batch   23: loss=1.179\n",
      "  batch   24: loss=1.183\n",
      "  batch   25: loss=0.705\n",
      "  batch   26: loss=0.991\n",
      "  batch   27: loss=1.025\n",
      "  batch   28: loss=0.757\n",
      "  batch   29: loss=1.160\n",
      "  batch   30: loss=1.212\n",
      "  batch   31: loss=1.065\n",
      "  batch   32: loss=0.815\n",
      "  batch   33: loss=1.134\n",
      "  batch   34: loss=0.882\n",
      "  batch   35: loss=1.118\n",
      "  batch   36: loss=0.967\n",
      "  batch   37: loss=1.278\n",
      "  batch   38: loss=0.882\n",
      "  batch   39: loss=1.468\n",
      "  batch   40: loss=1.100\n",
      "  batch   41: loss=1.071\n",
      "  batch   42: loss=1.250\n",
      "  batch   43: loss=0.770\n",
      "  batch   44: loss=1.170\n",
      "  batch   45: loss=1.427\n",
      "  batch   46: loss=1.230\n",
      "  batch   47: loss=1.240\n",
      "  batch   48: loss=0.862\n",
      "  batch   49: loss=1.460\n",
      "  batch   50: loss=1.050\n",
      "  batch   51: loss=1.416\n",
      "  batch   52: loss=1.523\n",
      "  batch   53: loss=0.942\n",
      "  batch   54: loss=1.127\n",
      "  batch   55: loss=0.887\n",
      "  batch   56: loss=1.085\n",
      "  batch   57: loss=1.172\n",
      "  batch   58: loss=1.456\n",
      "  batch   59: loss=0.908\n",
      "  batch   60: loss=1.231\n",
      "  batch   61: loss=1.575\n",
      "  batch   62: loss=1.308\n",
      "  batch   63: loss=1.023\n",
      "  batch   64: loss=1.189\n",
      "  batch   65: loss=1.115\n",
      "  batch   66: loss=1.249\n",
      "  batch   67: loss=1.302\n",
      "  batch   68: loss=1.238\n",
      "  batch   69: loss=1.205\n",
      "  batch   70: loss=0.960\n",
      "  batch   71: loss=1.025\n",
      "  batch   72: loss=1.119\n",
      "  batch   73: loss=0.982\n",
      "  batch   74: loss=0.839\n",
      "  batch   75: loss=1.050\n",
      "  batch   76: loss=1.294\n",
      "  batch   77: loss=1.228\n",
      "  batch   78: loss=0.764\n",
      "  batch   79: loss=1.018\n",
      "  batch   80: loss=1.086\n",
      "  batch   81: loss=1.180\n",
      "  batch   82: loss=1.880\n",
      "Testing on validation set\n",
      "  acc=0.665\n",
      "Training epoch 39\n",
      "  batch    1: loss=0.874\n",
      "  batch    2: loss=1.252\n",
      "  batch    3: loss=0.919\n",
      "  batch    4: loss=0.979\n",
      "  batch    5: loss=1.025\n",
      "  batch    6: loss=0.815\n",
      "  batch    7: loss=0.810\n",
      "  batch    8: loss=0.845\n",
      "  batch    9: loss=1.002\n",
      "  batch   10: loss=1.330\n",
      "  batch   11: loss=1.042\n",
      "  batch   12: loss=1.462\n",
      "  batch   13: loss=1.239\n",
      "  batch   14: loss=0.888\n",
      "  batch   15: loss=1.007\n",
      "  batch   16: loss=1.089\n",
      "  batch   17: loss=1.191\n",
      "  batch   18: loss=1.275\n",
      "  batch   19: loss=0.864\n",
      "  batch   20: loss=0.946\n",
      "  batch   21: loss=1.108\n",
      "  batch   22: loss=0.825\n",
      "  batch   23: loss=0.964\n",
      "  batch   24: loss=1.090\n",
      "  batch   25: loss=1.160\n",
      "  batch   26: loss=1.606\n",
      "  batch   27: loss=1.024\n",
      "  batch   28: loss=1.289\n",
      "  batch   29: loss=0.932\n",
      "  batch   30: loss=0.897\n",
      "  batch   31: loss=0.933\n",
      "  batch   32: loss=0.939\n",
      "  batch   33: loss=1.039\n",
      "  batch   34: loss=1.530\n",
      "  batch   35: loss=0.984\n",
      "  batch   36: loss=1.133\n",
      "  batch   37: loss=0.943\n",
      "  batch   38: loss=1.148\n",
      "  batch   39: loss=0.816\n",
      "  batch   40: loss=1.084\n",
      "  batch   41: loss=0.760\n",
      "  batch   42: loss=0.935\n",
      "  batch   43: loss=1.078\n",
      "  batch   44: loss=1.107\n",
      "  batch   45: loss=1.034\n",
      "  batch   46: loss=1.076\n",
      "  batch   47: loss=1.028\n",
      "  batch   48: loss=0.868\n",
      "  batch   49: loss=1.060\n",
      "  batch   50: loss=1.048\n",
      "  batch   51: loss=0.943\n",
      "  batch   52: loss=1.177\n",
      "  batch   53: loss=1.115\n",
      "  batch   54: loss=1.054\n",
      "  batch   55: loss=0.932\n",
      "  batch   56: loss=1.234\n",
      "  batch   57: loss=0.931\n",
      "  batch   58: loss=0.695\n",
      "  batch   59: loss=1.056\n",
      "  batch   60: loss=0.928\n",
      "  batch   61: loss=0.827\n",
      "  batch   62: loss=0.958\n",
      "  batch   63: loss=1.108\n",
      "  batch   64: loss=1.091\n",
      "  batch   65: loss=1.192\n",
      "  batch   66: loss=1.289\n",
      "  batch   67: loss=1.207\n",
      "  batch   68: loss=1.003\n",
      "  batch   69: loss=0.920\n",
      "  batch   70: loss=1.060\n",
      "  batch   71: loss=0.847\n",
      "  batch   72: loss=0.984\n",
      "  batch   73: loss=1.103\n",
      "  batch   74: loss=1.306\n",
      "  batch   75: loss=1.031\n",
      "  batch   76: loss=0.837\n",
      "  batch   77: loss=1.080\n",
      "  batch   78: loss=1.104\n",
      "  batch   79: loss=1.551\n",
      "  batch   80: loss=1.030\n",
      "  batch   81: loss=1.193\n",
      "  batch   82: loss=1.137\n",
      "Testing on validation set\n",
      "  acc=0.667\n",
      "Training epoch 40\n",
      "  batch    1: loss=1.045\n",
      "  batch    2: loss=1.160\n",
      "  batch    3: loss=0.968\n",
      "  batch    4: loss=1.230\n",
      "  batch    5: loss=1.113\n",
      "  batch    6: loss=1.349\n",
      "  batch    7: loss=1.124\n",
      "  batch    8: loss=0.823\n",
      "  batch    9: loss=1.142\n",
      "  batch   10: loss=0.836\n",
      "  batch   11: loss=0.940\n",
      "  batch   12: loss=0.925\n",
      "  batch   13: loss=0.950\n",
      "  batch   14: loss=0.781\n",
      "  batch   15: loss=1.246\n",
      "  batch   16: loss=0.775\n",
      "  batch   17: loss=1.239\n",
      "  batch   18: loss=0.988\n",
      "  batch   19: loss=1.098\n",
      "  batch   20: loss=1.130\n",
      "  batch   21: loss=1.366\n",
      "  batch   22: loss=0.848\n",
      "  batch   23: loss=1.228\n",
      "  batch   24: loss=0.996\n",
      "  batch   25: loss=1.325\n",
      "  batch   26: loss=0.974\n",
      "  batch   27: loss=0.883\n",
      "  batch   28: loss=0.863\n",
      "  batch   29: loss=0.871\n",
      "  batch   30: loss=1.203\n",
      "  batch   31: loss=0.931\n",
      "  batch   32: loss=1.085\n",
      "  batch   33: loss=1.192\n",
      "  batch   34: loss=0.916\n",
      "  batch   35: loss=1.168\n",
      "  batch   36: loss=1.191\n",
      "  batch   37: loss=0.973\n",
      "  batch   38: loss=0.839\n",
      "  batch   39: loss=0.953\n",
      "  batch   40: loss=1.292\n",
      "  batch   41: loss=1.140\n",
      "  batch   42: loss=1.015\n",
      "  batch   43: loss=1.290\n",
      "  batch   44: loss=1.026\n",
      "  batch   45: loss=1.023\n",
      "  batch   46: loss=0.909\n",
      "  batch   47: loss=1.492\n",
      "  batch   48: loss=1.100\n",
      "  batch   49: loss=1.017\n",
      "  batch   50: loss=1.598\n",
      "  batch   51: loss=1.073\n",
      "  batch   52: loss=1.154\n",
      "  batch   53: loss=0.828\n",
      "  batch   54: loss=0.825\n",
      "  batch   55: loss=1.053\n",
      "  batch   56: loss=1.078\n",
      "  batch   57: loss=1.008\n",
      "  batch   58: loss=1.106\n",
      "  batch   59: loss=1.159\n",
      "  batch   60: loss=1.039\n",
      "  batch   61: loss=1.206\n",
      "  batch   62: loss=1.389\n",
      "  batch   63: loss=1.103\n",
      "  batch   64: loss=1.132\n",
      "  batch   65: loss=1.073\n",
      "  batch   66: loss=0.859\n",
      "  batch   67: loss=0.771\n",
      "  batch   68: loss=1.413\n",
      "  batch   69: loss=1.234\n",
      "  batch   70: loss=1.066\n",
      "  batch   71: loss=1.116\n",
      "  batch   72: loss=0.757\n",
      "  batch   73: loss=0.843\n",
      "  batch   74: loss=0.842\n",
      "  batch   75: loss=1.277\n",
      "  batch   76: loss=1.166\n",
      "  batch   77: loss=1.097\n",
      "  batch   78: loss=0.773\n",
      "  batch   79: loss=1.272\n",
      "  batch   80: loss=0.808\n",
      "  batch   81: loss=1.204\n",
      "  batch   82: loss=1.639\n",
      "Testing on validation set\n",
      "  acc=0.668\n",
      "Training epoch 41\n",
      "  batch    1: loss=0.816\n",
      "  batch    2: loss=0.896\n",
      "  batch    3: loss=1.102\n",
      "  batch    4: loss=0.844\n",
      "  batch    5: loss=1.098\n",
      "  batch    6: loss=1.018\n",
      "  batch    7: loss=1.250\n",
      "  batch    8: loss=0.707\n",
      "  batch    9: loss=1.169\n",
      "  batch   10: loss=0.931\n",
      "  batch   11: loss=1.002\n",
      "  batch   12: loss=1.049\n",
      "  batch   13: loss=1.089\n",
      "  batch   14: loss=1.252\n",
      "  batch   15: loss=1.140\n",
      "  batch   16: loss=0.870\n",
      "  batch   17: loss=0.775\n",
      "  batch   18: loss=1.089\n",
      "  batch   19: loss=0.997\n",
      "  batch   20: loss=1.108\n",
      "  batch   21: loss=0.649\n",
      "  batch   22: loss=1.147\n",
      "  batch   23: loss=1.059\n",
      "  batch   24: loss=0.996\n",
      "  batch   25: loss=1.155\n",
      "  batch   26: loss=1.322\n",
      "  batch   27: loss=1.083\n",
      "  batch   28: loss=1.134\n",
      "  batch   29: loss=1.035\n",
      "  batch   30: loss=0.878\n",
      "  batch   31: loss=1.102\n",
      "  batch   32: loss=0.890\n",
      "  batch   33: loss=1.200\n",
      "  batch   34: loss=0.980\n",
      "  batch   35: loss=1.079\n",
      "  batch   36: loss=0.713\n",
      "  batch   37: loss=1.122\n",
      "  batch   38: loss=0.845\n",
      "  batch   39: loss=1.140\n",
      "  batch   40: loss=1.431\n",
      "  batch   41: loss=0.925\n",
      "  batch   42: loss=0.752\n",
      "  batch   43: loss=0.861\n",
      "  batch   44: loss=1.095\n",
      "  batch   45: loss=1.120\n",
      "  batch   46: loss=1.256\n",
      "  batch   47: loss=1.454\n",
      "  batch   48: loss=0.820\n",
      "  batch   49: loss=1.036\n",
      "  batch   50: loss=0.902\n",
      "  batch   51: loss=0.934\n",
      "  batch   52: loss=1.218\n",
      "  batch   53: loss=1.283\n",
      "  batch   54: loss=1.043\n",
      "  batch   55: loss=0.976\n",
      "  batch   56: loss=1.067\n",
      "  batch   57: loss=0.819\n",
      "  batch   58: loss=0.744\n",
      "  batch   59: loss=0.971\n",
      "  batch   60: loss=1.192\n",
      "  batch   61: loss=1.253\n",
      "  batch   62: loss=0.920\n",
      "  batch   63: loss=0.912\n",
      "  batch   64: loss=1.074\n",
      "  batch   65: loss=1.016\n",
      "  batch   66: loss=1.364\n",
      "  batch   67: loss=1.406\n",
      "  batch   68: loss=1.185\n",
      "  batch   69: loss=1.106\n",
      "  batch   70: loss=1.201\n",
      "  batch   71: loss=0.908\n",
      "  batch   72: loss=0.866\n",
      "  batch   73: loss=1.149\n",
      "  batch   74: loss=1.013\n",
      "  batch   75: loss=1.405\n",
      "  batch   76: loss=1.211\n",
      "  batch   77: loss=1.192\n",
      "  batch   78: loss=1.168\n",
      "  batch   79: loss=1.033\n",
      "  batch   80: loss=0.957\n",
      "  batch   81: loss=0.979\n",
      "  batch   82: loss=1.284\n",
      "Testing on validation set\n",
      "  acc=0.672\n",
      "Training epoch 42\n",
      "  batch    1: loss=0.725\n",
      "  batch    2: loss=0.749\n",
      "  batch    3: loss=1.154\n",
      "  batch    4: loss=0.975\n",
      "  batch    5: loss=1.046\n",
      "  batch    6: loss=1.016\n",
      "  batch    7: loss=1.013\n",
      "  batch    8: loss=1.168\n",
      "  batch    9: loss=0.904\n",
      "  batch   10: loss=1.175\n",
      "  batch   11: loss=0.868\n",
      "  batch   12: loss=0.899\n",
      "  batch   13: loss=0.958\n",
      "  batch   14: loss=0.824\n",
      "  batch   15: loss=0.916\n",
      "  batch   16: loss=1.066\n",
      "  batch   17: loss=1.192\n",
      "  batch   18: loss=0.938\n",
      "  batch   19: loss=1.061\n",
      "  batch   20: loss=1.302\n",
      "  batch   21: loss=0.748\n",
      "  batch   22: loss=0.803\n",
      "  batch   23: loss=1.143\n",
      "  batch   24: loss=1.203\n",
      "  batch   25: loss=1.106\n",
      "  batch   26: loss=0.910\n",
      "  batch   27: loss=1.114\n",
      "  batch   28: loss=0.863\n",
      "  batch   29: loss=0.897\n",
      "  batch   30: loss=1.356\n",
      "  batch   31: loss=1.023\n",
      "  batch   32: loss=0.975\n",
      "  batch   33: loss=0.894\n",
      "  batch   34: loss=1.019\n",
      "  batch   35: loss=1.049\n",
      "  batch   36: loss=0.921\n",
      "  batch   37: loss=1.128\n",
      "  batch   38: loss=0.712\n",
      "  batch   39: loss=1.048\n",
      "  batch   40: loss=1.180\n",
      "  batch   41: loss=0.855\n",
      "  batch   42: loss=1.112\n",
      "  batch   43: loss=1.439\n",
      "  batch   44: loss=1.051\n",
      "  batch   45: loss=0.758\n",
      "  batch   46: loss=0.534\n",
      "  batch   47: loss=1.095\n",
      "  batch   48: loss=1.421\n",
      "  batch   49: loss=1.063\n",
      "  batch   50: loss=1.125\n",
      "  batch   51: loss=0.980\n",
      "  batch   52: loss=0.973\n",
      "  batch   53: loss=0.909\n",
      "  batch   54: loss=0.898\n",
      "  batch   55: loss=1.349\n",
      "  batch   56: loss=1.201\n",
      "  batch   57: loss=0.817\n",
      "  batch   58: loss=0.900\n",
      "  batch   59: loss=1.286\n",
      "  batch   60: loss=0.958\n",
      "  batch   61: loss=1.241\n",
      "  batch   62: loss=1.052\n",
      "  batch   63: loss=1.354\n",
      "  batch   64: loss=0.775\n",
      "  batch   65: loss=0.858\n",
      "  batch   66: loss=0.765\n",
      "  batch   67: loss=0.828\n",
      "  batch   68: loss=1.423\n",
      "  batch   69: loss=1.362\n",
      "  batch   70: loss=1.177\n",
      "  batch   71: loss=1.040\n",
      "  batch   72: loss=1.148\n",
      "  batch   73: loss=1.122\n",
      "  batch   74: loss=1.081\n",
      "  batch   75: loss=0.593\n",
      "  batch   76: loss=1.092\n",
      "  batch   77: loss=0.892\n",
      "  batch   78: loss=1.071\n",
      "  batch   79: loss=1.175\n",
      "  batch   80: loss=1.322\n",
      "  batch   81: loss=0.958\n",
      "  batch   82: loss=1.351\n",
      "Testing on validation set\n",
      "  acc=0.678\n",
      "Training epoch 43\n",
      "  batch    1: loss=0.942\n",
      "  batch    2: loss=1.040\n",
      "  batch    3: loss=0.927\n",
      "  batch    4: loss=1.083\n",
      "  batch    5: loss=1.002\n",
      "  batch    6: loss=1.118\n",
      "  batch    7: loss=1.080\n",
      "  batch    8: loss=1.251\n",
      "  batch    9: loss=0.935\n",
      "  batch   10: loss=0.927\n",
      "  batch   11: loss=0.970\n",
      "  batch   12: loss=0.999\n",
      "  batch   13: loss=0.890\n",
      "  batch   14: loss=0.981\n",
      "  batch   15: loss=1.084\n",
      "  batch   16: loss=0.844\n",
      "  batch   17: loss=1.109\n",
      "  batch   18: loss=1.232\n",
      "  batch   19: loss=1.204\n",
      "  batch   20: loss=0.727\n",
      "  batch   21: loss=0.738\n",
      "  batch   22: loss=0.957\n",
      "  batch   23: loss=0.745\n",
      "  batch   24: loss=0.822\n",
      "  batch   25: loss=1.049\n",
      "  batch   26: loss=0.987\n",
      "  batch   27: loss=0.836\n",
      "  batch   28: loss=0.815\n",
      "  batch   29: loss=1.198\n",
      "  batch   30: loss=1.211\n",
      "  batch   31: loss=1.132\n",
      "  batch   32: loss=0.681\n",
      "  batch   33: loss=1.171\n",
      "  batch   34: loss=1.040\n",
      "  batch   35: loss=1.018\n",
      "  batch   36: loss=0.674\n",
      "  batch   37: loss=1.157\n",
      "  batch   38: loss=0.853\n",
      "  batch   39: loss=1.014\n",
      "  batch   40: loss=0.832\n",
      "  batch   41: loss=0.821\n",
      "  batch   42: loss=1.267\n",
      "  batch   43: loss=1.124\n",
      "  batch   44: loss=0.953\n",
      "  batch   45: loss=1.165\n",
      "  batch   46: loss=1.038\n",
      "  batch   47: loss=0.988\n",
      "  batch   48: loss=0.729\n",
      "  batch   49: loss=1.221\n",
      "  batch   50: loss=0.781\n",
      "  batch   51: loss=0.892\n",
      "  batch   52: loss=1.230\n",
      "  batch   53: loss=0.856\n",
      "  batch   54: loss=0.872\n",
      "  batch   55: loss=1.187\n",
      "  batch   56: loss=0.541\n",
      "  batch   57: loss=0.920\n",
      "  batch   58: loss=0.872\n",
      "  batch   59: loss=1.169\n",
      "  batch   60: loss=0.885\n",
      "  batch   61: loss=1.076\n",
      "  batch   62: loss=0.873\n",
      "  batch   63: loss=1.371\n",
      "  batch   64: loss=0.976\n",
      "  batch   65: loss=1.174\n",
      "  batch   66: loss=0.864\n",
      "  batch   67: loss=1.197\n",
      "  batch   68: loss=1.263\n",
      "  batch   69: loss=1.034\n",
      "  batch   70: loss=0.783\n",
      "  batch   71: loss=0.671\n",
      "  batch   72: loss=0.918\n",
      "  batch   73: loss=0.976\n",
      "  batch   74: loss=0.730\n",
      "  batch   75: loss=1.042\n",
      "  batch   76: loss=0.878\n",
      "  batch   77: loss=1.007\n",
      "  batch   78: loss=0.941\n",
      "  batch   79: loss=1.053\n",
      "  batch   80: loss=0.767\n",
      "  batch   81: loss=0.902\n",
      "  batch   82: loss=1.304\n",
      "Testing on validation set\n",
      "  acc=0.692\n",
      "Training epoch 44\n",
      "  batch    1: loss=1.078\n",
      "  batch    2: loss=0.839\n",
      "  batch    3: loss=1.014\n",
      "  batch    4: loss=1.067\n",
      "  batch    5: loss=0.636\n",
      "  batch    6: loss=0.924\n",
      "  batch    7: loss=1.059\n",
      "  batch    8: loss=0.764\n",
      "  batch    9: loss=0.781\n",
      "  batch   10: loss=1.343\n",
      "  batch   11: loss=0.838\n",
      "  batch   12: loss=1.347\n",
      "  batch   13: loss=1.505\n",
      "  batch   14: loss=0.848\n",
      "  batch   15: loss=1.052\n",
      "  batch   16: loss=0.857\n",
      "  batch   17: loss=0.939\n",
      "  batch   18: loss=0.995\n",
      "  batch   19: loss=1.136\n",
      "  batch   20: loss=0.788\n",
      "  batch   21: loss=0.783\n",
      "  batch   22: loss=1.244\n",
      "  batch   23: loss=1.057\n",
      "  batch   24: loss=1.272\n",
      "  batch   25: loss=1.001\n",
      "  batch   26: loss=1.084\n",
      "  batch   27: loss=0.858\n",
      "  batch   28: loss=0.957\n",
      "  batch   29: loss=1.104\n",
      "  batch   30: loss=1.026\n",
      "  batch   31: loss=0.902\n",
      "  batch   32: loss=0.893\n",
      "  batch   33: loss=1.124\n",
      "  batch   34: loss=1.099\n",
      "  batch   35: loss=1.082\n",
      "  batch   36: loss=1.134\n",
      "  batch   37: loss=0.601\n",
      "  batch   38: loss=0.983\n",
      "  batch   39: loss=1.074\n",
      "  batch   40: loss=1.191\n",
      "  batch   41: loss=1.048\n",
      "  batch   42: loss=0.872\n",
      "  batch   43: loss=0.941\n",
      "  batch   44: loss=0.843\n",
      "  batch   45: loss=0.972\n",
      "  batch   46: loss=0.835\n",
      "  batch   47: loss=0.744\n",
      "  batch   48: loss=1.021\n",
      "  batch   49: loss=0.627\n",
      "  batch   50: loss=1.091\n",
      "  batch   51: loss=0.728\n",
      "  batch   52: loss=1.111\n",
      "  batch   53: loss=0.912\n",
      "  batch   54: loss=0.947\n",
      "  batch   55: loss=0.975\n",
      "  batch   56: loss=1.056\n",
      "  batch   57: loss=0.741\n",
      "  batch   58: loss=0.892\n",
      "  batch   59: loss=0.855\n",
      "  batch   60: loss=0.951\n",
      "  batch   61: loss=0.865\n",
      "  batch   62: loss=1.113\n",
      "  batch   63: loss=0.741\n",
      "  batch   64: loss=0.792\n",
      "  batch   65: loss=1.457\n",
      "  batch   66: loss=1.054\n",
      "  batch   67: loss=0.963\n",
      "  batch   68: loss=0.841\n",
      "  batch   69: loss=1.439\n",
      "  batch   70: loss=1.196\n",
      "  batch   71: loss=0.905\n",
      "  batch   72: loss=0.898\n",
      "  batch   73: loss=0.825\n",
      "  batch   74: loss=1.123\n",
      "  batch   75: loss=0.599\n",
      "  batch   76: loss=1.178\n",
      "  batch   77: loss=0.520\n",
      "  batch   78: loss=0.841\n",
      "  batch   79: loss=0.658\n",
      "  batch   80: loss=1.347\n",
      "  batch   81: loss=0.978\n",
      "  batch   82: loss=1.862\n",
      "Testing on validation set\n",
      "  acc=0.674\n",
      "Training epoch 45\n",
      "  batch    1: loss=0.875\n",
      "  batch    2: loss=0.734\n",
      "  batch    3: loss=0.895\n",
      "  batch    4: loss=0.987\n",
      "  batch    5: loss=1.301\n",
      "  batch    6: loss=0.966\n",
      "  batch    7: loss=0.998\n",
      "  batch    8: loss=0.775\n",
      "  batch    9: loss=0.822\n",
      "  batch   10: loss=1.158\n",
      "  batch   11: loss=1.004\n",
      "  batch   12: loss=0.720\n",
      "  batch   13: loss=0.921\n",
      "  batch   14: loss=1.219\n",
      "  batch   15: loss=0.893\n",
      "  batch   16: loss=0.972\n",
      "  batch   17: loss=0.865\n",
      "  batch   18: loss=0.883\n",
      "  batch   19: loss=1.265\n",
      "  batch   20: loss=0.876\n",
      "  batch   21: loss=0.881\n",
      "  batch   22: loss=0.900\n",
      "  batch   23: loss=0.811\n",
      "  batch   24: loss=0.908\n",
      "  batch   25: loss=1.006\n",
      "  batch   26: loss=0.787\n",
      "  batch   27: loss=0.688\n",
      "  batch   28: loss=0.909\n",
      "  batch   29: loss=0.986\n",
      "  batch   30: loss=0.882\n",
      "  batch   31: loss=1.027\n",
      "  batch   32: loss=0.802\n",
      "  batch   33: loss=0.897\n",
      "  batch   34: loss=1.288\n",
      "  batch   35: loss=0.799\n",
      "  batch   36: loss=0.565\n",
      "  batch   37: loss=0.990\n",
      "  batch   38: loss=0.837\n",
      "  batch   39: loss=0.971\n",
      "  batch   40: loss=1.042\n",
      "  batch   41: loss=0.995\n",
      "  batch   42: loss=0.939\n",
      "  batch   43: loss=0.994\n",
      "  batch   44: loss=0.887\n",
      "  batch   45: loss=1.086\n",
      "  batch   46: loss=1.110\n",
      "  batch   47: loss=1.251\n",
      "  batch   48: loss=1.305\n",
      "  batch   49: loss=0.922\n",
      "  batch   50: loss=1.136\n",
      "  batch   51: loss=0.987\n",
      "  batch   52: loss=0.938\n",
      "  batch   53: loss=0.868\n",
      "  batch   54: loss=0.978\n",
      "  batch   55: loss=0.933\n",
      "  batch   56: loss=0.794\n",
      "  batch   57: loss=0.991\n",
      "  batch   58: loss=0.901\n",
      "  batch   59: loss=1.207\n",
      "  batch   60: loss=1.088\n",
      "  batch   61: loss=1.050\n",
      "  batch   62: loss=0.827\n",
      "  batch   63: loss=0.825\n",
      "  batch   64: loss=1.234\n",
      "  batch   65: loss=1.003\n",
      "  batch   66: loss=0.676\n",
      "  batch   67: loss=0.990\n",
      "  batch   68: loss=0.848\n",
      "  batch   69: loss=1.126\n",
      "  batch   70: loss=1.158\n",
      "  batch   71: loss=1.131\n",
      "  batch   72: loss=1.050\n",
      "  batch   73: loss=1.020\n",
      "  batch   74: loss=1.236\n",
      "  batch   75: loss=0.964\n",
      "  batch   76: loss=1.170\n",
      "  batch   77: loss=0.929\n",
      "  batch   78: loss=0.827\n",
      "  batch   79: loss=1.088\n",
      "  batch   80: loss=0.924\n",
      "  batch   81: loss=0.871\n",
      "  batch   82: loss=0.967\n",
      "Testing on validation set\n",
      "  acc=0.684\n",
      "Training epoch 46\n",
      "  batch    1: loss=0.571\n",
      "  batch    2: loss=0.876\n",
      "  batch    3: loss=0.622\n",
      "  batch    4: loss=0.748\n",
      "  batch    5: loss=0.807\n",
      "  batch    6: loss=0.695\n",
      "  batch    7: loss=1.187\n",
      "  batch    8: loss=0.567\n",
      "  batch    9: loss=1.008\n",
      "  batch   10: loss=0.881\n",
      "  batch   11: loss=0.767\n",
      "  batch   12: loss=0.813\n",
      "  batch   13: loss=0.840\n",
      "  batch   14: loss=0.882\n",
      "  batch   15: loss=1.042\n",
      "  batch   16: loss=1.399\n",
      "  batch   17: loss=1.015\n",
      "  batch   18: loss=0.934\n",
      "  batch   19: loss=1.086\n",
      "  batch   20: loss=1.140\n",
      "  batch   21: loss=1.013\n",
      "  batch   22: loss=1.022\n",
      "  batch   23: loss=0.816\n",
      "  batch   24: loss=0.943\n",
      "  batch   25: loss=1.148\n",
      "  batch   26: loss=0.772\n",
      "  batch   27: loss=0.827\n",
      "  batch   28: loss=0.819\n",
      "  batch   29: loss=0.732\n",
      "  batch   30: loss=1.143\n",
      "  batch   31: loss=1.231\n",
      "  batch   32: loss=1.096\n",
      "  batch   33: loss=0.968\n",
      "  batch   34: loss=1.012\n",
      "  batch   35: loss=0.894\n",
      "  batch   36: loss=0.869\n",
      "  batch   37: loss=1.247\n",
      "  batch   38: loss=0.994\n",
      "  batch   39: loss=0.589\n",
      "  batch   40: loss=0.909\n",
      "  batch   41: loss=0.809\n",
      "  batch   42: loss=0.672\n",
      "  batch   43: loss=1.282\n",
      "  batch   44: loss=1.264\n",
      "  batch   45: loss=0.782\n",
      "  batch   46: loss=1.106\n",
      "  batch   47: loss=0.889\n",
      "  batch   48: loss=0.936\n",
      "  batch   49: loss=0.907\n",
      "  batch   50: loss=0.784\n",
      "  batch   51: loss=0.779\n",
      "  batch   52: loss=0.912\n",
      "  batch   53: loss=1.197\n",
      "  batch   54: loss=1.078\n",
      "  batch   55: loss=1.253\n",
      "  batch   56: loss=1.134\n",
      "  batch   57: loss=0.929\n",
      "  batch   58: loss=1.068\n",
      "  batch   59: loss=1.019\n",
      "  batch   60: loss=1.294\n",
      "  batch   61: loss=0.818\n",
      "  batch   62: loss=0.731\n",
      "  batch   63: loss=0.783\n",
      "  batch   64: loss=0.915\n",
      "  batch   65: loss=0.857\n",
      "  batch   66: loss=0.793\n",
      "  batch   67: loss=1.162\n",
      "  batch   68: loss=1.421\n",
      "  batch   69: loss=0.950\n",
      "  batch   70: loss=0.603\n",
      "  batch   71: loss=0.974\n",
      "  batch   72: loss=1.122\n",
      "  batch   73: loss=1.132\n",
      "  batch   74: loss=0.728\n",
      "  batch   75: loss=0.904\n",
      "  batch   76: loss=1.377\n",
      "  batch   77: loss=0.894\n",
      "  batch   78: loss=0.923\n",
      "  batch   79: loss=0.980\n",
      "  batch   80: loss=0.642\n",
      "  batch   81: loss=0.825\n",
      "  batch   82: loss=0.848\n",
      "Testing on validation set\n",
      "  acc=0.670\n",
      "Training epoch 47\n",
      "  batch    1: loss=0.873\n",
      "  batch    2: loss=0.697\n",
      "  batch    3: loss=0.919\n",
      "  batch    4: loss=0.909\n",
      "  batch    5: loss=1.088\n",
      "  batch    6: loss=0.837\n",
      "  batch    7: loss=1.270\n",
      "  batch    8: loss=0.891\n",
      "  batch    9: loss=1.021\n",
      "  batch   10: loss=1.111\n",
      "  batch   11: loss=1.152\n",
      "  batch   12: loss=0.890\n",
      "  batch   13: loss=0.762\n",
      "  batch   14: loss=1.020\n",
      "  batch   15: loss=0.676\n",
      "  batch   16: loss=0.980\n",
      "  batch   17: loss=0.965\n",
      "  batch   18: loss=0.798\n",
      "  batch   19: loss=0.829\n",
      "  batch   20: loss=0.832\n",
      "  batch   21: loss=0.671\n",
      "  batch   22: loss=0.675\n",
      "  batch   23: loss=0.706\n",
      "  batch   24: loss=1.096\n",
      "  batch   25: loss=0.780\n",
      "  batch   26: loss=0.768\n",
      "  batch   27: loss=0.669\n",
      "  batch   28: loss=0.920\n",
      "  batch   29: loss=0.973\n",
      "  batch   30: loss=0.711\n",
      "  batch   31: loss=0.699\n",
      "  batch   32: loss=0.840\n",
      "  batch   33: loss=0.930\n",
      "  batch   34: loss=0.652\n",
      "  batch   35: loss=0.938\n",
      "  batch   36: loss=0.921\n",
      "  batch   37: loss=0.959\n",
      "  batch   38: loss=0.678\n",
      "  batch   39: loss=1.015\n",
      "  batch   40: loss=1.032\n",
      "  batch   41: loss=0.851\n",
      "  batch   42: loss=0.904\n",
      "  batch   43: loss=0.983\n",
      "  batch   44: loss=1.080\n",
      "  batch   45: loss=0.723\n",
      "  batch   46: loss=0.881\n",
      "  batch   47: loss=0.823\n",
      "  batch   48: loss=0.631\n",
      "  batch   49: loss=0.979\n",
      "  batch   50: loss=1.188\n",
      "  batch   51: loss=0.755\n",
      "  batch   52: loss=0.887\n",
      "  batch   53: loss=0.924\n",
      "  batch   54: loss=0.924\n",
      "  batch   55: loss=0.952\n",
      "  batch   56: loss=1.010\n",
      "  batch   57: loss=0.843\n",
      "  batch   58: loss=0.510\n",
      "  batch   59: loss=0.671\n",
      "  batch   60: loss=1.066\n",
      "  batch   61: loss=0.718\n",
      "  batch   62: loss=1.576\n",
      "  batch   63: loss=1.133\n",
      "  batch   64: loss=0.908\n",
      "  batch   65: loss=0.889\n",
      "  batch   66: loss=1.209\n",
      "  batch   67: loss=0.649\n",
      "  batch   68: loss=1.204\n",
      "  batch   69: loss=0.798\n",
      "  batch   70: loss=0.869\n",
      "  batch   71: loss=0.913\n",
      "  batch   72: loss=1.234\n",
      "  batch   73: loss=1.075\n",
      "  batch   74: loss=0.932\n",
      "  batch   75: loss=0.898\n",
      "  batch   76: loss=0.699\n",
      "  batch   77: loss=0.916\n",
      "  batch   78: loss=1.076\n",
      "  batch   79: loss=1.125\n",
      "  batch   80: loss=0.946\n",
      "  batch   81: loss=1.364\n",
      "  batch   82: loss=1.388\n",
      "Testing on validation set\n",
      "  acc=0.688\n",
      "Training epoch 48\n",
      "  batch    1: loss=0.733\n",
      "  batch    2: loss=1.017\n",
      "  batch    3: loss=0.769\n",
      "  batch    4: loss=0.805\n",
      "  batch    5: loss=0.897\n",
      "  batch    6: loss=1.365\n",
      "  batch    7: loss=0.876\n",
      "  batch    8: loss=1.045\n",
      "  batch    9: loss=0.877\n",
      "  batch   10: loss=1.073\n",
      "  batch   11: loss=0.836\n",
      "  batch   12: loss=1.068\n",
      "  batch   13: loss=0.868\n",
      "  batch   14: loss=0.722\n",
      "  batch   15: loss=1.008\n",
      "  batch   16: loss=0.865\n",
      "  batch   17: loss=1.171\n",
      "  batch   18: loss=0.993\n",
      "  batch   19: loss=0.716\n",
      "  batch   20: loss=0.885\n",
      "  batch   21: loss=0.555\n",
      "  batch   22: loss=0.644\n",
      "  batch   23: loss=1.130\n",
      "  batch   24: loss=0.625\n",
      "  batch   25: loss=1.045\n",
      "  batch   26: loss=0.853\n",
      "  batch   27: loss=0.940\n",
      "  batch   28: loss=0.572\n",
      "  batch   29: loss=1.060\n",
      "  batch   30: loss=1.083\n",
      "  batch   31: loss=0.819\n",
      "  batch   32: loss=0.961\n",
      "  batch   33: loss=0.760\n",
      "  batch   34: loss=0.824\n",
      "  batch   35: loss=0.794\n",
      "  batch   36: loss=0.953\n",
      "  batch   37: loss=1.056\n",
      "  batch   38: loss=0.844\n",
      "  batch   39: loss=0.862\n",
      "  batch   40: loss=1.149\n",
      "  batch   41: loss=1.589\n",
      "  batch   42: loss=0.716\n",
      "  batch   43: loss=0.889\n",
      "  batch   44: loss=0.726\n",
      "  batch   45: loss=0.752\n",
      "  batch   46: loss=0.716\n",
      "  batch   47: loss=1.080\n",
      "  batch   48: loss=0.881\n",
      "  batch   49: loss=0.774\n",
      "  batch   50: loss=0.805\n",
      "  batch   51: loss=0.838\n",
      "  batch   52: loss=1.156\n",
      "  batch   53: loss=1.096\n",
      "  batch   54: loss=0.586\n",
      "  batch   55: loss=1.296\n",
      "  batch   56: loss=0.619\n",
      "  batch   57: loss=0.988\n",
      "  batch   58: loss=1.154\n",
      "  batch   59: loss=0.936\n",
      "  batch   60: loss=0.737\n",
      "  batch   61: loss=0.677\n",
      "  batch   62: loss=1.191\n",
      "  batch   63: loss=1.229\n",
      "  batch   64: loss=0.942\n",
      "  batch   65: loss=0.761\n",
      "  batch   66: loss=0.911\n",
      "  batch   67: loss=0.727\n",
      "  batch   68: loss=0.940\n",
      "  batch   69: loss=0.763\n",
      "  batch   70: loss=0.964\n",
      "  batch   71: loss=1.262\n",
      "  batch   72: loss=1.128\n",
      "  batch   73: loss=1.040\n",
      "  batch   74: loss=1.000\n",
      "  batch   75: loss=0.909\n",
      "  batch   76: loss=0.842\n",
      "  batch   77: loss=1.058\n",
      "  batch   78: loss=1.136\n",
      "  batch   79: loss=1.160\n",
      "  batch   80: loss=1.126\n",
      "  batch   81: loss=1.430\n",
      "  batch   82: loss=1.808\n",
      "Testing on validation set\n",
      "  acc=0.660\n",
      "Training epoch 49\n",
      "  batch    1: loss=0.848\n",
      "  batch    2: loss=1.036\n",
      "  batch    3: loss=1.047\n",
      "  batch    4: loss=0.923\n",
      "  batch    5: loss=0.649\n",
      "  batch    6: loss=0.699\n",
      "  batch    7: loss=0.743\n",
      "  batch    8: loss=1.040\n",
      "  batch    9: loss=0.704\n",
      "  batch   10: loss=0.512\n",
      "  batch   11: loss=0.958\n",
      "  batch   12: loss=0.762\n",
      "  batch   13: loss=0.834\n",
      "  batch   14: loss=0.728\n",
      "  batch   15: loss=0.912\n",
      "  batch   16: loss=0.806\n",
      "  batch   17: loss=0.953\n",
      "  batch   18: loss=1.069\n",
      "  batch   19: loss=1.357\n",
      "  batch   20: loss=0.788\n",
      "  batch   21: loss=0.911\n",
      "  batch   22: loss=1.059\n",
      "  batch   23: loss=0.797\n",
      "  batch   24: loss=0.849\n",
      "  batch   25: loss=0.738\n",
      "  batch   26: loss=0.810\n",
      "  batch   27: loss=1.199\n",
      "  batch   28: loss=0.817\n",
      "  batch   29: loss=0.955\n",
      "  batch   30: loss=1.033\n",
      "  batch   31: loss=1.108\n",
      "  batch   32: loss=0.935\n",
      "  batch   33: loss=0.833\n",
      "  batch   34: loss=0.708\n",
      "  batch   35: loss=1.176\n",
      "  batch   36: loss=0.796\n",
      "  batch   37: loss=0.777\n",
      "  batch   38: loss=0.623\n",
      "  batch   39: loss=1.002\n",
      "  batch   40: loss=0.612\n",
      "  batch   41: loss=0.913\n",
      "  batch   42: loss=0.896\n",
      "  batch   43: loss=1.065\n",
      "  batch   44: loss=0.907\n",
      "  batch   45: loss=0.934\n",
      "  batch   46: loss=0.994\n",
      "  batch   47: loss=1.065\n",
      "  batch   48: loss=0.898\n",
      "  batch   49: loss=0.830\n",
      "  batch   50: loss=0.912\n",
      "  batch   51: loss=0.702\n",
      "  batch   52: loss=0.817\n",
      "  batch   53: loss=1.044\n",
      "  batch   54: loss=0.913\n",
      "  batch   55: loss=0.765\n",
      "  batch   56: loss=0.757\n",
      "  batch   57: loss=1.020\n",
      "  batch   58: loss=0.822\n",
      "  batch   59: loss=0.966\n",
      "  batch   60: loss=0.865\n",
      "  batch   61: loss=0.797\n",
      "  batch   62: loss=0.874\n",
      "  batch   63: loss=1.077\n",
      "  batch   64: loss=0.717\n",
      "  batch   65: loss=1.194\n",
      "  batch   66: loss=1.025\n",
      "  batch   67: loss=1.235\n",
      "  batch   68: loss=1.114\n",
      "  batch   69: loss=0.829\n",
      "  batch   70: loss=0.986\n",
      "  batch   71: loss=1.020\n",
      "  batch   72: loss=0.904\n",
      "  batch   73: loss=0.881\n",
      "  batch   74: loss=0.575\n",
      "  batch   75: loss=1.028\n",
      "  batch   76: loss=1.139\n",
      "  batch   77: loss=0.948\n",
      "  batch   78: loss=0.960\n",
      "  batch   79: loss=1.138\n",
      "  batch   80: loss=0.988\n",
      "  batch   81: loss=0.987\n",
      "  batch   82: loss=0.764\n",
      "Testing on validation set\n",
      "  acc=0.677\n",
      "Training epoch 50\n",
      "  batch    1: loss=0.710\n",
      "  batch    2: loss=0.692\n",
      "  batch    3: loss=0.694\n",
      "  batch    4: loss=0.859\n",
      "  batch    5: loss=0.959\n",
      "  batch    6: loss=0.890\n",
      "  batch    7: loss=0.265\n",
      "  batch    8: loss=0.796\n",
      "  batch    9: loss=0.904\n",
      "  batch   10: loss=0.896\n",
      "  batch   11: loss=1.050\n",
      "  batch   12: loss=0.611\n",
      "  batch   13: loss=0.811\n",
      "  batch   14: loss=0.773\n",
      "  batch   15: loss=0.572\n",
      "  batch   16: loss=0.642\n",
      "  batch   17: loss=0.779\n",
      "  batch   18: loss=0.528\n",
      "  batch   19: loss=1.112\n",
      "  batch   20: loss=0.691\n",
      "  batch   21: loss=0.950\n",
      "  batch   22: loss=0.936\n",
      "  batch   23: loss=0.714\n",
      "  batch   24: loss=0.709\n",
      "  batch   25: loss=1.033\n",
      "  batch   26: loss=1.119\n",
      "  batch   27: loss=0.851\n",
      "  batch   28: loss=0.834\n",
      "  batch   29: loss=1.055\n",
      "  batch   30: loss=1.058\n",
      "  batch   31: loss=0.770\n",
      "  batch   32: loss=1.112\n",
      "  batch   33: loss=0.851\n",
      "  batch   34: loss=0.814\n",
      "  batch   35: loss=1.196\n",
      "  batch   36: loss=0.903\n",
      "  batch   37: loss=0.705\n",
      "  batch   38: loss=0.607\n",
      "  batch   39: loss=0.663\n",
      "  batch   40: loss=0.491\n",
      "  batch   41: loss=0.958\n",
      "  batch   42: loss=0.757\n",
      "  batch   43: loss=0.583\n",
      "  batch   44: loss=0.870\n",
      "  batch   45: loss=0.902\n",
      "  batch   46: loss=0.786\n",
      "  batch   47: loss=1.136\n",
      "  batch   48: loss=0.577\n",
      "  batch   49: loss=0.961\n",
      "  batch   50: loss=0.895\n",
      "  batch   51: loss=1.103\n",
      "  batch   52: loss=0.960\n",
      "  batch   53: loss=0.741\n",
      "  batch   54: loss=0.799\n",
      "  batch   55: loss=0.914\n",
      "  batch   56: loss=0.644\n",
      "  batch   57: loss=0.807\n",
      "  batch   58: loss=0.840\n",
      "  batch   59: loss=1.181\n",
      "  batch   60: loss=0.972\n",
      "  batch   61: loss=0.972\n",
      "  batch   62: loss=0.748\n",
      "  batch   63: loss=0.731\n",
      "  batch   64: loss=0.861\n",
      "  batch   65: loss=0.649\n",
      "  batch   66: loss=0.841\n",
      "  batch   67: loss=0.933\n",
      "  batch   68: loss=0.889\n",
      "  batch   69: loss=0.762\n",
      "  batch   70: loss=0.760\n",
      "  batch   71: loss=1.188\n",
      "  batch   72: loss=0.844\n",
      "  batch   73: loss=1.201\n",
      "  batch   74: loss=1.022\n",
      "  batch   75: loss=0.721\n",
      "  batch   76: loss=0.779\n",
      "  batch   77: loss=0.785\n",
      "  batch   78: loss=0.772\n",
      "  batch   79: loss=0.866\n",
      "  batch   80: loss=1.085\n",
      "  batch   81: loss=1.116\n",
      "  batch   82: loss=0.791\n",
      "Testing on validation set\n",
      "  acc=0.709\n",
      "Training epoch 51\n",
      "  batch    1: loss=0.778\n",
      "  batch    2: loss=0.480\n",
      "  batch    3: loss=0.936\n",
      "  batch    4: loss=0.463\n",
      "  batch    5: loss=0.759\n",
      "  batch    6: loss=0.741\n",
      "  batch    7: loss=0.807\n",
      "  batch    8: loss=0.775\n",
      "  batch    9: loss=0.820\n",
      "  batch   10: loss=1.057\n",
      "  batch   11: loss=0.625\n",
      "  batch   12: loss=0.760\n",
      "  batch   13: loss=0.661\n",
      "  batch   14: loss=0.620\n",
      "  batch   15: loss=1.082\n",
      "  batch   16: loss=0.677\n",
      "  batch   17: loss=0.576\n",
      "  batch   18: loss=1.150\n",
      "  batch   19: loss=0.500\n",
      "  batch   20: loss=1.127\n",
      "  batch   21: loss=0.912\n",
      "  batch   22: loss=0.834\n",
      "  batch   23: loss=0.674\n",
      "  batch   24: loss=0.489\n",
      "  batch   25: loss=0.647\n",
      "  batch   26: loss=0.837\n",
      "  batch   27: loss=1.032\n",
      "  batch   28: loss=0.942\n",
      "  batch   29: loss=0.712\n",
      "  batch   30: loss=0.537\n",
      "  batch   31: loss=0.819\n",
      "  batch   32: loss=0.787\n",
      "  batch   33: loss=0.631\n",
      "  batch   34: loss=0.697\n",
      "  batch   35: loss=0.831\n",
      "  batch   36: loss=0.982\n",
      "  batch   37: loss=0.553\n",
      "  batch   38: loss=0.717\n",
      "  batch   39: loss=0.920\n",
      "  batch   40: loss=0.928\n",
      "  batch   41: loss=0.898\n",
      "  batch   42: loss=1.090\n",
      "  batch   43: loss=0.775\n",
      "  batch   44: loss=1.044\n",
      "  batch   45: loss=0.879\n",
      "  batch   46: loss=0.970\n",
      "  batch   47: loss=0.790\n",
      "  batch   48: loss=0.984\n",
      "  batch   49: loss=1.115\n",
      "  batch   50: loss=1.004\n",
      "  batch   51: loss=0.804\n",
      "  batch   52: loss=0.737\n",
      "  batch   53: loss=0.789\n",
      "  batch   54: loss=0.825\n",
      "  batch   55: loss=0.822\n",
      "  batch   56: loss=1.035\n",
      "  batch   57: loss=0.763\n",
      "  batch   58: loss=0.804\n",
      "  batch   59: loss=0.805\n",
      "  batch   60: loss=1.126\n",
      "  batch   61: loss=0.881\n",
      "  batch   62: loss=0.604\n",
      "  batch   63: loss=1.155\n",
      "  batch   64: loss=0.888\n",
      "  batch   65: loss=0.783\n",
      "  batch   66: loss=0.810\n",
      "  batch   67: loss=0.932\n",
      "  batch   68: loss=0.641\n",
      "  batch   69: loss=1.518\n",
      "  batch   70: loss=0.934\n",
      "  batch   71: loss=0.751\n",
      "  batch   72: loss=0.710\n",
      "  batch   73: loss=1.043\n",
      "  batch   74: loss=1.252\n",
      "  batch   75: loss=0.799\n",
      "  batch   76: loss=0.649\n",
      "  batch   77: loss=1.194\n",
      "  batch   78: loss=0.597\n",
      "  batch   79: loss=0.680\n",
      "  batch   80: loss=0.804\n",
      "  batch   81: loss=1.070\n",
      "  batch   82: loss=1.142\n",
      "Testing on validation set\n",
      "  acc=0.672\n",
      "Training epoch 52\n",
      "  batch    1: loss=0.853\n",
      "  batch    2: loss=0.693\n",
      "  batch    3: loss=0.907\n",
      "  batch    4: loss=1.085\n",
      "  batch    5: loss=0.854\n",
      "  batch    6: loss=0.474\n",
      "  batch    7: loss=0.773\n",
      "  batch    8: loss=0.640\n",
      "  batch    9: loss=0.590\n",
      "  batch   10: loss=0.939\n",
      "  batch   11: loss=0.945\n",
      "  batch   12: loss=0.943\n",
      "  batch   13: loss=0.922\n",
      "  batch   14: loss=0.748\n",
      "  batch   15: loss=0.810\n",
      "  batch   16: loss=0.879\n",
      "  batch   17: loss=0.795\n",
      "  batch   18: loss=1.225\n",
      "  batch   19: loss=0.810\n",
      "  batch   20: loss=0.772\n",
      "  batch   21: loss=0.763\n",
      "  batch   22: loss=0.750\n",
      "  batch   23: loss=0.569\n",
      "  batch   24: loss=1.101\n",
      "  batch   25: loss=0.590\n",
      "  batch   26: loss=0.853\n",
      "  batch   27: loss=0.577\n",
      "  batch   28: loss=0.685\n",
      "  batch   29: loss=0.674\n",
      "  batch   30: loss=1.013\n",
      "  batch   31: loss=0.783\n",
      "  batch   32: loss=0.779\n",
      "  batch   33: loss=0.928\n",
      "  batch   34: loss=0.781\n",
      "  batch   35: loss=0.861\n",
      "  batch   36: loss=0.740\n",
      "  batch   37: loss=0.641\n",
      "  batch   38: loss=0.925\n",
      "  batch   39: loss=0.936\n",
      "  batch   40: loss=0.853\n",
      "  batch   41: loss=1.086\n",
      "  batch   42: loss=1.024\n",
      "  batch   43: loss=1.196\n",
      "  batch   44: loss=0.626\n",
      "  batch   45: loss=0.843\n",
      "  batch   46: loss=0.524\n",
      "  batch   47: loss=0.594\n",
      "  batch   48: loss=0.845\n",
      "  batch   49: loss=1.168\n",
      "  batch   50: loss=0.910\n",
      "  batch   51: loss=0.847\n",
      "  batch   52: loss=0.899\n",
      "  batch   53: loss=0.944\n",
      "  batch   54: loss=1.239\n",
      "  batch   55: loss=1.295\n",
      "  batch   56: loss=0.769\n",
      "  batch   57: loss=0.840\n",
      "  batch   58: loss=0.927\n",
      "  batch   59: loss=0.948\n",
      "  batch   60: loss=1.004\n",
      "  batch   61: loss=0.522\n",
      "  batch   62: loss=0.695\n",
      "  batch   63: loss=0.999\n",
      "  batch   64: loss=0.883\n",
      "  batch   65: loss=0.885\n",
      "  batch   66: loss=1.203\n",
      "  batch   67: loss=0.871\n",
      "  batch   68: loss=0.944\n",
      "  batch   69: loss=0.837\n",
      "  batch   70: loss=1.006\n",
      "  batch   71: loss=1.121\n",
      "  batch   72: loss=0.924\n",
      "  batch   73: loss=0.660\n",
      "  batch   74: loss=0.699\n",
      "  batch   75: loss=0.773\n",
      "  batch   76: loss=0.842\n",
      "  batch   77: loss=0.708\n",
      "  batch   78: loss=0.878\n",
      "  batch   79: loss=0.661\n",
      "  batch   80: loss=0.796\n",
      "  batch   81: loss=1.109\n",
      "  batch   82: loss=1.149\n",
      "Testing on validation set\n",
      "  acc=0.695\n",
      "Training epoch 53\n",
      "  batch    1: loss=0.557\n",
      "  batch    2: loss=1.227\n",
      "  batch    3: loss=0.641\n",
      "  batch    4: loss=1.151\n",
      "  batch    5: loss=0.955\n",
      "  batch    6: loss=1.042\n",
      "  batch    7: loss=0.851\n",
      "  batch    8: loss=0.845\n",
      "  batch    9: loss=1.014\n",
      "  batch   10: loss=0.973\n",
      "  batch   11: loss=0.786\n",
      "  batch   12: loss=0.683\n",
      "  batch   13: loss=0.835\n",
      "  batch   14: loss=0.726\n",
      "  batch   15: loss=0.707\n",
      "  batch   16: loss=0.759\n",
      "  batch   17: loss=0.733\n",
      "  batch   18: loss=0.752\n",
      "  batch   19: loss=0.708\n",
      "  batch   20: loss=0.965\n",
      "  batch   21: loss=0.908\n",
      "  batch   22: loss=0.949\n",
      "  batch   23: loss=0.744\n",
      "  batch   24: loss=0.676\n",
      "  batch   25: loss=0.744\n",
      "  batch   26: loss=0.774\n",
      "  batch   27: loss=0.753\n",
      "  batch   28: loss=0.817\n",
      "  batch   29: loss=0.593\n",
      "  batch   30: loss=0.696\n",
      "  batch   31: loss=1.206\n",
      "  batch   32: loss=0.719\n",
      "  batch   33: loss=1.065\n",
      "  batch   34: loss=0.701\n",
      "  batch   35: loss=0.984\n",
      "  batch   36: loss=0.764\n",
      "  batch   37: loss=1.014\n",
      "  batch   38: loss=0.808\n",
      "  batch   39: loss=0.803\n",
      "  batch   40: loss=0.636\n",
      "  batch   41: loss=0.970\n",
      "  batch   42: loss=0.701\n",
      "  batch   43: loss=1.193\n",
      "  batch   44: loss=0.470\n",
      "  batch   45: loss=1.108\n",
      "  batch   46: loss=0.726\n",
      "  batch   47: loss=1.054\n",
      "  batch   48: loss=0.722\n",
      "  batch   49: loss=0.736\n",
      "  batch   50: loss=0.978\n",
      "  batch   51: loss=1.068\n",
      "  batch   52: loss=0.716\n",
      "  batch   53: loss=0.815\n",
      "  batch   54: loss=1.199\n",
      "  batch   55: loss=1.074\n",
      "  batch   56: loss=0.753\n",
      "  batch   57: loss=0.955\n",
      "  batch   58: loss=0.872\n",
      "  batch   59: loss=0.912\n",
      "  batch   60: loss=1.097\n",
      "  batch   61: loss=0.701\n",
      "  batch   62: loss=0.800\n",
      "  batch   63: loss=0.873\n",
      "  batch   64: loss=0.739\n",
      "  batch   65: loss=0.742\n",
      "  batch   66: loss=0.750\n",
      "  batch   67: loss=0.571\n",
      "  batch   68: loss=0.796\n",
      "  batch   69: loss=0.904\n",
      "  batch   70: loss=1.108\n",
      "  batch   71: loss=0.824\n",
      "  batch   72: loss=0.895\n",
      "  batch   73: loss=0.698\n",
      "  batch   74: loss=0.984\n",
      "  batch   75: loss=0.849\n",
      "  batch   76: loss=0.630\n",
      "  batch   77: loss=0.920\n",
      "  batch   78: loss=0.749\n",
      "  batch   79: loss=0.784\n",
      "  batch   80: loss=0.752\n",
      "  batch   81: loss=0.816\n",
      "  batch   82: loss=0.648\n",
      "Testing on validation set\n",
      "  acc=0.685\n",
      "Training epoch 54\n",
      "  batch    1: loss=0.860\n",
      "  batch    2: loss=0.670\n",
      "  batch    3: loss=0.774\n",
      "  batch    4: loss=0.833\n",
      "  batch    5: loss=0.783\n",
      "  batch    6: loss=0.801\n",
      "  batch    7: loss=0.582\n",
      "  batch    8: loss=0.624\n",
      "  batch    9: loss=0.511\n",
      "  batch   10: loss=0.664\n",
      "  batch   11: loss=0.754\n",
      "  batch   12: loss=0.478\n",
      "  batch   13: loss=0.653\n",
      "  batch   14: loss=0.839\n",
      "  batch   15: loss=0.911\n",
      "  batch   16: loss=0.821\n",
      "  batch   17: loss=0.734\n",
      "  batch   18: loss=0.727\n",
      "  batch   19: loss=0.909\n",
      "  batch   20: loss=0.534\n",
      "  batch   21: loss=0.589\n",
      "  batch   22: loss=0.981\n",
      "  batch   23: loss=0.838\n",
      "  batch   24: loss=0.767\n",
      "  batch   25: loss=0.623\n",
      "  batch   26: loss=0.752\n",
      "  batch   27: loss=0.910\n",
      "  batch   28: loss=0.553\n",
      "  batch   29: loss=0.819\n",
      "  batch   30: loss=0.683\n",
      "  batch   31: loss=0.830\n",
      "  batch   32: loss=0.670\n",
      "  batch   33: loss=0.384\n",
      "  batch   34: loss=1.056\n",
      "  batch   35: loss=0.672\n",
      "  batch   36: loss=0.691\n",
      "  batch   37: loss=1.060\n",
      "  batch   38: loss=0.726\n",
      "  batch   39: loss=0.791\n",
      "  batch   40: loss=1.139\n",
      "  batch   41: loss=1.002\n",
      "  batch   42: loss=0.987\n",
      "  batch   43: loss=0.916\n",
      "  batch   44: loss=0.877\n",
      "  batch   45: loss=0.587\n",
      "  batch   46: loss=1.015\n",
      "  batch   47: loss=0.681\n",
      "  batch   48: loss=0.698\n",
      "  batch   49: loss=0.750\n",
      "  batch   50: loss=1.085\n",
      "  batch   51: loss=0.786\n",
      "  batch   52: loss=0.959\n",
      "  batch   53: loss=0.645\n",
      "  batch   54: loss=0.754\n",
      "  batch   55: loss=0.895\n",
      "  batch   56: loss=0.729\n",
      "  batch   57: loss=0.757\n",
      "  batch   58: loss=0.879\n",
      "  batch   59: loss=0.904\n",
      "  batch   60: loss=0.761\n",
      "  batch   61: loss=0.788\n",
      "  batch   62: loss=0.846\n",
      "  batch   63: loss=1.155\n",
      "  batch   64: loss=0.814\n",
      "  batch   65: loss=0.536\n",
      "  batch   66: loss=0.934\n",
      "  batch   67: loss=0.688\n",
      "  batch   68: loss=0.697\n",
      "  batch   69: loss=0.864\n",
      "  batch   70: loss=0.829\n",
      "  batch   71: loss=1.016\n",
      "  batch   72: loss=0.892\n",
      "  batch   73: loss=0.625\n",
      "  batch   74: loss=0.853\n",
      "  batch   75: loss=1.014\n",
      "  batch   76: loss=0.665\n",
      "  batch   77: loss=0.822\n",
      "  batch   78: loss=0.630\n",
      "  batch   79: loss=0.517\n",
      "  batch   80: loss=0.883\n",
      "  batch   81: loss=0.690\n",
      "  batch   82: loss=0.918\n",
      "Testing on validation set\n",
      "  acc=0.682\n",
      "Training epoch 55\n",
      "  batch    1: loss=0.699\n",
      "  batch    2: loss=0.732\n",
      "  batch    3: loss=0.616\n",
      "  batch    4: loss=0.815\n",
      "  batch    5: loss=0.868\n",
      "  batch    6: loss=0.682\n",
      "  batch    7: loss=0.819\n",
      "  batch    8: loss=0.759\n",
      "  batch    9: loss=0.933\n",
      "  batch   10: loss=0.745\n",
      "  batch   11: loss=0.849\n",
      "  batch   12: loss=0.889\n",
      "  batch   13: loss=0.702\n",
      "  batch   14: loss=0.827\n",
      "  batch   15: loss=0.831\n",
      "  batch   16: loss=0.561\n",
      "  batch   17: loss=1.175\n",
      "  batch   18: loss=0.737\n",
      "  batch   19: loss=0.651\n",
      "  batch   20: loss=0.713\n",
      "  batch   21: loss=0.904\n",
      "  batch   22: loss=0.806\n",
      "  batch   23: loss=0.726\n",
      "  batch   24: loss=0.589\n",
      "  batch   25: loss=0.716\n",
      "  batch   26: loss=0.882\n",
      "  batch   27: loss=0.531\n",
      "  batch   28: loss=0.843\n",
      "  batch   29: loss=0.678\n",
      "  batch   30: loss=1.091\n",
      "  batch   31: loss=0.489\n",
      "  batch   32: loss=0.843\n",
      "  batch   33: loss=0.711\n",
      "  batch   34: loss=0.961\n",
      "  batch   35: loss=0.676\n",
      "  batch   36: loss=0.554\n",
      "  batch   37: loss=0.806\n",
      "  batch   38: loss=0.740\n",
      "  batch   39: loss=0.707\n",
      "  batch   40: loss=0.649\n",
      "  batch   41: loss=0.545\n",
      "  batch   42: loss=0.895\n",
      "  batch   43: loss=0.634\n",
      "  batch   44: loss=0.687\n",
      "  batch   45: loss=1.036\n",
      "  batch   46: loss=1.006\n",
      "  batch   47: loss=0.831\n",
      "  batch   48: loss=0.945\n",
      "  batch   49: loss=0.717\n",
      "  batch   50: loss=0.830\n",
      "  batch   51: loss=0.807\n",
      "  batch   52: loss=0.864\n",
      "  batch   53: loss=0.830\n",
      "  batch   54: loss=0.894\n",
      "  batch   55: loss=0.709\n",
      "  batch   56: loss=0.728\n",
      "  batch   57: loss=0.776\n",
      "  batch   58: loss=0.819\n",
      "  batch   59: loss=0.937\n",
      "  batch   60: loss=0.731\n",
      "  batch   61: loss=0.809\n",
      "  batch   62: loss=0.933\n",
      "  batch   63: loss=0.831\n",
      "  batch   64: loss=0.641\n",
      "  batch   65: loss=0.602\n",
      "  batch   66: loss=0.628\n",
      "  batch   67: loss=0.961\n",
      "  batch   68: loss=0.549\n",
      "  batch   69: loss=0.668\n",
      "  batch   70: loss=0.893\n",
      "  batch   71: loss=0.710\n",
      "  batch   72: loss=1.064\n",
      "  batch   73: loss=0.955\n",
      "  batch   74: loss=0.912\n",
      "  batch   75: loss=0.937\n",
      "  batch   76: loss=0.748\n",
      "  batch   77: loss=0.930\n",
      "  batch   78: loss=0.697\n",
      "  batch   79: loss=0.794\n",
      "  batch   80: loss=1.035\n",
      "  batch   81: loss=0.893\n",
      "  batch   82: loss=0.842\n",
      "Testing on validation set\n",
      "  acc=0.682\n",
      "Training epoch 56\n",
      "  batch    1: loss=1.066\n",
      "  batch    2: loss=0.612\n",
      "  batch    3: loss=0.578\n",
      "  batch    4: loss=0.885\n",
      "  batch    5: loss=0.688\n",
      "  batch    6: loss=0.697\n",
      "  batch    7: loss=0.980\n",
      "  batch    8: loss=0.811\n",
      "  batch    9: loss=0.704\n",
      "  batch   10: loss=0.707\n",
      "  batch   11: loss=0.768\n",
      "  batch   12: loss=0.823\n",
      "  batch   13: loss=0.793\n",
      "  batch   14: loss=0.953\n",
      "  batch   15: loss=0.742\n",
      "  batch   16: loss=0.447\n",
      "  batch   17: loss=0.864\n",
      "  batch   18: loss=0.887\n",
      "  batch   19: loss=0.942\n",
      "  batch   20: loss=1.073\n",
      "  batch   21: loss=0.570\n",
      "  batch   22: loss=0.824\n",
      "  batch   23: loss=1.105\n",
      "  batch   24: loss=0.608\n",
      "  batch   25: loss=0.722\n",
      "  batch   26: loss=0.437\n",
      "  batch   27: loss=0.843\n",
      "  batch   28: loss=0.488\n",
      "  batch   29: loss=0.756\n",
      "  batch   30: loss=1.036\n",
      "  batch   31: loss=1.135\n",
      "  batch   32: loss=0.781\n",
      "  batch   33: loss=0.712\n",
      "  batch   34: loss=0.968\n",
      "  batch   35: loss=0.891\n",
      "  batch   36: loss=0.818\n",
      "  batch   37: loss=0.984\n",
      "  batch   38: loss=0.648\n",
      "  batch   39: loss=0.629\n",
      "  batch   40: loss=1.403\n",
      "  batch   41: loss=0.574\n",
      "  batch   42: loss=1.024\n",
      "  batch   43: loss=0.677\n",
      "  batch   44: loss=0.747\n",
      "  batch   45: loss=0.794\n",
      "  batch   46: loss=0.632\n",
      "  batch   47: loss=0.649\n",
      "  batch   48: loss=0.522\n",
      "  batch   49: loss=0.990\n",
      "  batch   50: loss=0.787\n",
      "  batch   51: loss=0.707\n",
      "  batch   52: loss=0.587\n",
      "  batch   53: loss=1.283\n",
      "  batch   54: loss=0.601\n",
      "  batch   55: loss=0.617\n",
      "  batch   56: loss=0.787\n",
      "  batch   57: loss=0.918\n",
      "  batch   58: loss=0.726\n",
      "  batch   59: loss=0.482\n",
      "  batch   60: loss=0.968\n",
      "  batch   61: loss=0.791\n",
      "  batch   62: loss=0.766\n",
      "  batch   63: loss=1.004\n",
      "  batch   64: loss=0.740\n",
      "  batch   65: loss=0.427\n",
      "  batch   66: loss=1.010\n",
      "  batch   67: loss=0.542\n",
      "  batch   68: loss=0.751\n",
      "  batch   69: loss=0.663\n",
      "  batch   70: loss=0.880\n",
      "  batch   71: loss=0.606\n",
      "  batch   72: loss=0.511\n",
      "  batch   73: loss=1.006\n",
      "  batch   74: loss=0.715\n",
      "  batch   75: loss=0.815\n",
      "  batch   76: loss=0.720\n",
      "  batch   77: loss=0.727\n",
      "  batch   78: loss=0.989\n",
      "  batch   79: loss=0.823\n",
      "  batch   80: loss=0.848\n",
      "  batch   81: loss=0.804\n",
      "  batch   82: loss=1.538\n",
      "Testing on validation set\n",
      "  acc=0.674\n",
      "Training epoch 57\n",
      "  batch    1: loss=1.035\n",
      "  batch    2: loss=0.727\n",
      "  batch    3: loss=0.650\n",
      "  batch    4: loss=0.816\n",
      "  batch    5: loss=0.977\n",
      "  batch    6: loss=0.922\n",
      "  batch    7: loss=0.808\n",
      "  batch    8: loss=0.907\n",
      "  batch    9: loss=0.961\n",
      "  batch   10: loss=0.717\n",
      "  batch   11: loss=0.664\n",
      "  batch   12: loss=1.002\n",
      "  batch   13: loss=0.764\n",
      "  batch   14: loss=1.035\n",
      "  batch   15: loss=0.746\n",
      "  batch   16: loss=0.582\n",
      "  batch   17: loss=0.618\n",
      "  batch   18: loss=0.856\n",
      "  batch   19: loss=0.700\n",
      "  batch   20: loss=0.560\n",
      "  batch   21: loss=0.904\n",
      "  batch   22: loss=0.507\n",
      "  batch   23: loss=0.648\n",
      "  batch   24: loss=1.204\n",
      "  batch   25: loss=0.945\n",
      "  batch   26: loss=0.495\n",
      "  batch   27: loss=0.635\n",
      "  batch   28: loss=0.348\n",
      "  batch   29: loss=0.606\n",
      "  batch   30: loss=0.754\n",
      "  batch   31: loss=0.895\n",
      "  batch   32: loss=0.705\n",
      "  batch   33: loss=0.709\n",
      "  batch   34: loss=1.015\n",
      "  batch   35: loss=0.971\n",
      "  batch   36: loss=0.813\n",
      "  batch   37: loss=0.804\n",
      "  batch   38: loss=0.700\n",
      "  batch   39: loss=0.780\n",
      "  batch   40: loss=0.500\n",
      "  batch   41: loss=0.649\n",
      "  batch   42: loss=0.892\n",
      "  batch   43: loss=0.941\n",
      "  batch   44: loss=0.631\n",
      "  batch   45: loss=0.792\n",
      "  batch   46: loss=0.677\n",
      "  batch   47: loss=0.503\n",
      "  batch   48: loss=0.794\n",
      "  batch   49: loss=0.703\n",
      "  batch   50: loss=0.602\n",
      "  batch   51: loss=0.830\n",
      "  batch   52: loss=0.751\n",
      "  batch   53: loss=0.976\n",
      "  batch   54: loss=0.590\n",
      "  batch   55: loss=0.696\n",
      "  batch   56: loss=0.884\n",
      "  batch   57: loss=0.598\n",
      "  batch   58: loss=1.284\n",
      "  batch   59: loss=0.471\n",
      "  batch   60: loss=0.684\n",
      "  batch   61: loss=1.290\n",
      "  batch   62: loss=0.988\n",
      "  batch   63: loss=0.928\n",
      "  batch   64: loss=0.628\n",
      "  batch   65: loss=0.802\n",
      "  batch   66: loss=1.042\n",
      "  batch   67: loss=0.399\n",
      "  batch   68: loss=0.966\n",
      "  batch   69: loss=0.675\n",
      "  batch   70: loss=0.723\n",
      "  batch   71: loss=1.232\n",
      "  batch   72: loss=0.559\n",
      "  batch   73: loss=0.866\n",
      "  batch   74: loss=0.684\n",
      "  batch   75: loss=0.558\n",
      "  batch   76: loss=0.737\n",
      "  batch   77: loss=0.980\n",
      "  batch   78: loss=1.000\n",
      "  batch   79: loss=0.876\n",
      "  batch   80: loss=0.968\n",
      "  batch   81: loss=0.793\n",
      "  batch   82: loss=1.559\n",
      "Testing on validation set\n",
      "  acc=0.700\n",
      "Training epoch 58\n",
      "  batch    1: loss=0.846\n",
      "  batch    2: loss=0.816\n",
      "  batch    3: loss=0.621\n",
      "  batch    4: loss=0.697\n",
      "  batch    5: loss=0.546\n",
      "  batch    6: loss=0.682\n",
      "  batch    7: loss=0.920\n",
      "  batch    8: loss=0.607\n",
      "  batch    9: loss=0.689\n",
      "  batch   10: loss=0.558\n",
      "  batch   11: loss=0.655\n",
      "  batch   12: loss=0.786\n",
      "  batch   13: loss=0.701\n",
      "  batch   14: loss=0.562\n",
      "  batch   15: loss=0.427\n",
      "  batch   16: loss=0.784\n",
      "  batch   17: loss=0.739\n",
      "  batch   18: loss=0.719\n",
      "  batch   19: loss=0.762\n",
      "  batch   20: loss=0.848\n",
      "  batch   21: loss=0.638\n",
      "  batch   22: loss=0.571\n",
      "  batch   23: loss=1.019\n",
      "  batch   24: loss=0.854\n",
      "  batch   25: loss=0.860\n",
      "  batch   26: loss=1.172\n",
      "  batch   27: loss=0.718\n",
      "  batch   28: loss=0.662\n",
      "  batch   29: loss=0.918\n",
      "  batch   30: loss=0.724\n",
      "  batch   31: loss=0.684\n",
      "  batch   32: loss=0.834\n",
      "  batch   33: loss=0.749\n",
      "  batch   34: loss=0.801\n",
      "  batch   35: loss=1.146\n",
      "  batch   36: loss=0.662\n",
      "  batch   37: loss=0.738\n",
      "  batch   38: loss=0.974\n",
      "  batch   39: loss=0.379\n",
      "  batch   40: loss=1.136\n",
      "  batch   41: loss=0.707\n",
      "  batch   42: loss=0.765\n",
      "  batch   43: loss=0.786\n",
      "  batch   44: loss=0.736\n",
      "  batch   45: loss=0.615\n",
      "  batch   46: loss=0.705\n",
      "  batch   47: loss=0.617\n",
      "  batch   48: loss=0.612\n",
      "  batch   49: loss=1.034\n",
      "  batch   50: loss=0.863\n",
      "  batch   51: loss=1.006\n",
      "  batch   52: loss=0.942\n",
      "  batch   53: loss=0.815\n",
      "  batch   54: loss=0.683\n",
      "  batch   55: loss=0.916\n",
      "  batch   56: loss=0.747\n",
      "  batch   57: loss=0.932\n",
      "  batch   58: loss=0.848\n",
      "  batch   59: loss=0.813\n",
      "  batch   60: loss=0.540\n",
      "  batch   61: loss=0.781\n",
      "  batch   62: loss=0.874\n",
      "  batch   63: loss=0.827\n",
      "  batch   64: loss=1.115\n",
      "  batch   65: loss=0.630\n",
      "  batch   66: loss=0.883\n",
      "  batch   67: loss=0.740\n",
      "  batch   68: loss=0.843\n",
      "  batch   69: loss=1.060\n",
      "  batch   70: loss=0.601\n",
      "  batch   71: loss=0.608\n",
      "  batch   72: loss=0.797\n",
      "  batch   73: loss=0.820\n",
      "  batch   74: loss=0.829\n",
      "  batch   75: loss=0.876\n",
      "  batch   76: loss=0.615\n",
      "  batch   77: loss=1.011\n",
      "  batch   78: loss=0.961\n",
      "  batch   79: loss=0.493\n",
      "  batch   80: loss=0.846\n",
      "  batch   81: loss=0.813\n",
      "  batch   82: loss=1.011\n",
      "Testing on validation set\n",
      "  acc=0.713\n",
      "Training epoch 59\n",
      "  batch    1: loss=0.625\n",
      "  batch    2: loss=0.904\n",
      "  batch    3: loss=0.678\n",
      "  batch    4: loss=1.023\n",
      "  batch    5: loss=0.635\n",
      "  batch    6: loss=0.920\n",
      "  batch    7: loss=0.814\n",
      "  batch    8: loss=0.649\n",
      "  batch    9: loss=0.471\n",
      "  batch   10: loss=0.907\n",
      "  batch   11: loss=0.923\n",
      "  batch   12: loss=0.879\n",
      "  batch   13: loss=0.677\n",
      "  batch   14: loss=0.681\n",
      "  batch   15: loss=0.441\n",
      "  batch   16: loss=0.931\n",
      "  batch   17: loss=0.624\n",
      "  batch   18: loss=0.615\n",
      "  batch   19: loss=0.594\n",
      "  batch   20: loss=0.846\n",
      "  batch   21: loss=1.136\n",
      "  batch   22: loss=0.524\n",
      "  batch   23: loss=0.935\n",
      "  batch   24: loss=0.880\n",
      "  batch   25: loss=0.742\n",
      "  batch   26: loss=0.854\n",
      "  batch   27: loss=0.553\n",
      "  batch   28: loss=0.462\n",
      "  batch   29: loss=1.069\n",
      "  batch   30: loss=0.670\n",
      "  batch   31: loss=0.870\n",
      "  batch   32: loss=0.558\n",
      "  batch   33: loss=1.036\n",
      "  batch   34: loss=0.791\n",
      "  batch   35: loss=0.723\n",
      "  batch   36: loss=0.795\n",
      "  batch   37: loss=0.582\n",
      "  batch   38: loss=0.818\n",
      "  batch   39: loss=0.906\n",
      "  batch   40: loss=0.866\n",
      "  batch   41: loss=0.816\n",
      "  batch   42: loss=1.091\n",
      "  batch   43: loss=0.718\n",
      "  batch   44: loss=0.850\n",
      "  batch   45: loss=0.708\n",
      "  batch   46: loss=0.736\n",
      "  batch   47: loss=0.832\n",
      "  batch   48: loss=0.699\n",
      "  batch   49: loss=0.471\n",
      "  batch   50: loss=1.143\n",
      "  batch   51: loss=0.769\n",
      "  batch   52: loss=0.451\n",
      "  batch   53: loss=0.731\n",
      "  batch   54: loss=0.631\n",
      "  batch   55: loss=0.684\n",
      "  batch   56: loss=0.722\n",
      "  batch   57: loss=0.942\n",
      "  batch   58: loss=0.930\n",
      "  batch   59: loss=0.825\n",
      "  batch   60: loss=0.730\n",
      "  batch   61: loss=0.655\n",
      "  batch   62: loss=0.639\n",
      "  batch   63: loss=0.979\n",
      "  batch   64: loss=0.631\n",
      "  batch   65: loss=0.843\n",
      "  batch   66: loss=0.677\n",
      "  batch   67: loss=0.475\n",
      "  batch   68: loss=0.715\n",
      "  batch   69: loss=0.461\n",
      "  batch   70: loss=0.683\n",
      "  batch   71: loss=0.806\n",
      "  batch   72: loss=0.749\n",
      "  batch   73: loss=1.216\n",
      "  batch   74: loss=1.345\n",
      "  batch   75: loss=0.708\n",
      "  batch   76: loss=0.749\n",
      "  batch   77: loss=0.931\n",
      "  batch   78: loss=0.770\n",
      "  batch   79: loss=0.620\n",
      "  batch   80: loss=0.856\n",
      "  batch   81: loss=0.896\n",
      "  batch   82: loss=0.728\n",
      "Testing on validation set\n",
      "  acc=0.688\n",
      "Training epoch 60\n",
      "  batch    1: loss=1.033\n",
      "  batch    2: loss=0.711\n",
      "  batch    3: loss=0.518\n",
      "  batch    4: loss=0.744\n",
      "  batch    5: loss=0.869\n",
      "  batch    6: loss=1.052\n",
      "  batch    7: loss=0.723\n",
      "  batch    8: loss=0.857\n",
      "  batch    9: loss=0.589\n",
      "  batch   10: loss=0.585\n",
      "  batch   11: loss=0.509\n",
      "  batch   12: loss=0.741\n",
      "  batch   13: loss=0.802\n",
      "  batch   14: loss=0.912\n",
      "  batch   15: loss=0.866\n",
      "  batch   16: loss=0.862\n",
      "  batch   17: loss=0.860\n",
      "  batch   18: loss=0.978\n",
      "  batch   19: loss=1.026\n",
      "  batch   20: loss=0.601\n",
      "  batch   21: loss=0.803\n",
      "  batch   22: loss=0.897\n",
      "  batch   23: loss=0.905\n",
      "  batch   24: loss=0.568\n",
      "  batch   25: loss=0.641\n",
      "  batch   26: loss=0.721\n",
      "  batch   27: loss=0.683\n",
      "  batch   28: loss=0.811\n",
      "  batch   29: loss=0.766\n",
      "  batch   30: loss=0.703\n",
      "  batch   31: loss=0.934\n",
      "  batch   32: loss=0.782\n",
      "  batch   33: loss=0.666\n",
      "  batch   34: loss=0.695\n",
      "  batch   35: loss=0.744\n",
      "  batch   36: loss=0.768\n",
      "  batch   37: loss=0.852\n",
      "  batch   38: loss=0.763\n",
      "  batch   39: loss=0.856\n",
      "  batch   40: loss=0.790\n",
      "  batch   41: loss=0.670\n",
      "  batch   42: loss=0.805\n",
      "  batch   43: loss=1.036\n",
      "  batch   44: loss=0.996\n",
      "  batch   45: loss=0.817\n",
      "  batch   46: loss=0.530\n",
      "  batch   47: loss=0.514\n",
      "  batch   48: loss=0.643\n",
      "  batch   49: loss=1.068\n",
      "  batch   50: loss=0.504\n",
      "  batch   51: loss=0.894\n",
      "  batch   52: loss=0.772\n",
      "  batch   53: loss=0.808\n",
      "  batch   54: loss=0.748\n",
      "  batch   55: loss=0.844\n",
      "  batch   56: loss=0.698\n",
      "  batch   57: loss=0.496\n",
      "  batch   58: loss=0.657\n",
      "  batch   59: loss=0.848\n",
      "  batch   60: loss=0.750\n",
      "  batch   61: loss=0.727\n",
      "  batch   62: loss=0.926\n",
      "  batch   63: loss=0.817\n",
      "  batch   64: loss=1.011\n",
      "  batch   65: loss=0.732\n",
      "  batch   66: loss=0.757\n",
      "  batch   67: loss=0.799\n",
      "  batch   68: loss=0.528\n",
      "  batch   69: loss=0.691\n",
      "  batch   70: loss=0.749\n",
      "  batch   71: loss=0.819\n",
      "  batch   72: loss=0.605\n",
      "  batch   73: loss=0.527\n",
      "  batch   74: loss=0.814\n",
      "  batch   75: loss=0.602\n",
      "  batch   76: loss=0.693\n",
      "  batch   77: loss=0.880\n",
      "  batch   78: loss=0.553\n",
      "  batch   79: loss=0.720\n",
      "  batch   80: loss=0.965\n",
      "  batch   81: loss=0.696\n",
      "  batch   82: loss=1.533\n",
      "Testing on validation set\n",
      "  acc=0.708\n",
      "Training epoch 61\n",
      "  batch    1: loss=1.016\n",
      "  batch    2: loss=0.630\n",
      "  batch    3: loss=0.973\n",
      "  batch    4: loss=0.533\n",
      "  batch    5: loss=0.514\n",
      "  batch    6: loss=0.593\n",
      "  batch    7: loss=0.560\n",
      "  batch    8: loss=0.643\n",
      "  batch    9: loss=0.843\n",
      "  batch   10: loss=0.829\n",
      "  batch   11: loss=0.504\n",
      "  batch   12: loss=0.883\n",
      "  batch   13: loss=0.588\n",
      "  batch   14: loss=0.595\n",
      "  batch   15: loss=0.631\n",
      "  batch   16: loss=1.146\n",
      "  batch   17: loss=0.586\n",
      "  batch   18: loss=0.534\n",
      "  batch   19: loss=0.807\n",
      "  batch   20: loss=0.786\n",
      "  batch   21: loss=0.668\n",
      "  batch   22: loss=0.600\n",
      "  batch   23: loss=0.784\n",
      "  batch   24: loss=0.717\n",
      "  batch   25: loss=0.711\n",
      "  batch   26: loss=0.824\n",
      "  batch   27: loss=0.974\n",
      "  batch   28: loss=0.894\n",
      "  batch   29: loss=0.639\n",
      "  batch   30: loss=0.836\n",
      "  batch   31: loss=0.616\n",
      "  batch   32: loss=0.607\n",
      "  batch   33: loss=0.633\n",
      "  batch   34: loss=0.562\n",
      "  batch   35: loss=0.750\n",
      "  batch   36: loss=0.738\n",
      "  batch   37: loss=0.518\n",
      "  batch   38: loss=0.871\n",
      "  batch   39: loss=0.713\n",
      "  batch   40: loss=0.619\n",
      "  batch   41: loss=1.020\n",
      "  batch   42: loss=0.838\n",
      "  batch   43: loss=0.670\n",
      "  batch   44: loss=0.589\n",
      "  batch   45: loss=0.714\n",
      "  batch   46: loss=0.565\n",
      "  batch   47: loss=0.735\n",
      "  batch   48: loss=0.922\n",
      "  batch   49: loss=0.836\n",
      "  batch   50: loss=0.796\n",
      "  batch   51: loss=0.584\n",
      "  batch   52: loss=0.469\n",
      "  batch   53: loss=0.533\n",
      "  batch   54: loss=0.631\n",
      "  batch   55: loss=0.721\n",
      "  batch   56: loss=0.689\n",
      "  batch   57: loss=0.637\n",
      "  batch   58: loss=0.905\n",
      "  batch   59: loss=0.386\n",
      "  batch   60: loss=0.656\n",
      "  batch   61: loss=0.629\n",
      "  batch   62: loss=0.664\n",
      "  batch   63: loss=0.520\n",
      "  batch   64: loss=0.926\n",
      "  batch   65: loss=0.447\n",
      "  batch   66: loss=0.905\n",
      "  batch   67: loss=0.722\n",
      "  batch   68: loss=0.913\n",
      "  batch   69: loss=0.946\n",
      "  batch   70: loss=0.598\n",
      "  batch   71: loss=0.914\n",
      "  batch   72: loss=0.716\n",
      "  batch   73: loss=1.059\n",
      "  batch   74: loss=0.912\n",
      "  batch   75: loss=0.903\n",
      "  batch   76: loss=0.806\n",
      "  batch   77: loss=0.783\n",
      "  batch   78: loss=0.577\n",
      "  batch   79: loss=0.820\n",
      "  batch   80: loss=0.534\n",
      "  batch   81: loss=0.779\n",
      "  batch   82: loss=0.596\n",
      "Testing on validation set\n",
      "  acc=0.693\n",
      "Training epoch 62\n",
      "  batch    1: loss=0.765\n",
      "  batch    2: loss=0.791\n",
      "  batch    3: loss=0.986\n",
      "  batch    4: loss=0.316\n",
      "  batch    5: loss=0.546\n",
      "  batch    6: loss=0.627\n",
      "  batch    7: loss=0.704\n",
      "  batch    8: loss=0.710\n",
      "  batch    9: loss=0.467\n",
      "  batch   10: loss=0.534\n",
      "  batch   11: loss=0.433\n",
      "  batch   12: loss=0.636\n",
      "  batch   13: loss=0.456\n",
      "  batch   14: loss=0.608\n",
      "  batch   15: loss=0.689\n",
      "  batch   16: loss=0.736\n",
      "  batch   17: loss=0.595\n",
      "  batch   18: loss=0.619\n",
      "  batch   19: loss=0.758\n",
      "  batch   20: loss=0.942\n",
      "  batch   21: loss=0.694\n",
      "  batch   22: loss=0.422\n",
      "  batch   23: loss=0.572\n",
      "  batch   24: loss=0.943\n",
      "  batch   25: loss=0.711\n",
      "  batch   26: loss=0.786\n",
      "  batch   27: loss=0.560\n",
      "  batch   28: loss=0.881\n",
      "  batch   29: loss=0.714\n",
      "  batch   30: loss=0.766\n",
      "  batch   31: loss=0.298\n",
      "  batch   32: loss=0.551\n",
      "  batch   33: loss=0.530\n",
      "  batch   34: loss=0.616\n",
      "  batch   35: loss=0.489\n",
      "  batch   36: loss=0.574\n",
      "  batch   37: loss=0.766\n",
      "  batch   38: loss=0.814\n",
      "  batch   39: loss=0.609\n",
      "  batch   40: loss=0.690\n",
      "  batch   41: loss=0.543\n",
      "  batch   42: loss=0.776\n",
      "  batch   43: loss=0.532\n",
      "  batch   44: loss=0.764\n",
      "  batch   45: loss=0.522\n",
      "  batch   46: loss=0.777\n",
      "  batch   47: loss=0.788\n",
      "  batch   48: loss=0.643\n",
      "  batch   49: loss=0.456\n",
      "  batch   50: loss=0.723\n",
      "  batch   51: loss=0.756\n",
      "  batch   52: loss=0.728\n",
      "  batch   53: loss=0.722\n",
      "  batch   54: loss=0.466\n",
      "  batch   55: loss=0.717\n",
      "  batch   56: loss=0.899\n",
      "  batch   57: loss=0.632\n",
      "  batch   58: loss=0.924\n",
      "  batch   59: loss=0.581\n",
      "  batch   60: loss=0.546\n",
      "  batch   61: loss=1.190\n",
      "  batch   62: loss=0.560\n",
      "  batch   63: loss=0.672\n",
      "  batch   64: loss=0.542\n",
      "  batch   65: loss=0.601\n",
      "  batch   66: loss=0.877\n",
      "  batch   67: loss=1.017\n",
      "  batch   68: loss=0.524\n",
      "  batch   69: loss=0.975\n",
      "  batch   70: loss=0.729\n",
      "  batch   71: loss=0.551\n",
      "  batch   72: loss=0.823\n",
      "  batch   73: loss=0.702\n",
      "  batch   74: loss=0.798\n",
      "  batch   75: loss=0.664\n",
      "  batch   76: loss=0.610\n",
      "  batch   77: loss=0.718\n",
      "  batch   78: loss=0.804\n",
      "  batch   79: loss=0.777\n",
      "  batch   80: loss=0.617\n",
      "  batch   81: loss=0.673\n",
      "  batch   82: loss=1.362\n",
      "Testing on validation set\n",
      "  acc=0.697\n",
      "Training epoch 63\n",
      "  batch    1: loss=0.811\n",
      "  batch    2: loss=0.597\n",
      "  batch    3: loss=0.625\n",
      "  batch    4: loss=0.549\n",
      "  batch    5: loss=0.736\n",
      "  batch    6: loss=0.870\n",
      "  batch    7: loss=0.769\n",
      "  batch    8: loss=0.679\n",
      "  batch    9: loss=0.750\n",
      "  batch   10: loss=0.830\n",
      "  batch   11: loss=0.604\n",
      "  batch   12: loss=0.801\n",
      "  batch   13: loss=0.834\n",
      "  batch   14: loss=0.862\n",
      "  batch   15: loss=0.746\n",
      "  batch   16: loss=0.882\n",
      "  batch   17: loss=1.057\n",
      "  batch   18: loss=0.532\n",
      "  batch   19: loss=0.548\n",
      "  batch   20: loss=0.904\n",
      "  batch   21: loss=0.896\n",
      "  batch   22: loss=0.553\n",
      "  batch   23: loss=0.756\n",
      "  batch   24: loss=1.000\n",
      "  batch   25: loss=0.743\n",
      "  batch   26: loss=0.662\n",
      "  batch   27: loss=0.958\n",
      "  batch   28: loss=0.781\n",
      "  batch   29: loss=0.648\n",
      "  batch   30: loss=0.658\n",
      "  batch   31: loss=0.752\n",
      "  batch   32: loss=0.535\n",
      "  batch   33: loss=0.982\n",
      "  batch   34: loss=0.759\n",
      "  batch   35: loss=0.541\n",
      "  batch   36: loss=0.501\n",
      "  batch   37: loss=0.558\n",
      "  batch   38: loss=0.626\n",
      "  batch   39: loss=0.557\n",
      "  batch   40: loss=0.901\n",
      "  batch   41: loss=0.494\n",
      "  batch   42: loss=0.784\n",
      "  batch   43: loss=0.771\n",
      "  batch   44: loss=0.857\n",
      "  batch   45: loss=0.824\n",
      "  batch   46: loss=0.819\n",
      "  batch   47: loss=0.401\n",
      "  batch   48: loss=0.939\n",
      "  batch   49: loss=0.741\n",
      "  batch   50: loss=0.633\n",
      "  batch   51: loss=0.728\n",
      "  batch   52: loss=0.723\n",
      "  batch   53: loss=0.436\n",
      "  batch   54: loss=0.578\n",
      "  batch   55: loss=0.441\n",
      "  batch   56: loss=0.633\n",
      "  batch   57: loss=0.856\n",
      "  batch   58: loss=0.535\n",
      "  batch   59: loss=0.777\n",
      "  batch   60: loss=0.630\n",
      "  batch   61: loss=0.802\n",
      "  batch   62: loss=0.986\n",
      "  batch   63: loss=0.804\n",
      "  batch   64: loss=0.774\n",
      "  batch   65: loss=0.517\n",
      "  batch   66: loss=0.833\n",
      "  batch   67: loss=0.924\n",
      "  batch   68: loss=0.506\n",
      "  batch   69: loss=1.077\n",
      "  batch   70: loss=0.635\n",
      "  batch   71: loss=0.719\n",
      "  batch   72: loss=0.857\n",
      "  batch   73: loss=0.693\n",
      "  batch   74: loss=0.934\n",
      "  batch   75: loss=0.452\n",
      "  batch   76: loss=0.695\n",
      "  batch   77: loss=0.677\n",
      "  batch   78: loss=0.515\n",
      "  batch   79: loss=0.880\n",
      "  batch   80: loss=0.684\n",
      "  batch   81: loss=0.699\n",
      "  batch   82: loss=1.036\n",
      "Testing on validation set\n",
      "  acc=0.708\n",
      "Training epoch 64\n",
      "  batch    1: loss=0.454\n",
      "  batch    2: loss=0.614\n",
      "  batch    3: loss=0.702\n",
      "  batch    4: loss=0.804\n",
      "  batch    5: loss=0.647\n",
      "  batch    6: loss=0.634\n",
      "  batch    7: loss=0.628\n",
      "  batch    8: loss=0.582\n",
      "  batch    9: loss=0.937\n",
      "  batch   10: loss=0.416\n",
      "  batch   11: loss=0.656\n",
      "  batch   12: loss=0.598\n",
      "  batch   13: loss=0.581\n",
      "  batch   14: loss=0.817\n",
      "  batch   15: loss=0.778\n",
      "  batch   16: loss=0.484\n",
      "  batch   17: loss=0.481\n",
      "  batch   18: loss=0.833\n",
      "  batch   19: loss=0.771\n",
      "  batch   20: loss=0.741\n",
      "  batch   21: loss=0.727\n",
      "  batch   22: loss=0.585\n",
      "  batch   23: loss=0.755\n",
      "  batch   24: loss=0.604\n",
      "  batch   25: loss=0.806\n",
      "  batch   26: loss=0.460\n",
      "  batch   27: loss=0.714\n",
      "  batch   28: loss=0.594\n",
      "  batch   29: loss=0.792\n",
      "  batch   30: loss=0.608\n",
      "  batch   31: loss=0.728\n",
      "  batch   32: loss=0.873\n",
      "  batch   33: loss=0.687\n",
      "  batch   34: loss=0.695\n",
      "  batch   35: loss=0.843\n",
      "  batch   36: loss=0.704\n",
      "  batch   37: loss=0.671\n",
      "  batch   38: loss=0.460\n",
      "  batch   39: loss=0.765\n",
      "  batch   40: loss=0.612\n",
      "  batch   41: loss=0.756\n",
      "  batch   42: loss=0.603\n",
      "  batch   43: loss=0.667\n",
      "  batch   44: loss=0.489\n",
      "  batch   45: loss=0.655\n",
      "  batch   46: loss=0.728\n",
      "  batch   47: loss=0.657\n",
      "  batch   48: loss=0.719\n",
      "  batch   49: loss=0.422\n",
      "  batch   50: loss=0.542\n",
      "  batch   51: loss=0.886\n",
      "  batch   52: loss=0.553\n",
      "  batch   53: loss=0.887\n",
      "  batch   54: loss=0.654\n",
      "  batch   55: loss=0.730\n",
      "  batch   56: loss=0.727\n",
      "  batch   57: loss=0.393\n",
      "  batch   58: loss=0.549\n",
      "  batch   59: loss=0.818\n",
      "  batch   60: loss=0.782\n",
      "  batch   61: loss=0.580\n",
      "  batch   62: loss=0.749\n",
      "  batch   63: loss=0.284\n",
      "  batch   64: loss=0.871\n",
      "  batch   65: loss=0.680\n",
      "  batch   66: loss=0.656\n",
      "  batch   67: loss=0.578\n",
      "  batch   68: loss=0.941\n",
      "  batch   69: loss=0.725\n",
      "  batch   70: loss=0.705\n",
      "  batch   71: loss=0.788\n",
      "  batch   72: loss=0.725\n",
      "  batch   73: loss=0.597\n",
      "  batch   74: loss=0.567\n",
      "  batch   75: loss=0.868\n",
      "  batch   76: loss=0.682\n",
      "  batch   77: loss=0.793\n",
      "  batch   78: loss=0.652\n",
      "  batch   79: loss=0.832\n",
      "  batch   80: loss=0.643\n",
      "  batch   81: loss=0.696\n",
      "  batch   82: loss=0.816\n",
      "Testing on validation set\n",
      "  acc=0.704\n",
      "Training epoch 65\n",
      "  batch    1: loss=0.370\n",
      "  batch    2: loss=0.572\n",
      "  batch    3: loss=0.447\n",
      "  batch    4: loss=0.601\n",
      "  batch    5: loss=0.401\n",
      "  batch    6: loss=0.484\n",
      "  batch    7: loss=0.708\n",
      "  batch    8: loss=0.885\n",
      "  batch    9: loss=1.006\n",
      "  batch   10: loss=0.408\n",
      "  batch   11: loss=0.691\n",
      "  batch   12: loss=0.563\n",
      "  batch   13: loss=0.731\n",
      "  batch   14: loss=0.913\n",
      "  batch   15: loss=0.475\n",
      "  batch   16: loss=0.476\n",
      "  batch   17: loss=0.490\n",
      "  batch   18: loss=0.840\n",
      "  batch   19: loss=0.925\n",
      "  batch   20: loss=0.479\n",
      "  batch   21: loss=0.939\n",
      "  batch   22: loss=0.586\n",
      "  batch   23: loss=0.475\n",
      "  batch   24: loss=0.865\n",
      "  batch   25: loss=0.757\n",
      "  batch   26: loss=0.757\n",
      "  batch   27: loss=0.595\n",
      "  batch   28: loss=0.675\n",
      "  batch   29: loss=0.699\n",
      "  batch   30: loss=0.595\n",
      "  batch   31: loss=0.915\n",
      "  batch   32: loss=0.803\n",
      "  batch   33: loss=0.546\n",
      "  batch   34: loss=0.824\n",
      "  batch   35: loss=0.890\n",
      "  batch   36: loss=0.752\n",
      "  batch   37: loss=0.577\n",
      "  batch   38: loss=0.567\n",
      "  batch   39: loss=0.556\n",
      "  batch   40: loss=0.858\n",
      "  batch   41: loss=0.620\n",
      "  batch   42: loss=0.679\n",
      "  batch   43: loss=0.842\n",
      "  batch   44: loss=0.953\n",
      "  batch   45: loss=0.593\n",
      "  batch   46: loss=0.709\n",
      "  batch   47: loss=0.699\n",
      "  batch   48: loss=0.394\n",
      "  batch   49: loss=0.975\n",
      "  batch   50: loss=0.698\n",
      "  batch   51: loss=0.885\n",
      "  batch   52: loss=0.671\n",
      "  batch   53: loss=0.771\n",
      "  batch   54: loss=0.852\n",
      "  batch   55: loss=0.786\n",
      "  batch   56: loss=0.539\n",
      "  batch   57: loss=0.540\n",
      "  batch   58: loss=0.645\n",
      "  batch   59: loss=1.035\n",
      "  batch   60: loss=0.834\n",
      "  batch   61: loss=0.799\n",
      "  batch   62: loss=0.503\n",
      "  batch   63: loss=0.629\n",
      "  batch   64: loss=0.614\n",
      "  batch   65: loss=0.805\n",
      "  batch   66: loss=0.763\n",
      "  batch   67: loss=0.758\n",
      "  batch   68: loss=0.671\n",
      "  batch   69: loss=0.457\n",
      "  batch   70: loss=0.480\n",
      "  batch   71: loss=0.512\n",
      "  batch   72: loss=0.876\n",
      "  batch   73: loss=0.598\n",
      "  batch   74: loss=0.535\n",
      "  batch   75: loss=0.643\n",
      "  batch   76: loss=0.867\n",
      "  batch   77: loss=0.443\n",
      "  batch   78: loss=0.597\n",
      "  batch   79: loss=1.035\n",
      "  batch   80: loss=1.128\n",
      "  batch   81: loss=0.667\n",
      "  batch   82: loss=0.967\n",
      "Testing on validation set\n",
      "  acc=0.714\n",
      "Training epoch 66\n",
      "  batch    1: loss=0.846\n",
      "  batch    2: loss=0.663\n",
      "  batch    3: loss=0.414\n",
      "  batch    4: loss=0.546\n",
      "  batch    5: loss=0.765\n",
      "  batch    6: loss=0.595\n",
      "  batch    7: loss=0.531\n",
      "  batch    8: loss=0.443\n",
      "  batch    9: loss=0.415\n",
      "  batch   10: loss=0.554\n",
      "  batch   11: loss=0.610\n",
      "  batch   12: loss=0.650\n",
      "  batch   13: loss=0.559\n",
      "  batch   14: loss=0.430\n",
      "  batch   15: loss=0.897\n",
      "  batch   16: loss=0.602\n",
      "  batch   17: loss=0.576\n",
      "  batch   18: loss=0.966\n",
      "  batch   19: loss=0.536\n",
      "  batch   20: loss=0.546\n",
      "  batch   21: loss=0.629\n",
      "  batch   22: loss=0.605\n",
      "  batch   23: loss=0.686\n",
      "  batch   24: loss=0.369\n",
      "  batch   25: loss=0.646\n",
      "  batch   26: loss=0.960\n",
      "  batch   27: loss=0.641\n",
      "  batch   28: loss=0.459\n",
      "  batch   29: loss=0.598\n",
      "  batch   30: loss=0.494\n",
      "  batch   31: loss=0.513\n",
      "  batch   32: loss=0.566\n",
      "  batch   33: loss=0.613\n",
      "  batch   34: loss=0.459\n",
      "  batch   35: loss=0.811\n",
      "  batch   36: loss=0.859\n",
      "  batch   37: loss=0.681\n",
      "  batch   38: loss=0.613\n",
      "  batch   39: loss=0.798\n",
      "  batch   40: loss=0.519\n",
      "  batch   41: loss=0.664\n",
      "  batch   42: loss=0.939\n",
      "  batch   43: loss=0.606\n",
      "  batch   44: loss=0.844\n",
      "  batch   45: loss=0.581\n",
      "  batch   46: loss=0.877\n",
      "  batch   47: loss=0.784\n",
      "  batch   48: loss=0.591\n",
      "  batch   49: loss=0.578\n",
      "  batch   50: loss=0.686\n",
      "  batch   51: loss=0.731\n",
      "  batch   52: loss=0.851\n",
      "  batch   53: loss=0.433\n",
      "  batch   54: loss=0.779\n",
      "  batch   55: loss=0.671\n",
      "  batch   56: loss=0.714\n",
      "  batch   57: loss=0.685\n",
      "  batch   58: loss=0.626\n",
      "  batch   59: loss=1.007\n",
      "  batch   60: loss=0.716\n",
      "  batch   61: loss=0.715\n",
      "  batch   62: loss=0.656\n",
      "  batch   63: loss=0.954\n",
      "  batch   64: loss=0.709\n",
      "  batch   65: loss=0.718\n",
      "  batch   66: loss=0.897\n",
      "  batch   67: loss=0.567\n",
      "  batch   68: loss=0.807\n",
      "  batch   69: loss=1.069\n",
      "  batch   70: loss=0.799\n",
      "  batch   71: loss=0.825\n",
      "  batch   72: loss=0.966\n",
      "  batch   73: loss=0.655\n",
      "  batch   74: loss=0.412\n",
      "  batch   75: loss=1.022\n",
      "  batch   76: loss=0.822\n",
      "  batch   77: loss=0.826\n",
      "  batch   78: loss=0.710\n",
      "  batch   79: loss=0.719\n",
      "  batch   80: loss=0.583\n",
      "  batch   81: loss=0.621\n",
      "  batch   82: loss=0.917\n",
      "Testing on validation set\n",
      "  acc=0.691\n",
      "Training epoch 67\n",
      "  batch    1: loss=0.885\n",
      "  batch    2: loss=0.488\n",
      "  batch    3: loss=0.756\n",
      "  batch    4: loss=0.483\n",
      "  batch    5: loss=0.960\n",
      "  batch    6: loss=0.984\n",
      "  batch    7: loss=0.763\n",
      "  batch    8: loss=0.525\n",
      "  batch    9: loss=0.734\n",
      "  batch   10: loss=0.766\n",
      "  batch   11: loss=0.510\n",
      "  batch   12: loss=0.677\n",
      "  batch   13: loss=0.640\n",
      "  batch   14: loss=0.840\n",
      "  batch   15: loss=0.554\n",
      "  batch   16: loss=0.593\n",
      "  batch   17: loss=0.736\n",
      "  batch   18: loss=0.362\n",
      "  batch   19: loss=0.657\n",
      "  batch   20: loss=0.820\n",
      "  batch   21: loss=0.499\n",
      "  batch   22: loss=0.789\n",
      "  batch   23: loss=0.452\n",
      "  batch   24: loss=0.855\n",
      "  batch   25: loss=0.507\n",
      "  batch   26: loss=0.370\n",
      "  batch   27: loss=0.725\n",
      "  batch   28: loss=0.673\n",
      "  batch   29: loss=0.346\n",
      "  batch   30: loss=0.820\n",
      "  batch   31: loss=0.637\n",
      "  batch   32: loss=0.627\n",
      "  batch   33: loss=0.649\n",
      "  batch   34: loss=0.877\n",
      "  batch   35: loss=0.581\n",
      "  batch   36: loss=0.603\n",
      "  batch   37: loss=0.435\n",
      "  batch   38: loss=0.697\n",
      "  batch   39: loss=0.800\n",
      "  batch   40: loss=0.724\n",
      "  batch   41: loss=0.488\n",
      "  batch   42: loss=0.785\n",
      "  batch   43: loss=0.921\n",
      "  batch   44: loss=0.757\n",
      "  batch   45: loss=0.933\n",
      "  batch   46: loss=0.822\n",
      "  batch   47: loss=0.824\n",
      "  batch   48: loss=0.736\n",
      "  batch   49: loss=0.683\n",
      "  batch   50: loss=0.714\n",
      "  batch   51: loss=0.581\n",
      "  batch   52: loss=0.518\n",
      "  batch   53: loss=0.819\n",
      "  batch   54: loss=0.520\n",
      "  batch   55: loss=0.612\n",
      "  batch   56: loss=0.617\n",
      "  batch   57: loss=1.047\n",
      "  batch   58: loss=0.780\n",
      "  batch   59: loss=0.774\n",
      "  batch   60: loss=0.701\n",
      "  batch   61: loss=0.550\n",
      "  batch   62: loss=0.681\n",
      "  batch   63: loss=0.741\n",
      "  batch   64: loss=0.829\n",
      "  batch   65: loss=0.726\n",
      "  batch   66: loss=0.434\n",
      "  batch   67: loss=0.537\n",
      "  batch   68: loss=0.688\n",
      "  batch   69: loss=0.480\n",
      "  batch   70: loss=0.806\n",
      "  batch   71: loss=0.779\n",
      "  batch   72: loss=0.802\n",
      "  batch   73: loss=0.558\n",
      "  batch   74: loss=0.674\n",
      "  batch   75: loss=0.704\n",
      "  batch   76: loss=0.533\n",
      "  batch   77: loss=0.854\n",
      "  batch   78: loss=0.651\n",
      "  batch   79: loss=0.715\n",
      "  batch   80: loss=0.581\n",
      "  batch   81: loss=0.583\n",
      "  batch   82: loss=0.795\n",
      "Testing on validation set\n",
      "  acc=0.715\n",
      "Training epoch 68\n",
      "  batch    1: loss=0.372\n",
      "  batch    2: loss=0.565\n",
      "  batch    3: loss=0.551\n",
      "  batch    4: loss=0.577\n",
      "  batch    5: loss=0.628\n",
      "  batch    6: loss=0.931\n",
      "  batch    7: loss=0.614\n",
      "  batch    8: loss=0.520\n",
      "  batch    9: loss=0.582\n",
      "  batch   10: loss=0.585\n",
      "  batch   11: loss=0.677\n",
      "  batch   12: loss=0.628\n",
      "  batch   13: loss=0.393\n",
      "  batch   14: loss=0.562\n",
      "  batch   15: loss=0.839\n",
      "  batch   16: loss=0.646\n",
      "  batch   17: loss=0.519\n",
      "  batch   18: loss=0.530\n",
      "  batch   19: loss=0.704\n",
      "  batch   20: loss=0.661\n",
      "  batch   21: loss=0.828\n",
      "  batch   22: loss=0.785\n",
      "  batch   23: loss=0.676\n",
      "  batch   24: loss=0.941\n",
      "  batch   25: loss=0.708\n",
      "  batch   26: loss=0.814\n",
      "  batch   27: loss=0.623\n",
      "  batch   28: loss=0.659\n",
      "  batch   29: loss=0.661\n",
      "  batch   30: loss=0.354\n",
      "  batch   31: loss=0.810\n",
      "  batch   32: loss=0.691\n",
      "  batch   33: loss=0.523\n",
      "  batch   34: loss=0.625\n",
      "  batch   35: loss=0.396\n",
      "  batch   36: loss=0.598\n",
      "  batch   37: loss=0.762\n",
      "  batch   38: loss=0.762\n",
      "  batch   39: loss=0.629\n",
      "  batch   40: loss=0.567\n",
      "  batch   41: loss=0.535\n",
      "  batch   42: loss=0.874\n",
      "  batch   43: loss=0.681\n",
      "  batch   44: loss=0.404\n",
      "  batch   45: loss=0.986\n",
      "  batch   46: loss=0.704\n",
      "  batch   47: loss=0.378\n",
      "  batch   48: loss=0.621\n",
      "  batch   49: loss=0.671\n",
      "  batch   50: loss=0.318\n",
      "  batch   51: loss=0.668\n",
      "  batch   52: loss=0.830\n",
      "  batch   53: loss=0.799\n",
      "  batch   54: loss=0.599\n",
      "  batch   55: loss=0.507\n",
      "  batch   56: loss=0.449\n",
      "  batch   57: loss=0.677\n",
      "  batch   58: loss=0.649\n",
      "  batch   59: loss=0.683\n",
      "  batch   60: loss=0.589\n",
      "  batch   61: loss=0.843\n",
      "  batch   62: loss=0.915\n",
      "  batch   63: loss=0.802\n",
      "  batch   64: loss=0.401\n",
      "  batch   65: loss=0.749\n",
      "  batch   66: loss=0.658\n",
      "  batch   67: loss=0.992\n",
      "  batch   68: loss=0.606\n",
      "  batch   69: loss=0.673\n",
      "  batch   70: loss=0.681\n",
      "  batch   71: loss=0.844\n",
      "  batch   72: loss=0.747\n",
      "  batch   73: loss=0.851\n",
      "  batch   74: loss=0.658\n",
      "  batch   75: loss=0.493\n",
      "  batch   76: loss=0.627\n",
      "  batch   77: loss=0.747\n",
      "  batch   78: loss=0.868\n",
      "  batch   79: loss=0.712\n",
      "  batch   80: loss=0.804\n",
      "  batch   81: loss=1.069\n",
      "  batch   82: loss=0.512\n",
      "Testing on validation set\n",
      "  acc=0.700\n",
      "Training epoch 69\n",
      "  batch    1: loss=0.713\n",
      "  batch    2: loss=0.465\n",
      "  batch    3: loss=0.850\n",
      "  batch    4: loss=0.502\n",
      "  batch    5: loss=0.718\n",
      "  batch    6: loss=0.325\n",
      "  batch    7: loss=0.647\n",
      "  batch    8: loss=0.570\n",
      "  batch    9: loss=0.775\n",
      "  batch   10: loss=0.565\n",
      "  batch   11: loss=0.627\n",
      "  batch   12: loss=0.952\n",
      "  batch   13: loss=0.961\n",
      "  batch   14: loss=0.457\n",
      "  batch   15: loss=0.610\n",
      "  batch   16: loss=0.685\n",
      "  batch   17: loss=0.620\n",
      "  batch   18: loss=0.735\n",
      "  batch   19: loss=0.409\n",
      "  batch   20: loss=0.654\n",
      "  batch   21: loss=0.656\n",
      "  batch   22: loss=0.555\n",
      "  batch   23: loss=0.403\n",
      "  batch   24: loss=0.662\n",
      "  batch   25: loss=0.636\n",
      "  batch   26: loss=0.736\n",
      "  batch   27: loss=0.681\n",
      "  batch   28: loss=0.425\n",
      "  batch   29: loss=0.453\n",
      "  batch   30: loss=0.584\n",
      "  batch   31: loss=0.532\n",
      "  batch   32: loss=0.548\n",
      "  batch   33: loss=0.841\n",
      "  batch   34: loss=0.713\n",
      "  batch   35: loss=0.486\n",
      "  batch   36: loss=0.600\n",
      "  batch   37: loss=0.356\n",
      "  batch   38: loss=0.658\n",
      "  batch   39: loss=0.774\n",
      "  batch   40: loss=0.638\n",
      "  batch   41: loss=0.438\n",
      "  batch   42: loss=0.962\n",
      "  batch   43: loss=0.447\n",
      "  batch   44: loss=0.673\n",
      "  batch   45: loss=0.654\n",
      "  batch   46: loss=0.628\n",
      "  batch   47: loss=0.935\n",
      "  batch   48: loss=0.600\n",
      "  batch   49: loss=0.488\n",
      "  batch   50: loss=0.498\n",
      "  batch   51: loss=0.754\n",
      "  batch   52: loss=0.608\n",
      "  batch   53: loss=0.694\n",
      "  batch   54: loss=0.572\n",
      "  batch   55: loss=0.401\n",
      "  batch   56: loss=0.767\n",
      "  batch   57: loss=0.701\n",
      "  batch   58: loss=0.536\n",
      "  batch   59: loss=0.912\n",
      "  batch   60: loss=0.772\n",
      "  batch   61: loss=0.578\n",
      "  batch   62: loss=0.661\n",
      "  batch   63: loss=0.709\n",
      "  batch   64: loss=0.911\n",
      "  batch   65: loss=0.802\n",
      "  batch   66: loss=0.753\n",
      "  batch   67: loss=0.526\n",
      "  batch   68: loss=0.658\n",
      "  batch   69: loss=0.628\n",
      "  batch   70: loss=0.685\n",
      "  batch   71: loss=0.521\n",
      "  batch   72: loss=0.508\n",
      "  batch   73: loss=0.602\n",
      "  batch   74: loss=0.633\n",
      "  batch   75: loss=0.724\n",
      "  batch   76: loss=0.558\n",
      "  batch   77: loss=0.665\n",
      "  batch   78: loss=0.544\n",
      "  batch   79: loss=0.584\n",
      "  batch   80: loss=0.550\n",
      "  batch   81: loss=0.655\n",
      "  batch   82: loss=1.439\n",
      "Testing on validation set\n",
      "  acc=0.706\n",
      "Training epoch 70\n",
      "  batch    1: loss=0.490\n",
      "  batch    2: loss=0.394\n",
      "  batch    3: loss=0.615\n",
      "  batch    4: loss=0.622\n",
      "  batch    5: loss=0.816\n",
      "  batch    6: loss=0.741\n",
      "  batch    7: loss=0.645\n",
      "  batch    8: loss=0.522\n",
      "  batch    9: loss=0.755\n",
      "  batch   10: loss=0.662\n",
      "  batch   11: loss=0.556\n",
      "  batch   12: loss=0.779\n",
      "  batch   13: loss=0.559\n",
      "  batch   14: loss=0.867\n",
      "  batch   15: loss=0.479\n",
      "  batch   16: loss=0.407\n",
      "  batch   17: loss=0.731\n",
      "  batch   18: loss=0.432\n",
      "  batch   19: loss=0.698\n",
      "  batch   20: loss=0.583\n",
      "  batch   21: loss=0.983\n",
      "  batch   22: loss=0.498\n",
      "  batch   23: loss=0.382\n",
      "  batch   24: loss=0.442\n",
      "  batch   25: loss=0.664\n",
      "  batch   26: loss=0.433\n",
      "  batch   27: loss=0.748\n",
      "  batch   28: loss=0.802\n",
      "  batch   29: loss=0.956\n",
      "  batch   30: loss=0.544\n",
      "  batch   31: loss=0.313\n",
      "  batch   32: loss=0.671\n",
      "  batch   33: loss=0.686\n",
      "  batch   34: loss=0.737\n",
      "  batch   35: loss=0.526\n",
      "  batch   36: loss=0.618\n",
      "  batch   37: loss=0.591\n",
      "  batch   38: loss=0.547\n",
      "  batch   39: loss=0.604\n",
      "  batch   40: loss=0.408\n",
      "  batch   41: loss=0.699\n",
      "  batch   42: loss=0.738\n",
      "  batch   43: loss=0.718\n",
      "  batch   44: loss=0.579\n",
      "  batch   45: loss=0.668\n",
      "  batch   46: loss=0.557\n",
      "  batch   47: loss=0.786\n",
      "  batch   48: loss=0.621\n",
      "  batch   49: loss=0.481\n",
      "  batch   50: loss=0.680\n",
      "  batch   51: loss=0.477\n",
      "  batch   52: loss=0.840\n",
      "  batch   53: loss=0.694\n",
      "  batch   54: loss=0.561\n",
      "  batch   55: loss=0.588\n",
      "  batch   56: loss=0.482\n",
      "  batch   57: loss=0.782\n",
      "  batch   58: loss=1.105\n",
      "  batch   59: loss=0.648\n",
      "  batch   60: loss=0.609\n",
      "  batch   61: loss=0.716\n",
      "  batch   62: loss=0.651\n",
      "  batch   63: loss=0.741\n",
      "  batch   64: loss=0.773\n",
      "  batch   65: loss=0.658\n",
      "  batch   66: loss=0.581\n",
      "  batch   67: loss=0.733\n",
      "  batch   68: loss=0.560\n",
      "  batch   69: loss=0.985\n",
      "  batch   70: loss=0.699\n",
      "  batch   71: loss=0.832\n",
      "  batch   72: loss=0.732\n",
      "  batch   73: loss=0.595\n",
      "  batch   74: loss=0.685\n",
      "  batch   75: loss=0.557\n",
      "  batch   76: loss=1.181\n",
      "  batch   77: loss=0.757\n",
      "  batch   78: loss=0.924\n",
      "  batch   79: loss=0.500\n",
      "  batch   80: loss=0.887\n",
      "  batch   81: loss=0.729\n",
      "  batch   82: loss=0.642\n",
      "Testing on validation set\n",
      "  acc=0.713\n",
      "Training epoch 71\n",
      "  batch    1: loss=0.440\n",
      "  batch    2: loss=0.459\n",
      "  batch    3: loss=0.640\n",
      "  batch    4: loss=0.525\n",
      "  batch    5: loss=0.504\n",
      "  batch    6: loss=0.407\n",
      "  batch    7: loss=0.786\n",
      "  batch    8: loss=0.849\n",
      "  batch    9: loss=0.544\n",
      "  batch   10: loss=0.941\n",
      "  batch   11: loss=0.420\n",
      "  batch   12: loss=0.484\n",
      "  batch   13: loss=0.780\n",
      "  batch   14: loss=0.763\n",
      "  batch   15: loss=0.660\n",
      "  batch   16: loss=0.494\n",
      "  batch   17: loss=0.719\n",
      "  batch   18: loss=0.566\n",
      "  batch   19: loss=0.645\n",
      "  batch   20: loss=0.613\n",
      "  batch   21: loss=0.626\n",
      "  batch   22: loss=0.429\n",
      "  batch   23: loss=0.409\n",
      "  batch   24: loss=0.840\n",
      "  batch   25: loss=0.552\n",
      "  batch   26: loss=0.828\n",
      "  batch   27: loss=0.579\n",
      "  batch   28: loss=0.629\n",
      "  batch   29: loss=0.472\n",
      "  batch   30: loss=0.855\n",
      "  batch   31: loss=0.360\n",
      "  batch   32: loss=0.539\n",
      "  batch   33: loss=0.595\n",
      "  batch   34: loss=0.588\n",
      "  batch   35: loss=0.761\n",
      "  batch   36: loss=0.763\n",
      "  batch   37: loss=0.605\n",
      "  batch   38: loss=0.680\n",
      "  batch   39: loss=0.632\n",
      "  batch   40: loss=0.663\n",
      "  batch   41: loss=0.648\n",
      "  batch   42: loss=0.476\n",
      "  batch   43: loss=0.767\n",
      "  batch   44: loss=0.451\n",
      "  batch   45: loss=0.282\n",
      "  batch   46: loss=0.509\n",
      "  batch   47: loss=0.927\n",
      "  batch   48: loss=0.693\n",
      "  batch   49: loss=0.747\n",
      "  batch   50: loss=0.375\n",
      "  batch   51: loss=0.655\n",
      "  batch   52: loss=0.972\n",
      "  batch   53: loss=0.598\n",
      "  batch   54: loss=0.540\n",
      "  batch   55: loss=0.619\n",
      "  batch   56: loss=0.620\n",
      "  batch   57: loss=0.810\n",
      "  batch   58: loss=0.375\n",
      "  batch   59: loss=0.784\n",
      "  batch   60: loss=0.897\n",
      "  batch   61: loss=0.684\n",
      "  batch   62: loss=0.742\n",
      "  batch   63: loss=0.386\n",
      "  batch   64: loss=0.647\n",
      "  batch   65: loss=0.504\n",
      "  batch   66: loss=0.513\n",
      "  batch   67: loss=0.635\n",
      "  batch   68: loss=0.957\n",
      "  batch   69: loss=0.506\n",
      "  batch   70: loss=0.564\n",
      "  batch   71: loss=0.477\n",
      "  batch   72: loss=0.715\n",
      "  batch   73: loss=0.661\n",
      "  batch   74: loss=1.206\n",
      "  batch   75: loss=0.905\n",
      "  batch   76: loss=0.626\n",
      "  batch   77: loss=0.423\n",
      "  batch   78: loss=0.681\n",
      "  batch   79: loss=0.749\n",
      "  batch   80: loss=0.326\n",
      "  batch   81: loss=0.694\n",
      "  batch   82: loss=2.108\n",
      "Testing on validation set\n",
      "  acc=0.714\n",
      "Training epoch 72\n",
      "  batch    1: loss=0.407\n",
      "  batch    2: loss=0.567\n",
      "  batch    3: loss=0.435\n",
      "  batch    4: loss=0.700\n",
      "  batch    5: loss=0.889\n",
      "  batch    6: loss=0.654\n",
      "  batch    7: loss=0.620\n",
      "  batch    8: loss=0.561\n",
      "  batch    9: loss=0.877\n",
      "  batch   10: loss=0.738\n",
      "  batch   11: loss=0.635\n",
      "  batch   12: loss=0.396\n",
      "  batch   13: loss=0.815\n",
      "  batch   14: loss=0.492\n",
      "  batch   15: loss=0.524\n",
      "  batch   16: loss=0.682\n",
      "  batch   17: loss=0.625\n",
      "  batch   18: loss=0.702\n",
      "  batch   19: loss=0.726\n",
      "  batch   20: loss=0.569\n",
      "  batch   21: loss=0.561\n",
      "  batch   22: loss=0.545\n",
      "  batch   23: loss=0.563\n",
      "  batch   24: loss=0.457\n",
      "  batch   25: loss=0.476\n",
      "  batch   26: loss=0.563\n",
      "  batch   27: loss=0.721\n",
      "  batch   28: loss=0.430\n",
      "  batch   29: loss=0.412\n",
      "  batch   30: loss=0.770\n",
      "  batch   31: loss=0.530\n",
      "  batch   32: loss=0.788\n",
      "  batch   33: loss=0.910\n",
      "  batch   34: loss=0.655\n",
      "  batch   35: loss=0.654\n",
      "  batch   36: loss=0.588\n",
      "  batch   37: loss=0.730\n",
      "  batch   38: loss=0.532\n",
      "  batch   39: loss=0.697\n",
      "  batch   40: loss=0.623\n",
      "  batch   41: loss=0.929\n",
      "  batch   42: loss=0.863\n",
      "  batch   43: loss=0.801\n",
      "  batch   44: loss=0.431\n",
      "  batch   45: loss=0.628\n",
      "  batch   46: loss=0.376\n",
      "  batch   47: loss=0.433\n",
      "  batch   48: loss=0.573\n",
      "  batch   49: loss=0.648\n",
      "  batch   50: loss=0.668\n",
      "  batch   51: loss=0.738\n",
      "  batch   52: loss=0.257\n",
      "  batch   53: loss=0.783\n",
      "  batch   54: loss=0.618\n",
      "  batch   55: loss=0.543\n",
      "  batch   56: loss=0.758\n",
      "  batch   57: loss=0.392\n",
      "  batch   58: loss=0.604\n",
      "  batch   59: loss=0.833\n",
      "  batch   60: loss=0.638\n",
      "  batch   61: loss=0.559\n",
      "  batch   62: loss=0.485\n",
      "  batch   63: loss=0.583\n",
      "  batch   64: loss=0.892\n",
      "  batch   65: loss=0.842\n",
      "  batch   66: loss=0.619\n",
      "  batch   67: loss=0.896\n",
      "  batch   68: loss=0.596\n",
      "  batch   69: loss=0.696\n",
      "  batch   70: loss=0.806\n",
      "  batch   71: loss=0.660\n",
      "  batch   72: loss=0.898\n",
      "  batch   73: loss=0.580\n",
      "  batch   74: loss=0.722\n",
      "  batch   75: loss=0.872\n",
      "  batch   76: loss=0.733\n",
      "  batch   77: loss=0.757\n",
      "  batch   78: loss=0.681\n",
      "  batch   79: loss=0.712\n",
      "  batch   80: loss=0.480\n",
      "  batch   81: loss=0.458\n",
      "  batch   82: loss=0.934\n",
      "Testing on validation set\n",
      "  acc=0.724\n",
      "Training epoch 73\n",
      "  batch    1: loss=0.767\n",
      "  batch    2: loss=0.702\n",
      "  batch    3: loss=0.691\n",
      "  batch    4: loss=0.549\n",
      "  batch    5: loss=0.652\n",
      "  batch    6: loss=0.330\n",
      "  batch    7: loss=0.450\n",
      "  batch    8: loss=0.497\n",
      "  batch    9: loss=0.399\n",
      "  batch   10: loss=1.026\n",
      "  batch   11: loss=0.674\n",
      "  batch   12: loss=0.599\n",
      "  batch   13: loss=0.651\n",
      "  batch   14: loss=0.648\n",
      "  batch   15: loss=0.525\n",
      "  batch   16: loss=0.824\n",
      "  batch   17: loss=0.665\n",
      "  batch   18: loss=0.815\n",
      "  batch   19: loss=0.544\n",
      "  batch   20: loss=0.536\n",
      "  batch   21: loss=0.420\n",
      "  batch   22: loss=0.775\n",
      "  batch   23: loss=0.426\n",
      "  batch   24: loss=0.398\n",
      "  batch   25: loss=0.303\n",
      "  batch   26: loss=0.392\n",
      "  batch   27: loss=0.847\n",
      "  batch   28: loss=0.550\n",
      "  batch   29: loss=0.734\n",
      "  batch   30: loss=0.473\n",
      "  batch   31: loss=0.568\n",
      "  batch   32: loss=0.495\n",
      "  batch   33: loss=0.616\n",
      "  batch   34: loss=0.705\n",
      "  batch   35: loss=0.551\n",
      "  batch   36: loss=1.036\n",
      "  batch   37: loss=0.517\n",
      "  batch   38: loss=0.809\n",
      "  batch   39: loss=0.689\n",
      "  batch   40: loss=0.517\n",
      "  batch   41: loss=0.559\n",
      "  batch   42: loss=0.561\n",
      "  batch   43: loss=0.562\n",
      "  batch   44: loss=0.548\n",
      "  batch   45: loss=0.505\n",
      "  batch   46: loss=0.668\n",
      "  batch   47: loss=0.574\n",
      "  batch   48: loss=0.743\n",
      "  batch   49: loss=0.514\n",
      "  batch   50: loss=0.652\n",
      "  batch   51: loss=0.470\n",
      "  batch   52: loss=0.979\n",
      "  batch   53: loss=0.553\n",
      "  batch   54: loss=0.671\n",
      "  batch   55: loss=0.594\n",
      "  batch   56: loss=0.646\n",
      "  batch   57: loss=0.587\n",
      "  batch   58: loss=0.666\n",
      "  batch   59: loss=0.713\n",
      "  batch   60: loss=1.142\n",
      "  batch   61: loss=0.630\n",
      "  batch   62: loss=0.437\n",
      "  batch   63: loss=0.687\n",
      "  batch   64: loss=0.471\n",
      "  batch   65: loss=0.868\n",
      "  batch   66: loss=0.894\n",
      "  batch   67: loss=0.792\n",
      "  batch   68: loss=0.698\n",
      "  batch   69: loss=0.695\n",
      "  batch   70: loss=0.621\n",
      "  batch   71: loss=0.639\n",
      "  batch   72: loss=0.486\n",
      "  batch   73: loss=0.856\n",
      "  batch   74: loss=0.773\n",
      "  batch   75: loss=0.583\n",
      "  batch   76: loss=0.621\n",
      "  batch   77: loss=0.702\n",
      "  batch   78: loss=0.591\n",
      "  batch   79: loss=0.668\n",
      "  batch   80: loss=0.367\n",
      "  batch   81: loss=0.980\n",
      "  batch   82: loss=0.536\n",
      "Testing on validation set\n",
      "  acc=0.713\n",
      "Training epoch 74\n",
      "  batch    1: loss=0.588\n",
      "  batch    2: loss=0.542\n",
      "  batch    3: loss=0.476\n",
      "  batch    4: loss=0.673\n",
      "  batch    5: loss=0.482\n",
      "  batch    6: loss=0.571\n",
      "  batch    7: loss=0.653\n",
      "  batch    8: loss=0.641\n",
      "  batch    9: loss=0.248\n",
      "  batch   10: loss=0.489\n",
      "  batch   11: loss=0.327\n",
      "  batch   12: loss=0.714\n",
      "  batch   13: loss=0.572\n",
      "  batch   14: loss=0.823\n",
      "  batch   15: loss=0.736\n",
      "  batch   16: loss=0.662\n",
      "  batch   17: loss=0.541\n",
      "  batch   18: loss=0.679\n",
      "  batch   19: loss=0.281\n",
      "  batch   20: loss=0.681\n",
      "  batch   21: loss=0.425\n",
      "  batch   22: loss=0.713\n",
      "  batch   23: loss=0.759\n",
      "  batch   24: loss=0.831\n",
      "  batch   25: loss=0.583\n",
      "  batch   26: loss=0.628\n",
      "  batch   27: loss=0.474\n",
      "  batch   28: loss=0.502\n",
      "  batch   29: loss=0.876\n",
      "  batch   30: loss=0.561\n",
      "  batch   31: loss=0.639\n",
      "  batch   32: loss=0.553\n",
      "  batch   33: loss=0.621\n",
      "  batch   34: loss=0.595\n",
      "  batch   35: loss=0.650\n",
      "  batch   36: loss=0.682\n",
      "  batch   37: loss=0.559\n",
      "  batch   38: loss=0.755\n",
      "  batch   39: loss=0.849\n",
      "  batch   40: loss=0.617\n",
      "  batch   41: loss=0.492\n",
      "  batch   42: loss=0.463\n",
      "  batch   43: loss=0.531\n",
      "  batch   44: loss=0.656\n",
      "  batch   45: loss=0.668\n",
      "  batch   46: loss=0.864\n",
      "  batch   47: loss=0.670\n",
      "  batch   48: loss=0.475\n",
      "  batch   49: loss=0.459\n",
      "  batch   50: loss=0.520\n",
      "  batch   51: loss=0.731\n",
      "  batch   52: loss=0.470\n",
      "  batch   53: loss=0.525\n",
      "  batch   54: loss=0.536\n",
      "  batch   55: loss=0.693\n",
      "  batch   56: loss=0.507\n",
      "  batch   57: loss=0.643\n",
      "  batch   58: loss=0.535\n",
      "  batch   59: loss=0.809\n",
      "  batch   60: loss=0.672\n",
      "  batch   61: loss=0.559\n",
      "  batch   62: loss=0.592\n",
      "  batch   63: loss=0.802\n",
      "  batch   64: loss=0.463\n",
      "  batch   65: loss=0.697\n",
      "  batch   66: loss=0.657\n",
      "  batch   67: loss=0.363\n",
      "  batch   68: loss=0.539\n",
      "  batch   69: loss=0.553\n",
      "  batch   70: loss=0.827\n",
      "  batch   71: loss=0.520\n",
      "  batch   72: loss=0.563\n",
      "  batch   73: loss=0.334\n",
      "  batch   74: loss=0.492\n",
      "  batch   75: loss=0.427\n",
      "  batch   76: loss=0.760\n",
      "  batch   77: loss=0.913\n",
      "  batch   78: loss=0.330\n",
      "  batch   79: loss=0.525\n",
      "  batch   80: loss=0.675\n",
      "  batch   81: loss=0.629\n",
      "  batch   82: loss=0.476\n",
      "Testing on validation set\n",
      "  acc=0.702\n",
      "Training epoch 75\n",
      "  batch    1: loss=0.709\n",
      "  batch    2: loss=0.283\n",
      "  batch    3: loss=0.362\n",
      "  batch    4: loss=0.745\n",
      "  batch    5: loss=0.565\n",
      "  batch    6: loss=0.485\n",
      "  batch    7: loss=0.484\n",
      "  batch    8: loss=0.552\n",
      "  batch    9: loss=0.536\n",
      "  batch   10: loss=0.647\n",
      "  batch   11: loss=0.769\n",
      "  batch   12: loss=0.540\n",
      "  batch   13: loss=0.778\n",
      "  batch   14: loss=1.031\n",
      "  batch   15: loss=0.822\n",
      "  batch   16: loss=0.819\n",
      "  batch   17: loss=0.630\n",
      "  batch   18: loss=0.527\n",
      "  batch   19: loss=0.606\n",
      "  batch   20: loss=0.558\n",
      "  batch   21: loss=0.719\n",
      "  batch   22: loss=0.700\n",
      "  batch   23: loss=0.515\n",
      "  batch   24: loss=0.910\n",
      "  batch   25: loss=0.798\n",
      "  batch   26: loss=0.855\n",
      "  batch   27: loss=0.484\n",
      "  batch   28: loss=0.610\n",
      "  batch   29: loss=0.459\n",
      "  batch   30: loss=0.368\n",
      "  batch   31: loss=0.615\n",
      "  batch   32: loss=0.585\n",
      "  batch   33: loss=0.496\n",
      "  batch   34: loss=0.790\n",
      "  batch   35: loss=0.357\n",
      "  batch   36: loss=0.609\n",
      "  batch   37: loss=0.577\n",
      "  batch   38: loss=0.491\n",
      "  batch   39: loss=0.525\n",
      "  batch   40: loss=0.694\n",
      "  batch   41: loss=0.538\n",
      "  batch   42: loss=0.501\n",
      "  batch   43: loss=0.561\n",
      "  batch   44: loss=0.574\n",
      "  batch   45: loss=0.959\n",
      "  batch   46: loss=0.642\n",
      "  batch   47: loss=0.558\n",
      "  batch   48: loss=0.604\n",
      "  batch   49: loss=0.503\n",
      "  batch   50: loss=0.714\n",
      "  batch   51: loss=0.615\n",
      "  batch   52: loss=0.697\n",
      "  batch   53: loss=0.649\n",
      "  batch   54: loss=0.644\n",
      "  batch   55: loss=0.445\n",
      "  batch   56: loss=0.417\n",
      "  batch   57: loss=0.912\n",
      "  batch   58: loss=0.666\n",
      "  batch   59: loss=0.816\n",
      "  batch   60: loss=0.473\n",
      "  batch   61: loss=0.602\n",
      "  batch   62: loss=0.586\n",
      "  batch   63: loss=0.490\n",
      "  batch   64: loss=0.817\n",
      "  batch   65: loss=0.544\n",
      "  batch   66: loss=0.435\n",
      "  batch   67: loss=0.316\n",
      "  batch   68: loss=0.709\n",
      "  batch   69: loss=0.430\n",
      "  batch   70: loss=0.714\n",
      "  batch   71: loss=0.527\n",
      "  batch   72: loss=0.480\n",
      "  batch   73: loss=0.591\n",
      "  batch   74: loss=0.780\n",
      "  batch   75: loss=0.646\n",
      "  batch   76: loss=0.486\n",
      "  batch   77: loss=0.798\n",
      "  batch   78: loss=0.750\n",
      "  batch   79: loss=0.581\n",
      "  batch   80: loss=0.632\n",
      "  batch   81: loss=0.574\n",
      "  batch   82: loss=1.074\n",
      "Testing on validation set\n",
      "  acc=0.717\n",
      "Training epoch 76\n",
      "  batch    1: loss=0.675\n",
      "  batch    2: loss=0.433\n",
      "  batch    3: loss=0.497\n",
      "  batch    4: loss=0.730\n",
      "  batch    5: loss=0.824\n",
      "  batch    6: loss=0.750\n",
      "  batch    7: loss=0.732\n",
      "  batch    8: loss=0.528\n",
      "  batch    9: loss=0.926\n",
      "  batch   10: loss=1.040\n",
      "  batch   11: loss=0.753\n",
      "  batch   12: loss=0.600\n",
      "  batch   13: loss=0.659\n",
      "  batch   14: loss=0.462\n",
      "  batch   15: loss=0.771\n",
      "  batch   16: loss=0.546\n",
      "  batch   17: loss=0.542\n",
      "  batch   18: loss=0.454\n",
      "  batch   19: loss=0.884\n",
      "  batch   20: loss=0.504\n",
      "  batch   21: loss=0.921\n",
      "  batch   22: loss=0.730\n",
      "  batch   23: loss=0.517\n",
      "  batch   24: loss=0.475\n",
      "  batch   25: loss=0.712\n",
      "  batch   26: loss=0.825\n",
      "  batch   27: loss=0.861\n",
      "  batch   28: loss=0.615\n",
      "  batch   29: loss=0.626\n",
      "  batch   30: loss=0.765\n",
      "  batch   31: loss=0.510\n",
      "  batch   32: loss=0.731\n",
      "  batch   33: loss=0.531\n",
      "  batch   34: loss=0.353\n",
      "  batch   35: loss=0.360\n",
      "  batch   36: loss=0.726\n",
      "  batch   37: loss=0.651\n",
      "  batch   38: loss=0.626\n",
      "  batch   39: loss=0.765\n",
      "  batch   40: loss=0.428\n",
      "  batch   41: loss=0.682\n",
      "  batch   42: loss=0.570\n",
      "  batch   43: loss=0.692\n",
      "  batch   44: loss=0.746\n",
      "  batch   45: loss=0.671\n",
      "  batch   46: loss=0.684\n",
      "  batch   47: loss=0.533\n",
      "  batch   48: loss=0.501\n",
      "  batch   49: loss=0.679\n",
      "  batch   50: loss=0.576\n",
      "  batch   51: loss=0.632\n",
      "  batch   52: loss=0.520\n",
      "  batch   53: loss=0.719\n",
      "  batch   54: loss=0.713\n",
      "  batch   55: loss=0.408\n",
      "  batch   56: loss=0.499\n",
      "  batch   57: loss=0.633\n",
      "  batch   58: loss=0.860\n",
      "  batch   59: loss=0.725\n",
      "  batch   60: loss=0.622\n",
      "  batch   61: loss=0.815\n",
      "  batch   62: loss=0.831\n",
      "  batch   63: loss=0.448\n",
      "  batch   64: loss=0.811\n",
      "  batch   65: loss=0.697\n",
      "  batch   66: loss=0.501\n",
      "  batch   67: loss=0.705\n",
      "  batch   68: loss=0.665\n",
      "  batch   69: loss=0.583\n",
      "  batch   70: loss=0.713\n",
      "  batch   71: loss=0.666\n",
      "  batch   72: loss=0.961\n",
      "  batch   73: loss=0.413\n",
      "  batch   74: loss=0.547\n",
      "  batch   75: loss=0.731\n",
      "  batch   76: loss=0.519\n",
      "  batch   77: loss=0.824\n",
      "  batch   78: loss=0.549\n",
      "  batch   79: loss=0.418\n",
      "  batch   80: loss=0.634\n",
      "  batch   81: loss=0.781\n",
      "  batch   82: loss=0.862\n",
      "Testing on validation set\n",
      "  acc=0.715\n",
      "Training epoch 77\n",
      "  batch    1: loss=0.667\n",
      "  batch    2: loss=0.409\n",
      "  batch    3: loss=0.601\n",
      "  batch    4: loss=0.355\n",
      "  batch    5: loss=0.420\n",
      "  batch    6: loss=0.391\n",
      "  batch    7: loss=0.703\n",
      "  batch    8: loss=0.871\n",
      "  batch    9: loss=0.585\n",
      "  batch   10: loss=0.548\n",
      "  batch   11: loss=1.025\n",
      "  batch   12: loss=0.508\n",
      "  batch   13: loss=0.706\n",
      "  batch   14: loss=0.478\n",
      "  batch   15: loss=0.565\n",
      "  batch   16: loss=0.801\n",
      "  batch   17: loss=0.620\n",
      "  batch   18: loss=0.768\n",
      "  batch   19: loss=0.607\n",
      "  batch   20: loss=0.584\n",
      "  batch   21: loss=0.604\n",
      "  batch   22: loss=0.406\n",
      "  batch   23: loss=0.982\n",
      "  batch   24: loss=0.377\n",
      "  batch   25: loss=0.469\n",
      "  batch   26: loss=0.667\n",
      "  batch   27: loss=0.494\n",
      "  batch   28: loss=0.976\n",
      "  batch   29: loss=0.648\n",
      "  batch   30: loss=0.496\n",
      "  batch   31: loss=0.777\n",
      "  batch   32: loss=0.559\n",
      "  batch   33: loss=0.686\n",
      "  batch   34: loss=0.353\n",
      "  batch   35: loss=0.803\n",
      "  batch   36: loss=0.472\n",
      "  batch   37: loss=0.590\n",
      "  batch   38: loss=0.430\n",
      "  batch   39: loss=0.772\n",
      "  batch   40: loss=0.566\n",
      "  batch   41: loss=0.605\n",
      "  batch   42: loss=0.387\n",
      "  batch   43: loss=0.973\n",
      "  batch   44: loss=0.653\n",
      "  batch   45: loss=0.639\n",
      "  batch   46: loss=0.878\n",
      "  batch   47: loss=0.492\n",
      "  batch   48: loss=0.271\n",
      "  batch   49: loss=0.568\n",
      "  batch   50: loss=0.536\n",
      "  batch   51: loss=0.725\n",
      "  batch   52: loss=0.675\n",
      "  batch   53: loss=0.492\n",
      "  batch   54: loss=0.636\n",
      "  batch   55: loss=0.618\n",
      "  batch   56: loss=0.593\n",
      "  batch   57: loss=0.595\n",
      "  batch   58: loss=0.463\n",
      "  batch   59: loss=0.537\n",
      "  batch   60: loss=0.528\n",
      "  batch   61: loss=0.436\n",
      "  batch   62: loss=0.700\n",
      "  batch   63: loss=0.482\n",
      "  batch   64: loss=0.549\n",
      "  batch   65: loss=0.619\n",
      "  batch   66: loss=0.523\n",
      "  batch   67: loss=0.569\n",
      "  batch   68: loss=0.558\n",
      "  batch   69: loss=0.425\n",
      "  batch   70: loss=0.816\n",
      "  batch   71: loss=0.398\n",
      "  batch   72: loss=0.680\n",
      "  batch   73: loss=0.526\n",
      "  batch   74: loss=0.557\n",
      "  batch   75: loss=0.576\n",
      "  batch   76: loss=0.738\n",
      "  batch   77: loss=0.412\n",
      "  batch   78: loss=0.776\n",
      "  batch   79: loss=0.493\n",
      "  batch   80: loss=0.726\n",
      "  batch   81: loss=0.347\n",
      "  batch   82: loss=0.799\n",
      "Testing on validation set\n",
      "  acc=0.700\n",
      "Training epoch 78\n",
      "  batch    1: loss=0.548\n",
      "  batch    2: loss=0.384\n",
      "  batch    3: loss=0.639\n",
      "  batch    4: loss=0.681\n",
      "  batch    5: loss=0.449\n",
      "  batch    6: loss=0.526\n",
      "  batch    7: loss=0.415\n",
      "  batch    8: loss=0.555\n",
      "  batch    9: loss=0.668\n",
      "  batch   10: loss=0.440\n",
      "  batch   11: loss=0.709\n",
      "  batch   12: loss=0.701\n",
      "  batch   13: loss=0.572\n",
      "  batch   14: loss=0.654\n",
      "  batch   15: loss=0.631\n",
      "  batch   16: loss=0.722\n",
      "  batch   17: loss=0.517\n",
      "  batch   18: loss=0.425\n",
      "  batch   19: loss=0.877\n",
      "  batch   20: loss=0.461\n",
      "  batch   21: loss=0.507\n",
      "  batch   22: loss=0.419\n",
      "  batch   23: loss=1.042\n",
      "  batch   24: loss=0.550\n",
      "  batch   25: loss=0.547\n",
      "  batch   26: loss=0.578\n",
      "  batch   27: loss=0.525\n",
      "  batch   28: loss=0.775\n",
      "  batch   29: loss=0.536\n",
      "  batch   30: loss=0.537\n",
      "  batch   31: loss=0.701\n",
      "  batch   32: loss=0.582\n",
      "  batch   33: loss=0.572\n",
      "  batch   34: loss=0.597\n",
      "  batch   35: loss=0.358\n",
      "  batch   36: loss=0.561\n",
      "  batch   37: loss=0.588\n",
      "  batch   38: loss=0.647\n",
      "  batch   39: loss=0.598\n",
      "  batch   40: loss=0.426\n",
      "  batch   41: loss=0.540\n",
      "  batch   42: loss=0.621\n",
      "  batch   43: loss=0.783\n",
      "  batch   44: loss=0.757\n",
      "  batch   45: loss=0.475\n",
      "  batch   46: loss=1.084\n",
      "  batch   47: loss=0.494\n",
      "  batch   48: loss=0.739\n",
      "  batch   49: loss=0.775\n",
      "  batch   50: loss=0.627\n",
      "  batch   51: loss=1.004\n",
      "  batch   52: loss=0.586\n",
      "  batch   53: loss=0.740\n",
      "  batch   54: loss=0.672\n",
      "  batch   55: loss=0.657\n",
      "  batch   56: loss=0.379\n",
      "  batch   57: loss=0.728\n",
      "  batch   58: loss=0.363\n",
      "  batch   59: loss=0.533\n",
      "  batch   60: loss=0.296\n",
      "  batch   61: loss=0.660\n",
      "  batch   62: loss=0.453\n",
      "  batch   63: loss=0.556\n",
      "  batch   64: loss=0.364\n",
      "  batch   65: loss=0.577\n",
      "  batch   66: loss=0.733\n",
      "  batch   67: loss=0.236\n",
      "  batch   68: loss=0.800\n",
      "  batch   69: loss=0.369\n",
      "  batch   70: loss=0.669\n",
      "  batch   71: loss=0.680\n",
      "  batch   72: loss=0.557\n",
      "  batch   73: loss=0.640\n",
      "  batch   74: loss=0.424\n",
      "  batch   75: loss=0.594\n",
      "  batch   76: loss=0.569\n",
      "  batch   77: loss=0.324\n",
      "  batch   78: loss=0.567\n",
      "  batch   79: loss=0.638\n",
      "  batch   80: loss=0.487\n",
      "  batch   81: loss=0.361\n",
      "  batch   82: loss=1.157\n",
      "Testing on validation set\n",
      "  acc=0.721\n",
      "Training epoch 79\n",
      "  batch    1: loss=0.599\n",
      "  batch    2: loss=0.593\n",
      "  batch    3: loss=0.729\n",
      "  batch    4: loss=0.529\n",
      "  batch    5: loss=0.357\n",
      "  batch    6: loss=0.477\n",
      "  batch    7: loss=0.515\n",
      "  batch    8: loss=0.411\n",
      "  batch    9: loss=0.825\n",
      "  batch   10: loss=0.658\n",
      "  batch   11: loss=0.552\n",
      "  batch   12: loss=0.409\n",
      "  batch   13: loss=0.714\n",
      "  batch   14: loss=0.562\n",
      "  batch   15: loss=0.542\n",
      "  batch   16: loss=0.504\n",
      "  batch   17: loss=0.621\n",
      "  batch   18: loss=0.490\n",
      "  batch   19: loss=0.615\n",
      "  batch   20: loss=0.522\n",
      "  batch   21: loss=0.344\n",
      "  batch   22: loss=0.708\n",
      "  batch   23: loss=0.380\n",
      "  batch   24: loss=0.442\n",
      "  batch   25: loss=0.504\n",
      "  batch   26: loss=0.581\n",
      "  batch   27: loss=0.437\n",
      "  batch   28: loss=0.447\n",
      "  batch   29: loss=0.618\n",
      "  batch   30: loss=0.679\n",
      "  batch   31: loss=0.480\n",
      "  batch   32: loss=0.733\n",
      "  batch   33: loss=0.770\n",
      "  batch   34: loss=0.591\n",
      "  batch   35: loss=0.615\n",
      "  batch   36: loss=0.798\n",
      "  batch   37: loss=0.563\n",
      "  batch   38: loss=0.803\n",
      "  batch   39: loss=0.508\n",
      "  batch   40: loss=0.398\n",
      "  batch   41: loss=0.652\n",
      "  batch   42: loss=0.605\n",
      "  batch   43: loss=0.437\n",
      "  batch   44: loss=0.607\n",
      "  batch   45: loss=0.507\n",
      "  batch   46: loss=0.744\n",
      "  batch   47: loss=0.646\n",
      "  batch   48: loss=0.682\n",
      "  batch   49: loss=0.487\n",
      "  batch   50: loss=0.810\n",
      "  batch   51: loss=0.556\n",
      "  batch   52: loss=0.778\n",
      "  batch   53: loss=0.442\n",
      "  batch   54: loss=0.734\n",
      "  batch   55: loss=0.514\n",
      "  batch   56: loss=0.686\n",
      "  batch   57: loss=0.797\n",
      "  batch   58: loss=0.564\n",
      "  batch   59: loss=0.775\n",
      "  batch   60: loss=0.481\n",
      "  batch   61: loss=0.446\n",
      "  batch   62: loss=0.721\n",
      "  batch   63: loss=0.706\n",
      "  batch   64: loss=0.530\n",
      "  batch   65: loss=0.463\n",
      "  batch   66: loss=0.611\n",
      "  batch   67: loss=0.543\n",
      "  batch   68: loss=0.352\n",
      "  batch   69: loss=0.620\n",
      "  batch   70: loss=0.561\n",
      "  batch   71: loss=0.590\n",
      "  batch   72: loss=0.556\n",
      "  batch   73: loss=0.656\n",
      "  batch   74: loss=0.587\n",
      "  batch   75: loss=0.506\n",
      "  batch   76: loss=0.741\n",
      "  batch   77: loss=0.875\n",
      "  batch   78: loss=0.589\n",
      "  batch   79: loss=0.573\n",
      "  batch   80: loss=0.666\n",
      "  batch   81: loss=0.660\n",
      "  batch   82: loss=0.638\n",
      "Testing on validation set\n",
      "  acc=0.728\n",
      "Training epoch 80\n",
      "  batch    1: loss=0.713\n",
      "  batch    2: loss=0.574\n",
      "  batch    3: loss=0.407\n",
      "  batch    4: loss=0.621\n",
      "  batch    5: loss=0.429\n",
      "  batch    6: loss=1.249\n",
      "  batch    7: loss=0.689\n",
      "  batch    8: loss=0.354\n",
      "  batch    9: loss=0.549\n",
      "  batch   10: loss=0.492\n",
      "  batch   11: loss=0.640\n",
      "  batch   12: loss=0.546\n",
      "  batch   13: loss=0.452\n",
      "  batch   14: loss=0.540\n",
      "  batch   15: loss=0.617\n",
      "  batch   16: loss=0.401\n",
      "  batch   17: loss=0.383\n",
      "  batch   18: loss=0.403\n",
      "  batch   19: loss=0.711\n",
      "  batch   20: loss=0.577\n",
      "  batch   21: loss=0.462\n",
      "  batch   22: loss=0.555\n",
      "  batch   23: loss=0.502\n",
      "  batch   24: loss=0.700\n",
      "  batch   25: loss=0.368\n",
      "  batch   26: loss=0.470\n",
      "  batch   27: loss=0.429\n",
      "  batch   28: loss=0.578\n",
      "  batch   29: loss=0.769\n",
      "  batch   30: loss=0.564\n",
      "  batch   31: loss=0.471\n",
      "  batch   32: loss=0.538\n",
      "  batch   33: loss=0.349\n",
      "  batch   34: loss=0.405\n",
      "  batch   35: loss=0.683\n",
      "  batch   36: loss=0.455\n",
      "  batch   37: loss=0.618\n",
      "  batch   38: loss=0.778\n",
      "  batch   39: loss=0.750\n",
      "  batch   40: loss=0.739\n",
      "  batch   41: loss=0.436\n",
      "  batch   42: loss=0.564\n",
      "  batch   43: loss=0.354\n",
      "  batch   44: loss=0.768\n",
      "  batch   45: loss=0.787\n",
      "  batch   46: loss=0.604\n",
      "  batch   47: loss=0.617\n",
      "  batch   48: loss=0.403\n",
      "  batch   49: loss=0.685\n",
      "  batch   50: loss=0.406\n",
      "  batch   51: loss=0.515\n",
      "  batch   52: loss=0.334\n",
      "  batch   53: loss=0.690\n",
      "  batch   54: loss=0.980\n",
      "  batch   55: loss=0.922\n",
      "  batch   56: loss=0.515\n",
      "  batch   57: loss=0.434\n",
      "  batch   58: loss=0.548\n",
      "  batch   59: loss=0.756\n",
      "  batch   60: loss=0.572\n",
      "  batch   61: loss=0.585\n",
      "  batch   62: loss=0.664\n",
      "  batch   63: loss=0.340\n",
      "  batch   64: loss=0.663\n",
      "  batch   65: loss=0.655\n",
      "  batch   66: loss=0.839\n",
      "  batch   67: loss=0.676\n",
      "  batch   68: loss=0.647\n",
      "  batch   69: loss=0.364\n",
      "  batch   70: loss=0.593\n",
      "  batch   71: loss=0.511\n",
      "  batch   72: loss=0.400\n",
      "  batch   73: loss=0.634\n",
      "  batch   74: loss=0.416\n",
      "  batch   75: loss=0.760\n",
      "  batch   76: loss=0.486\n",
      "  batch   77: loss=0.806\n",
      "  batch   78: loss=0.644\n",
      "  batch   79: loss=0.641\n",
      "  batch   80: loss=0.479\n",
      "  batch   81: loss=0.586\n",
      "  batch   82: loss=0.520\n",
      "Testing on validation set\n",
      "  acc=0.716\n",
      "Training epoch 81\n",
      "  batch    1: loss=0.488\n",
      "  batch    2: loss=0.893\n",
      "  batch    3: loss=0.365\n",
      "  batch    4: loss=0.763\n",
      "  batch    5: loss=0.453\n",
      "  batch    6: loss=0.437\n",
      "  batch    7: loss=0.363\n",
      "  batch    8: loss=0.571\n",
      "  batch    9: loss=0.416\n",
      "  batch   10: loss=0.487\n",
      "  batch   11: loss=0.510\n",
      "  batch   12: loss=0.447\n",
      "  batch   13: loss=0.858\n",
      "  batch   14: loss=0.700\n",
      "  batch   15: loss=0.433\n",
      "  batch   16: loss=0.443\n",
      "  batch   17: loss=0.495\n",
      "  batch   18: loss=0.556\n",
      "  batch   19: loss=0.385\n",
      "  batch   20: loss=0.562\n",
      "  batch   21: loss=0.732\n",
      "  batch   22: loss=0.519\n",
      "  batch   23: loss=0.575\n",
      "  batch   24: loss=0.321\n",
      "  batch   25: loss=0.411\n",
      "  batch   26: loss=0.576\n",
      "  batch   27: loss=0.599\n",
      "  batch   28: loss=0.484\n",
      "  batch   29: loss=0.539\n",
      "  batch   30: loss=0.513\n",
      "  batch   31: loss=0.457\n",
      "  batch   32: loss=0.724\n",
      "  batch   33: loss=0.380\n",
      "  batch   34: loss=0.900\n",
      "  batch   35: loss=0.636\n",
      "  batch   36: loss=0.682\n",
      "  batch   37: loss=0.708\n",
      "  batch   38: loss=0.757\n",
      "  batch   39: loss=0.769\n",
      "  batch   40: loss=0.531\n",
      "  batch   41: loss=0.600\n",
      "  batch   42: loss=0.413\n",
      "  batch   43: loss=0.459\n",
      "  batch   44: loss=0.342\n",
      "  batch   45: loss=0.445\n",
      "  batch   46: loss=0.571\n",
      "  batch   47: loss=0.380\n",
      "  batch   48: loss=0.304\n",
      "  batch   49: loss=0.514\n",
      "  batch   50: loss=0.582\n",
      "  batch   51: loss=0.796\n",
      "  batch   52: loss=0.447\n",
      "  batch   53: loss=0.574\n",
      "  batch   54: loss=0.606\n",
      "  batch   55: loss=0.713\n",
      "  batch   56: loss=0.427\n",
      "  batch   57: loss=0.875\n",
      "  batch   58: loss=0.380\n",
      "  batch   59: loss=0.470\n",
      "  batch   60: loss=0.352\n",
      "  batch   61: loss=0.618\n",
      "  batch   62: loss=0.552\n",
      "  batch   63: loss=0.504\n",
      "  batch   64: loss=0.416\n",
      "  batch   65: loss=0.607\n",
      "  batch   66: loss=0.291\n",
      "  batch   67: loss=0.533\n",
      "  batch   68: loss=0.372\n",
      "  batch   69: loss=0.673\n",
      "  batch   70: loss=0.481\n",
      "  batch   71: loss=0.636\n",
      "  batch   72: loss=0.491\n",
      "  batch   73: loss=0.415\n",
      "  batch   74: loss=0.923\n",
      "  batch   75: loss=0.373\n",
      "  batch   76: loss=0.463\n",
      "  batch   77: loss=0.399\n",
      "  batch   78: loss=0.251\n",
      "  batch   79: loss=0.476\n",
      "  batch   80: loss=0.624\n",
      "  batch   81: loss=0.324\n",
      "  batch   82: loss=0.687\n",
      "Testing on validation set\n",
      "  acc=0.732\n",
      "Training epoch 82\n",
      "  batch    1: loss=0.423\n",
      "  batch    2: loss=0.590\n",
      "  batch    3: loss=0.360\n",
      "  batch    4: loss=0.365\n",
      "  batch    5: loss=0.822\n",
      "  batch    6: loss=0.403\n",
      "  batch    7: loss=0.909\n",
      "  batch    8: loss=0.898\n",
      "  batch    9: loss=0.552\n",
      "  batch   10: loss=0.659\n",
      "  batch   11: loss=0.628\n",
      "  batch   12: loss=0.338\n",
      "  batch   13: loss=0.367\n",
      "  batch   14: loss=0.677\n",
      "  batch   15: loss=0.484\n",
      "  batch   16: loss=0.579\n",
      "  batch   17: loss=0.431\n",
      "  batch   18: loss=0.433\n",
      "  batch   19: loss=0.774\n",
      "  batch   20: loss=0.757\n",
      "  batch   21: loss=0.517\n",
      "  batch   22: loss=0.592\n",
      "  batch   23: loss=0.564\n",
      "  batch   24: loss=0.683\n",
      "  batch   25: loss=0.689\n",
      "  batch   26: loss=0.464\n",
      "  batch   27: loss=0.456\n",
      "  batch   28: loss=0.732\n",
      "  batch   29: loss=0.371\n",
      "  batch   30: loss=0.566\n",
      "  batch   31: loss=0.609\n",
      "  batch   32: loss=0.601\n",
      "  batch   33: loss=0.461\n",
      "  batch   34: loss=0.443\n",
      "  batch   35: loss=0.643\n",
      "  batch   36: loss=0.501\n",
      "  batch   37: loss=0.493\n",
      "  batch   38: loss=0.693\n",
      "  batch   39: loss=0.589\n",
      "  batch   40: loss=0.755\n",
      "  batch   41: loss=0.447\n",
      "  batch   42: loss=0.483\n",
      "  batch   43: loss=0.385\n",
      "  batch   44: loss=0.709\n",
      "  batch   45: loss=0.413\n",
      "  batch   46: loss=0.485\n",
      "  batch   47: loss=0.406\n",
      "  batch   48: loss=0.620\n",
      "  batch   49: loss=0.845\n",
      "  batch   50: loss=0.536\n",
      "  batch   51: loss=0.747\n",
      "  batch   52: loss=0.258\n",
      "  batch   53: loss=0.547\n",
      "  batch   54: loss=0.532\n",
      "  batch   55: loss=0.580\n",
      "  batch   56: loss=0.392\n",
      "  batch   57: loss=0.464\n",
      "  batch   58: loss=0.495\n",
      "  batch   59: loss=0.514\n",
      "  batch   60: loss=0.793\n",
      "  batch   61: loss=0.371\n",
      "  batch   62: loss=0.536\n",
      "  batch   63: loss=0.541\n",
      "  batch   64: loss=0.327\n",
      "  batch   65: loss=0.324\n",
      "  batch   66: loss=0.447\n",
      "  batch   67: loss=0.573\n",
      "  batch   68: loss=0.730\n",
      "  batch   69: loss=0.815\n",
      "  batch   70: loss=0.621\n",
      "  batch   71: loss=0.648\n",
      "  batch   72: loss=0.623\n",
      "  batch   73: loss=0.492\n",
      "  batch   74: loss=0.580\n",
      "  batch   75: loss=0.703\n",
      "  batch   76: loss=0.526\n",
      "  batch   77: loss=0.695\n",
      "  batch   78: loss=0.760\n",
      "  batch   79: loss=0.793\n",
      "  batch   80: loss=0.494\n",
      "  batch   81: loss=0.806\n",
      "  batch   82: loss=0.784\n",
      "Testing on validation set\n",
      "  acc=0.721\n",
      "Training epoch 83\n",
      "  batch    1: loss=0.429\n",
      "  batch    2: loss=0.667\n",
      "  batch    3: loss=0.732\n",
      "  batch    4: loss=0.407\n",
      "  batch    5: loss=0.534\n",
      "  batch    6: loss=0.271\n",
      "  batch    7: loss=0.456\n",
      "  batch    8: loss=0.850\n",
      "  batch    9: loss=0.465\n",
      "  batch   10: loss=0.565\n",
      "  batch   11: loss=0.427\n",
      "  batch   12: loss=0.766\n",
      "  batch   13: loss=0.473\n",
      "  batch   14: loss=0.871\n",
      "  batch   15: loss=0.421\n",
      "  batch   16: loss=0.655\n",
      "  batch   17: loss=0.478\n",
      "  batch   18: loss=0.691\n",
      "  batch   19: loss=0.664\n",
      "  batch   20: loss=0.550\n",
      "  batch   21: loss=0.420\n",
      "  batch   22: loss=0.318\n",
      "  batch   23: loss=0.354\n",
      "  batch   24: loss=0.401\n",
      "  batch   25: loss=0.517\n",
      "  batch   26: loss=0.470\n",
      "  batch   27: loss=0.707\n",
      "  batch   28: loss=0.674\n",
      "  batch   29: loss=0.530\n",
      "  batch   30: loss=0.689\n",
      "  batch   31: loss=0.936\n",
      "  batch   32: loss=0.562\n",
      "  batch   33: loss=0.623\n",
      "  batch   34: loss=0.599\n",
      "  batch   35: loss=0.231\n",
      "  batch   36: loss=0.572\n",
      "  batch   37: loss=0.574\n",
      "  batch   38: loss=0.394\n",
      "  batch   39: loss=0.492\n",
      "  batch   40: loss=1.018\n",
      "  batch   41: loss=0.575\n",
      "  batch   42: loss=0.485\n",
      "  batch   43: loss=0.308\n",
      "  batch   44: loss=0.496\n",
      "  batch   45: loss=0.499\n",
      "  batch   46: loss=0.423\n",
      "  batch   47: loss=0.757\n",
      "  batch   48: loss=0.685\n",
      "  batch   49: loss=0.676\n",
      "  batch   50: loss=0.543\n",
      "  batch   51: loss=0.387\n",
      "  batch   52: loss=0.647\n",
      "  batch   53: loss=0.394\n",
      "  batch   54: loss=0.465\n",
      "  batch   55: loss=0.686\n",
      "  batch   56: loss=0.657\n",
      "  batch   57: loss=0.448\n",
      "  batch   58: loss=0.615\n",
      "  batch   59: loss=0.717\n",
      "  batch   60: loss=0.457\n",
      "  batch   61: loss=0.395\n",
      "  batch   62: loss=0.500\n",
      "  batch   63: loss=0.351\n",
      "  batch   64: loss=0.559\n",
      "  batch   65: loss=0.481\n",
      "  batch   66: loss=0.407\n",
      "  batch   67: loss=0.536\n",
      "  batch   68: loss=0.763\n",
      "  batch   69: loss=0.670\n",
      "  batch   70: loss=0.538\n",
      "  batch   71: loss=0.475\n",
      "  batch   72: loss=0.447\n",
      "  batch   73: loss=0.569\n",
      "  batch   74: loss=0.491\n",
      "  batch   75: loss=0.585\n",
      "  batch   76: loss=0.754\n",
      "  batch   77: loss=0.516\n",
      "  batch   78: loss=0.837\n",
      "  batch   79: loss=0.371\n",
      "  batch   80: loss=0.674\n",
      "  batch   81: loss=0.568\n",
      "  batch   82: loss=0.632\n",
      "Testing on validation set\n",
      "  acc=0.729\n",
      "Training epoch 84\n",
      "  batch    1: loss=0.361\n",
      "  batch    2: loss=0.505\n",
      "  batch    3: loss=0.571\n",
      "  batch    4: loss=0.631\n",
      "  batch    5: loss=0.677\n",
      "  batch    6: loss=0.499\n",
      "  batch    7: loss=0.675\n",
      "  batch    8: loss=0.527\n",
      "  batch    9: loss=0.484\n",
      "  batch   10: loss=0.468\n",
      "  batch   11: loss=0.625\n",
      "  batch   12: loss=0.631\n",
      "  batch   13: loss=0.604\n",
      "  batch   14: loss=0.790\n",
      "  batch   15: loss=0.624\n",
      "  batch   16: loss=0.663\n",
      "  batch   17: loss=0.486\n",
      "  batch   18: loss=0.504\n",
      "  batch   19: loss=0.568\n",
      "  batch   20: loss=0.538\n",
      "  batch   21: loss=0.353\n",
      "  batch   22: loss=0.472\n",
      "  batch   23: loss=0.320\n",
      "  batch   24: loss=0.557\n",
      "  batch   25: loss=0.490\n",
      "  batch   26: loss=0.393\n",
      "  batch   27: loss=0.634\n",
      "  batch   28: loss=0.648\n",
      "  batch   29: loss=0.611\n",
      "  batch   30: loss=0.570\n",
      "  batch   31: loss=0.343\n",
      "  batch   32: loss=0.601\n",
      "  batch   33: loss=0.569\n",
      "  batch   34: loss=0.425\n",
      "  batch   35: loss=0.576\n",
      "  batch   36: loss=0.366\n",
      "  batch   37: loss=0.621\n",
      "  batch   38: loss=0.438\n",
      "  batch   39: loss=0.493\n",
      "  batch   40: loss=0.526\n",
      "  batch   41: loss=0.504\n",
      "  batch   42: loss=0.399\n",
      "  batch   43: loss=0.286\n",
      "  batch   44: loss=0.408\n",
      "  batch   45: loss=0.252\n",
      "  batch   46: loss=0.572\n",
      "  batch   47: loss=0.687\n",
      "  batch   48: loss=0.385\n",
      "  batch   49: loss=0.491\n",
      "  batch   50: loss=0.410\n",
      "  batch   51: loss=0.568\n",
      "  batch   52: loss=0.659\n",
      "  batch   53: loss=0.492\n",
      "  batch   54: loss=0.553\n",
      "  batch   55: loss=0.525\n",
      "  batch   56: loss=0.600\n",
      "  batch   57: loss=0.584\n",
      "  batch   58: loss=0.478\n",
      "  batch   59: loss=0.562\n",
      "  batch   60: loss=0.587\n",
      "  batch   61: loss=0.472\n",
      "  batch   62: loss=0.717\n",
      "  batch   63: loss=0.539\n",
      "  batch   64: loss=0.373\n",
      "  batch   65: loss=0.558\n",
      "  batch   66: loss=0.463\n",
      "  batch   67: loss=0.610\n",
      "  batch   68: loss=0.356\n",
      "  batch   69: loss=0.586\n",
      "  batch   70: loss=0.611\n",
      "  batch   71: loss=0.716\n",
      "  batch   72: loss=0.674\n",
      "  batch   73: loss=0.501\n",
      "  batch   74: loss=0.387\n",
      "  batch   75: loss=0.560\n",
      "  batch   76: loss=0.557\n",
      "  batch   77: loss=0.719\n",
      "  batch   78: loss=0.794\n",
      "  batch   79: loss=0.490\n",
      "  batch   80: loss=0.494\n",
      "  batch   81: loss=0.904\n",
      "  batch   82: loss=0.546\n",
      "Testing on validation set\n",
      "  acc=0.714\n",
      "Training epoch 85\n",
      "  batch    1: loss=0.478\n",
      "  batch    2: loss=0.646\n",
      "  batch    3: loss=0.689\n",
      "  batch    4: loss=0.425\n",
      "  batch    5: loss=0.586\n",
      "  batch    6: loss=0.418\n",
      "  batch    7: loss=0.426\n",
      "  batch    8: loss=0.453\n",
      "  batch    9: loss=0.629\n",
      "  batch   10: loss=0.508\n",
      "  batch   11: loss=0.570\n",
      "  batch   12: loss=0.485\n",
      "  batch   13: loss=0.411\n",
      "  batch   14: loss=0.423\n",
      "  batch   15: loss=0.451\n",
      "  batch   16: loss=0.448\n",
      "  batch   17: loss=0.615\n",
      "  batch   18: loss=0.474\n",
      "  batch   19: loss=0.474\n",
      "  batch   20: loss=0.817\n",
      "  batch   21: loss=0.405\n",
      "  batch   22: loss=0.679\n",
      "  batch   23: loss=0.415\n",
      "  batch   24: loss=0.758\n",
      "  batch   25: loss=0.404\n",
      "  batch   26: loss=0.482\n",
      "  batch   27: loss=0.386\n",
      "  batch   28: loss=0.476\n",
      "  batch   29: loss=0.249\n",
      "  batch   30: loss=0.794\n",
      "  batch   31: loss=0.570\n",
      "  batch   32: loss=0.253\n",
      "  batch   33: loss=0.888\n",
      "  batch   34: loss=0.362\n",
      "  batch   35: loss=0.642\n",
      "  batch   36: loss=0.836\n",
      "  batch   37: loss=0.664\n",
      "  batch   38: loss=0.582\n",
      "  batch   39: loss=0.576\n",
      "  batch   40: loss=0.711\n",
      "  batch   41: loss=0.587\n",
      "  batch   42: loss=0.269\n",
      "  batch   43: loss=0.470\n",
      "  batch   44: loss=0.729\n",
      "  batch   45: loss=0.661\n",
      "  batch   46: loss=0.368\n",
      "  batch   47: loss=0.605\n",
      "  batch   48: loss=0.572\n",
      "  batch   49: loss=0.360\n",
      "  batch   50: loss=0.781\n",
      "  batch   51: loss=0.571\n",
      "  batch   52: loss=0.712\n",
      "  batch   53: loss=0.569\n",
      "  batch   54: loss=0.328\n",
      "  batch   55: loss=0.450\n",
      "  batch   56: loss=0.848\n",
      "  batch   57: loss=0.554\n",
      "  batch   58: loss=0.466\n",
      "  batch   59: loss=0.509\n",
      "  batch   60: loss=0.547\n",
      "  batch   61: loss=0.313\n",
      "  batch   62: loss=0.494\n",
      "  batch   63: loss=0.567\n",
      "  batch   64: loss=0.304\n",
      "  batch   65: loss=0.408\n",
      "  batch   66: loss=0.429\n",
      "  batch   67: loss=0.649\n",
      "  batch   68: loss=0.734\n",
      "  batch   69: loss=0.550\n",
      "  batch   70: loss=0.366\n",
      "  batch   71: loss=0.311\n",
      "  batch   72: loss=0.329\n",
      "  batch   73: loss=0.574\n",
      "  batch   74: loss=0.675\n",
      "  batch   75: loss=0.414\n",
      "  batch   76: loss=1.008\n",
      "  batch   77: loss=0.377\n",
      "  batch   78: loss=0.526\n",
      "  batch   79: loss=0.560\n",
      "  batch   80: loss=0.377\n",
      "  batch   81: loss=0.521\n",
      "  batch   82: loss=0.535\n",
      "Testing on validation set\n",
      "  acc=0.725\n",
      "Training epoch 86\n",
      "  batch    1: loss=0.247\n",
      "  batch    2: loss=0.694\n",
      "  batch    3: loss=0.409\n",
      "  batch    4: loss=0.399\n",
      "  batch    5: loss=0.464\n",
      "  batch    6: loss=0.583\n",
      "  batch    7: loss=0.718\n",
      "  batch    8: loss=0.455\n",
      "  batch    9: loss=0.678\n",
      "  batch   10: loss=0.475\n",
      "  batch   11: loss=0.472\n",
      "  batch   12: loss=0.719\n",
      "  batch   13: loss=0.471\n",
      "  batch   14: loss=0.534\n",
      "  batch   15: loss=0.515\n",
      "  batch   16: loss=0.606\n",
      "  batch   17: loss=0.493\n",
      "  batch   18: loss=0.355\n",
      "  batch   19: loss=0.561\n",
      "  batch   20: loss=0.457\n",
      "  batch   21: loss=0.568\n",
      "  batch   22: loss=0.557\n",
      "  batch   23: loss=0.294\n",
      "  batch   24: loss=0.477\n",
      "  batch   25: loss=0.550\n",
      "  batch   26: loss=0.418\n",
      "  batch   27: loss=0.490\n",
      "  batch   28: loss=0.443\n",
      "  batch   29: loss=0.286\n",
      "  batch   30: loss=0.893\n",
      "  batch   31: loss=0.432\n",
      "  batch   32: loss=0.399\n",
      "  batch   33: loss=0.584\n",
      "  batch   34: loss=0.521\n",
      "  batch   35: loss=0.507\n",
      "  batch   36: loss=0.435\n",
      "  batch   37: loss=0.261\n",
      "  batch   38: loss=0.543\n",
      "  batch   39: loss=0.285\n",
      "  batch   40: loss=0.461\n",
      "  batch   41: loss=0.913\n",
      "  batch   42: loss=0.581\n",
      "  batch   43: loss=0.795\n",
      "  batch   44: loss=0.623\n",
      "  batch   45: loss=0.505\n",
      "  batch   46: loss=0.506\n",
      "  batch   47: loss=0.521\n",
      "  batch   48: loss=0.394\n",
      "  batch   49: loss=0.598\n",
      "  batch   50: loss=0.500\n",
      "  batch   51: loss=0.346\n",
      "  batch   52: loss=0.609\n",
      "  batch   53: loss=0.966\n",
      "  batch   54: loss=0.395\n",
      "  batch   55: loss=0.452\n",
      "  batch   56: loss=0.467\n",
      "  batch   57: loss=0.669\n",
      "  batch   58: loss=0.784\n",
      "  batch   59: loss=0.558\n",
      "  batch   60: loss=0.622\n",
      "  batch   61: loss=0.639\n",
      "  batch   62: loss=0.676\n",
      "  batch   63: loss=0.701\n",
      "  batch   64: loss=0.614\n",
      "  batch   65: loss=0.680\n",
      "  batch   66: loss=0.500\n",
      "  batch   67: loss=0.605\n",
      "  batch   68: loss=0.585\n",
      "  batch   69: loss=0.425\n",
      "  batch   70: loss=0.737\n",
      "  batch   71: loss=0.585\n",
      "  batch   72: loss=0.528\n",
      "  batch   73: loss=0.625\n",
      "  batch   74: loss=0.388\n",
      "  batch   75: loss=0.498\n",
      "  batch   76: loss=0.398\n",
      "  batch   77: loss=0.736\n",
      "  batch   78: loss=0.910\n",
      "  batch   79: loss=0.665\n",
      "  batch   80: loss=0.709\n",
      "  batch   81: loss=0.546\n",
      "  batch   82: loss=0.502\n",
      "Testing on validation set\n",
      "  acc=0.720\n",
      "Training epoch 87\n",
      "  batch    1: loss=0.218\n",
      "  batch    2: loss=0.252\n",
      "  batch    3: loss=0.369\n",
      "  batch    4: loss=0.685\n",
      "  batch    5: loss=0.853\n",
      "  batch    6: loss=0.466\n",
      "  batch    7: loss=0.384\n",
      "  batch    8: loss=0.305\n",
      "  batch    9: loss=0.469\n",
      "  batch   10: loss=0.716\n",
      "  batch   11: loss=0.480\n",
      "  batch   12: loss=0.493\n",
      "  batch   13: loss=0.401\n",
      "  batch   14: loss=0.617\n",
      "  batch   15: loss=0.602\n",
      "  batch   16: loss=0.347\n",
      "  batch   17: loss=0.453\n",
      "  batch   18: loss=0.281\n",
      "  batch   19: loss=0.601\n",
      "  batch   20: loss=0.517\n",
      "  batch   21: loss=0.627\n",
      "  batch   22: loss=0.542\n",
      "  batch   23: loss=0.425\n",
      "  batch   24: loss=0.461\n",
      "  batch   25: loss=0.409\n",
      "  batch   26: loss=0.276\n",
      "  batch   27: loss=0.441\n",
      "  batch   28: loss=0.435\n",
      "  batch   29: loss=0.623\n",
      "  batch   30: loss=0.448\n",
      "  batch   31: loss=0.623\n",
      "  batch   32: loss=0.665\n",
      "  batch   33: loss=0.652\n",
      "  batch   34: loss=0.437\n",
      "  batch   35: loss=0.643\n",
      "  batch   36: loss=0.473\n",
      "  batch   37: loss=0.489\n",
      "  batch   38: loss=0.706\n",
      "  batch   39: loss=0.446\n",
      "  batch   40: loss=0.310\n",
      "  batch   41: loss=0.878\n",
      "  batch   42: loss=0.458\n",
      "  batch   43: loss=0.538\n",
      "  batch   44: loss=0.357\n",
      "  batch   45: loss=0.576\n",
      "  batch   46: loss=0.419\n",
      "  batch   47: loss=0.758\n",
      "  batch   48: loss=0.192\n",
      "  batch   49: loss=0.454\n",
      "  batch   50: loss=0.476\n",
      "  batch   51: loss=0.597\n",
      "  batch   52: loss=0.340\n",
      "  batch   53: loss=0.307\n",
      "  batch   54: loss=0.583\n",
      "  batch   55: loss=0.394\n",
      "  batch   56: loss=0.441\n",
      "  batch   57: loss=0.701\n",
      "  batch   58: loss=0.256\n",
      "  batch   59: loss=0.493\n",
      "  batch   60: loss=0.580\n",
      "  batch   61: loss=0.438\n",
      "  batch   62: loss=0.572\n",
      "  batch   63: loss=0.452\n",
      "  batch   64: loss=0.449\n",
      "  batch   65: loss=0.496\n",
      "  batch   66: loss=0.624\n",
      "  batch   67: loss=0.818\n",
      "  batch   68: loss=0.452\n",
      "  batch   69: loss=0.416\n",
      "  batch   70: loss=0.483\n",
      "  batch   71: loss=0.438\n",
      "  batch   72: loss=0.745\n",
      "  batch   73: loss=0.596\n",
      "  batch   74: loss=0.416\n",
      "  batch   75: loss=0.696\n",
      "  batch   76: loss=0.308\n",
      "  batch   77: loss=0.828\n",
      "  batch   78: loss=0.454\n",
      "  batch   79: loss=0.795\n",
      "  batch   80: loss=0.578\n",
      "  batch   81: loss=0.733\n",
      "  batch   82: loss=0.404\n",
      "Testing on validation set\n",
      "  acc=0.715\n",
      "Training epoch 88\n",
      "  batch    1: loss=0.368\n",
      "  batch    2: loss=0.957\n",
      "  batch    3: loss=0.536\n",
      "  batch    4: loss=0.454\n",
      "  batch    5: loss=0.450\n",
      "  batch    6: loss=0.788\n",
      "  batch    7: loss=0.461\n",
      "  batch    8: loss=0.533\n",
      "  batch    9: loss=0.390\n",
      "  batch   10: loss=0.494\n",
      "  batch   11: loss=0.567\n",
      "  batch   12: loss=0.550\n",
      "  batch   13: loss=0.749\n",
      "  batch   14: loss=0.567\n",
      "  batch   15: loss=0.543\n",
      "  batch   16: loss=0.363\n",
      "  batch   17: loss=0.534\n",
      "  batch   18: loss=0.659\n",
      "  batch   19: loss=0.545\n",
      "  batch   20: loss=0.601\n",
      "  batch   21: loss=0.524\n",
      "  batch   22: loss=0.522\n",
      "  batch   23: loss=0.679\n",
      "  batch   24: loss=0.451\n",
      "  batch   25: loss=0.308\n",
      "  batch   26: loss=0.382\n",
      "  batch   27: loss=0.551\n",
      "  batch   28: loss=0.560\n",
      "  batch   29: loss=0.375\n",
      "  batch   30: loss=0.259\n",
      "  batch   31: loss=0.428\n",
      "  batch   32: loss=0.515\n",
      "  batch   33: loss=0.591\n",
      "  batch   34: loss=0.344\n",
      "  batch   35: loss=0.643\n",
      "  batch   36: loss=0.650\n",
      "  batch   37: loss=0.573\n",
      "  batch   38: loss=0.528\n",
      "  batch   39: loss=0.291\n",
      "  batch   40: loss=0.675\n",
      "  batch   41: loss=0.552\n",
      "  batch   42: loss=0.519\n",
      "  batch   43: loss=0.488\n",
      "  batch   44: loss=0.328\n",
      "  batch   45: loss=0.475\n",
      "  batch   46: loss=0.827\n",
      "  batch   47: loss=0.443\n",
      "  batch   48: loss=0.739\n",
      "  batch   49: loss=0.357\n",
      "  batch   50: loss=0.278\n",
      "  batch   51: loss=0.612\n",
      "  batch   52: loss=0.652\n",
      "  batch   53: loss=0.324\n",
      "  batch   54: loss=0.550\n",
      "  batch   55: loss=0.840\n",
      "  batch   56: loss=0.538\n",
      "  batch   57: loss=0.481\n",
      "  batch   58: loss=0.357\n",
      "  batch   59: loss=0.596\n",
      "  batch   60: loss=0.458\n",
      "  batch   61: loss=0.250\n",
      "  batch   62: loss=0.522\n",
      "  batch   63: loss=0.496\n",
      "  batch   64: loss=0.526\n",
      "  batch   65: loss=0.674\n",
      "  batch   66: loss=0.661\n",
      "  batch   67: loss=0.574\n",
      "  batch   68: loss=0.312\n",
      "  batch   69: loss=0.435\n",
      "  batch   70: loss=0.501\n",
      "  batch   71: loss=0.394\n",
      "  batch   72: loss=0.404\n",
      "  batch   73: loss=0.932\n",
      "  batch   74: loss=0.587\n",
      "  batch   75: loss=0.647\n",
      "  batch   76: loss=0.469\n",
      "  batch   77: loss=0.294\n",
      "  batch   78: loss=0.260\n",
      "  batch   79: loss=0.335\n",
      "  batch   80: loss=0.620\n",
      "  batch   81: loss=0.361\n",
      "  batch   82: loss=0.149\n",
      "Testing on validation set\n",
      "  acc=0.731\n",
      "Training epoch 89\n",
      "  batch    1: loss=0.280\n",
      "  batch    2: loss=0.371\n",
      "  batch    3: loss=0.348\n",
      "  batch    4: loss=0.404\n",
      "  batch    5: loss=0.629\n",
      "  batch    6: loss=0.432\n",
      "  batch    7: loss=0.607\n",
      "  batch    8: loss=0.679\n",
      "  batch    9: loss=0.210\n",
      "  batch   10: loss=0.511\n",
      "  batch   11: loss=0.526\n",
      "  batch   12: loss=0.356\n",
      "  batch   13: loss=0.298\n",
      "  batch   14: loss=0.310\n",
      "  batch   15: loss=0.490\n",
      "  batch   16: loss=0.331\n",
      "  batch   17: loss=0.726\n",
      "  batch   18: loss=0.611\n",
      "  batch   19: loss=0.581\n",
      "  batch   20: loss=0.519\n",
      "  batch   21: loss=0.768\n",
      "  batch   22: loss=0.542\n",
      "  batch   23: loss=0.459\n",
      "  batch   24: loss=0.264\n",
      "  batch   25: loss=0.524\n",
      "  batch   26: loss=0.429\n",
      "  batch   27: loss=0.693\n",
      "  batch   28: loss=0.416\n",
      "  batch   29: loss=0.559\n",
      "  batch   30: loss=0.433\n",
      "  batch   31: loss=0.222\n",
      "  batch   32: loss=0.347\n",
      "  batch   33: loss=0.539\n",
      "  batch   34: loss=0.458\n",
      "  batch   35: loss=0.421\n",
      "  batch   36: loss=0.503\n",
      "  batch   37: loss=0.594\n",
      "  batch   38: loss=0.639\n",
      "  batch   39: loss=0.483\n",
      "  batch   40: loss=0.799\n",
      "  batch   41: loss=0.571\n",
      "  batch   42: loss=0.428\n",
      "  batch   43: loss=0.756\n",
      "  batch   44: loss=0.408\n",
      "  batch   45: loss=0.484\n",
      "  batch   46: loss=0.658\n",
      "  batch   47: loss=0.747\n",
      "  batch   48: loss=0.584\n",
      "  batch   49: loss=0.463\n",
      "  batch   50: loss=0.518\n",
      "  batch   51: loss=0.651\n",
      "  batch   52: loss=0.391\n",
      "  batch   53: loss=0.434\n",
      "  batch   54: loss=0.664\n",
      "  batch   55: loss=0.217\n",
      "  batch   56: loss=0.443\n",
      "  batch   57: loss=0.568\n",
      "  batch   58: loss=0.509\n",
      "  batch   59: loss=0.503\n",
      "  batch   60: loss=0.562\n",
      "  batch   61: loss=0.567\n",
      "  batch   62: loss=0.511\n",
      "  batch   63: loss=0.637\n",
      "  batch   64: loss=0.543\n",
      "  batch   65: loss=0.851\n",
      "  batch   66: loss=0.414\n",
      "  batch   67: loss=0.427\n",
      "  batch   68: loss=0.459\n",
      "  batch   69: loss=0.637\n",
      "  batch   70: loss=0.542\n",
      "  batch   71: loss=0.348\n",
      "  batch   72: loss=0.257\n",
      "  batch   73: loss=0.620\n",
      "  batch   74: loss=0.372\n",
      "  batch   75: loss=0.436\n",
      "  batch   76: loss=0.280\n",
      "  batch   77: loss=0.428\n",
      "  batch   78: loss=0.780\n",
      "  batch   79: loss=0.375\n",
      "  batch   80: loss=0.357\n",
      "  batch   81: loss=0.512\n",
      "  batch   82: loss=0.833\n",
      "Testing on validation set\n",
      "  acc=0.730\n",
      "Training epoch 90\n",
      "  batch    1: loss=0.335\n",
      "  batch    2: loss=0.402\n",
      "  batch    3: loss=0.350\n",
      "  batch    4: loss=0.384\n",
      "  batch    5: loss=0.392\n",
      "  batch    6: loss=0.614\n",
      "  batch    7: loss=0.429\n",
      "  batch    8: loss=0.466\n",
      "  batch    9: loss=0.463\n",
      "  batch   10: loss=0.425\n",
      "  batch   11: loss=0.465\n",
      "  batch   12: loss=0.598\n",
      "  batch   13: loss=0.568\n",
      "  batch   14: loss=0.522\n",
      "  batch   15: loss=0.377\n",
      "  batch   16: loss=0.504\n",
      "  batch   17: loss=0.676\n",
      "  batch   18: loss=0.656\n",
      "  batch   19: loss=0.313\n",
      "  batch   20: loss=0.465\n",
      "  batch   21: loss=0.433\n",
      "  batch   22: loss=0.420\n",
      "  batch   23: loss=0.447\n",
      "  batch   24: loss=0.280\n",
      "  batch   25: loss=0.330\n",
      "  batch   26: loss=0.618\n",
      "  batch   27: loss=0.471\n",
      "  batch   28: loss=0.449\n",
      "  batch   29: loss=0.370\n",
      "  batch   30: loss=0.248\n",
      "  batch   31: loss=0.380\n",
      "  batch   32: loss=0.469\n",
      "  batch   33: loss=0.379\n",
      "  batch   34: loss=0.210\n",
      "  batch   35: loss=0.676\n",
      "  batch   36: loss=0.504\n",
      "  batch   37: loss=0.458\n",
      "  batch   38: loss=0.533\n",
      "  batch   39: loss=0.326\n",
      "  batch   40: loss=0.501\n",
      "  batch   41: loss=0.473\n",
      "  batch   42: loss=0.841\n",
      "  batch   43: loss=0.804\n",
      "  batch   44: loss=0.486\n",
      "  batch   45: loss=0.278\n",
      "  batch   46: loss=0.518\n",
      "  batch   47: loss=0.499\n",
      "  batch   48: loss=1.009\n",
      "  batch   49: loss=0.397\n",
      "  batch   50: loss=0.434\n",
      "  batch   51: loss=0.730\n",
      "  batch   52: loss=0.441\n",
      "  batch   53: loss=0.579\n",
      "  batch   54: loss=0.470\n",
      "  batch   55: loss=0.547\n",
      "  batch   56: loss=0.412\n",
      "  batch   57: loss=0.483\n",
      "  batch   58: loss=0.343\n",
      "  batch   59: loss=0.400\n",
      "  batch   60: loss=0.333\n",
      "  batch   61: loss=0.555\n",
      "  batch   62: loss=0.690\n",
      "  batch   63: loss=0.435\n",
      "  batch   64: loss=0.498\n",
      "  batch   65: loss=0.448\n",
      "  batch   66: loss=0.474\n",
      "  batch   67: loss=0.355\n",
      "  batch   68: loss=0.412\n",
      "  batch   69: loss=0.754\n",
      "  batch   70: loss=0.263\n",
      "  batch   71: loss=0.572\n",
      "  batch   72: loss=0.546\n",
      "  batch   73: loss=0.618\n",
      "  batch   74: loss=0.935\n",
      "  batch   75: loss=0.367\n",
      "  batch   76: loss=0.450\n",
      "  batch   77: loss=0.384\n",
      "  batch   78: loss=0.494\n",
      "  batch   79: loss=0.469\n",
      "  batch   80: loss=0.319\n",
      "  batch   81: loss=0.265\n",
      "  batch   82: loss=0.341\n",
      "Testing on validation set\n",
      "  acc=0.718\n",
      "Training epoch 91\n",
      "  batch    1: loss=0.561\n",
      "  batch    2: loss=0.739\n",
      "  batch    3: loss=0.374\n",
      "  batch    4: loss=0.471\n",
      "  batch    5: loss=0.510\n",
      "  batch    6: loss=0.701\n",
      "  batch    7: loss=0.384\n",
      "  batch    8: loss=0.357\n",
      "  batch    9: loss=0.502\n",
      "  batch   10: loss=0.720\n",
      "  batch   11: loss=0.503\n",
      "  batch   12: loss=0.509\n",
      "  batch   13: loss=0.458\n",
      "  batch   14: loss=0.408\n",
      "  batch   15: loss=0.575\n",
      "  batch   16: loss=0.580\n",
      "  batch   17: loss=0.517\n",
      "  batch   18: loss=0.651\n",
      "  batch   19: loss=0.570\n",
      "  batch   20: loss=0.631\n",
      "  batch   21: loss=0.570\n",
      "  batch   22: loss=0.631\n",
      "  batch   23: loss=0.444\n",
      "  batch   24: loss=0.214\n",
      "  batch   25: loss=0.324\n",
      "  batch   26: loss=0.504\n",
      "  batch   27: loss=0.528\n",
      "  batch   28: loss=0.509\n",
      "  batch   29: loss=0.664\n",
      "  batch   30: loss=0.467\n",
      "  batch   31: loss=0.509\n",
      "  batch   32: loss=0.270\n",
      "  batch   33: loss=0.493\n",
      "  batch   34: loss=0.552\n",
      "  batch   35: loss=0.603\n",
      "  batch   36: loss=0.418\n",
      "  batch   37: loss=0.397\n",
      "  batch   38: loss=0.412\n",
      "  batch   39: loss=0.244\n",
      "  batch   40: loss=0.699\n",
      "  batch   41: loss=0.564\n",
      "  batch   42: loss=0.395\n",
      "  batch   43: loss=0.532\n",
      "  batch   44: loss=0.362\n",
      "  batch   45: loss=0.328\n",
      "  batch   46: loss=0.544\n",
      "  batch   47: loss=0.496\n",
      "  batch   48: loss=0.462\n",
      "  batch   49: loss=0.470\n",
      "  batch   50: loss=0.709\n",
      "  batch   51: loss=0.494\n",
      "  batch   52: loss=0.633\n",
      "  batch   53: loss=0.490\n",
      "  batch   54: loss=0.575\n",
      "  batch   55: loss=0.445\n",
      "  batch   56: loss=0.552\n",
      "  batch   57: loss=0.436\n",
      "  batch   58: loss=0.446\n",
      "  batch   59: loss=0.454\n",
      "  batch   60: loss=0.290\n",
      "  batch   61: loss=0.550\n",
      "  batch   62: loss=0.563\n",
      "  batch   63: loss=0.521\n",
      "  batch   64: loss=0.512\n",
      "  batch   65: loss=0.507\n",
      "  batch   66: loss=0.374\n",
      "  batch   67: loss=0.564\n",
      "  batch   68: loss=0.388\n",
      "  batch   69: loss=0.573\n",
      "  batch   70: loss=1.000\n",
      "  batch   71: loss=0.421\n",
      "  batch   72: loss=0.888\n",
      "  batch   73: loss=0.608\n",
      "  batch   74: loss=0.635\n",
      "  batch   75: loss=0.407\n",
      "  batch   76: loss=0.296\n",
      "  batch   77: loss=0.378\n",
      "  batch   78: loss=0.661\n",
      "  batch   79: loss=0.430\n",
      "  batch   80: loss=0.467\n",
      "  batch   81: loss=0.522\n",
      "  batch   82: loss=0.623\n",
      "Testing on validation set\n",
      "  acc=0.725\n",
      "Training epoch 92\n",
      "  batch    1: loss=0.469\n",
      "  batch    2: loss=0.548\n",
      "  batch    3: loss=0.300\n",
      "  batch    4: loss=0.410\n",
      "  batch    5: loss=0.470\n",
      "  batch    6: loss=0.693\n",
      "  batch    7: loss=0.714\n",
      "  batch    8: loss=0.639\n",
      "  batch    9: loss=0.659\n",
      "  batch   10: loss=0.477\n",
      "  batch   11: loss=0.405\n",
      "  batch   12: loss=0.609\n",
      "  batch   13: loss=0.761\n",
      "  batch   14: loss=0.493\n",
      "  batch   15: loss=0.288\n",
      "  batch   16: loss=0.170\n",
      "  batch   17: loss=0.881\n",
      "  batch   18: loss=0.605\n",
      "  batch   19: loss=0.534\n",
      "  batch   20: loss=0.374\n",
      "  batch   21: loss=0.468\n",
      "  batch   22: loss=0.414\n",
      "  batch   23: loss=0.529\n",
      "  batch   24: loss=0.484\n",
      "  batch   25: loss=0.444\n",
      "  batch   26: loss=0.248\n",
      "  batch   27: loss=0.240\n",
      "  batch   28: loss=0.539\n",
      "  batch   29: loss=0.574\n",
      "  batch   30: loss=0.360\n",
      "  batch   31: loss=0.437\n",
      "  batch   32: loss=0.582\n",
      "  batch   33: loss=0.475\n",
      "  batch   34: loss=0.460\n",
      "  batch   35: loss=0.375\n",
      "  batch   36: loss=0.648\n",
      "  batch   37: loss=0.678\n",
      "  batch   38: loss=0.829\n",
      "  batch   39: loss=0.349\n",
      "  batch   40: loss=0.415\n",
      "  batch   41: loss=0.500\n",
      "  batch   42: loss=0.377\n",
      "  batch   43: loss=0.442\n",
      "  batch   44: loss=0.422\n",
      "  batch   45: loss=0.393\n",
      "  batch   46: loss=0.485\n",
      "  batch   47: loss=0.329\n",
      "  batch   48: loss=0.422\n",
      "  batch   49: loss=0.438\n",
      "  batch   50: loss=0.474\n",
      "  batch   51: loss=0.469\n",
      "  batch   52: loss=0.216\n",
      "  batch   53: loss=0.584\n",
      "  batch   54: loss=0.505\n",
      "  batch   55: loss=0.195\n",
      "  batch   56: loss=0.599\n",
      "  batch   57: loss=0.720\n",
      "  batch   58: loss=0.702\n",
      "  batch   59: loss=0.467\n",
      "  batch   60: loss=0.831\n",
      "  batch   61: loss=0.354\n",
      "  batch   62: loss=0.717\n",
      "  batch   63: loss=0.565\n",
      "  batch   64: loss=0.359\n",
      "  batch   65: loss=0.504\n",
      "  batch   66: loss=0.744\n",
      "  batch   67: loss=0.230\n",
      "  batch   68: loss=0.391\n",
      "  batch   69: loss=0.621\n",
      "  batch   70: loss=0.609\n",
      "  batch   71: loss=0.459\n",
      "  batch   72: loss=0.573\n",
      "  batch   73: loss=0.391\n",
      "  batch   74: loss=0.536\n",
      "  batch   75: loss=0.501\n",
      "  batch   76: loss=0.498\n",
      "  batch   77: loss=0.578\n",
      "  batch   78: loss=0.578\n",
      "  batch   79: loss=0.456\n",
      "  batch   80: loss=0.619\n",
      "  batch   81: loss=0.311\n",
      "  batch   82: loss=0.201\n",
      "Testing on validation set\n",
      "  acc=0.724\n",
      "Training epoch 93\n",
      "  batch    1: loss=0.299\n",
      "  batch    2: loss=0.482\n",
      "  batch    3: loss=0.468\n",
      "  batch    4: loss=0.261\n",
      "  batch    5: loss=0.681\n",
      "  batch    6: loss=0.408\n",
      "  batch    7: loss=0.289\n",
      "  batch    8: loss=0.203\n",
      "  batch    9: loss=0.601\n",
      "  batch   10: loss=0.260\n",
      "  batch   11: loss=0.439\n",
      "  batch   12: loss=0.399\n",
      "  batch   13: loss=0.621\n",
      "  batch   14: loss=0.507\n",
      "  batch   15: loss=0.561\n",
      "  batch   16: loss=0.442\n",
      "  batch   17: loss=0.506\n",
      "  batch   18: loss=0.502\n",
      "  batch   19: loss=0.461\n",
      "  batch   20: loss=0.355\n",
      "  batch   21: loss=0.596\n",
      "  batch   22: loss=0.396\n",
      "  batch   23: loss=0.328\n",
      "  batch   24: loss=0.331\n",
      "  batch   25: loss=0.378\n",
      "  batch   26: loss=0.491\n",
      "  batch   27: loss=0.429\n",
      "  batch   28: loss=0.590\n",
      "  batch   29: loss=0.628\n",
      "  batch   30: loss=0.399\n",
      "  batch   31: loss=0.219\n",
      "  batch   32: loss=0.824\n",
      "  batch   33: loss=0.847\n",
      "  batch   34: loss=0.403\n",
      "  batch   35: loss=0.436\n",
      "  batch   36: loss=0.341\n",
      "  batch   37: loss=0.416\n",
      "  batch   38: loss=0.521\n",
      "  batch   39: loss=0.383\n",
      "  batch   40: loss=0.481\n",
      "  batch   41: loss=0.389\n",
      "  batch   42: loss=0.499\n",
      "  batch   43: loss=0.521\n",
      "  batch   44: loss=0.439\n",
      "  batch   45: loss=0.559\n",
      "  batch   46: loss=0.375\n",
      "  batch   47: loss=0.477\n",
      "  batch   48: loss=0.823\n",
      "  batch   49: loss=0.445\n",
      "  batch   50: loss=0.514\n",
      "  batch   51: loss=0.582\n",
      "  batch   52: loss=0.206\n",
      "  batch   53: loss=0.397\n",
      "  batch   54: loss=0.539\n",
      "  batch   55: loss=0.530\n",
      "  batch   56: loss=0.481\n",
      "  batch   57: loss=0.470\n",
      "  batch   58: loss=0.703\n",
      "  batch   59: loss=0.385\n",
      "  batch   60: loss=0.349\n",
      "  batch   61: loss=0.299\n",
      "  batch   62: loss=0.331\n",
      "  batch   63: loss=0.663\n",
      "  batch   64: loss=0.415\n",
      "  batch   65: loss=0.437\n",
      "  batch   66: loss=0.374\n",
      "  batch   67: loss=0.624\n",
      "  batch   68: loss=0.646\n",
      "  batch   69: loss=0.508\n",
      "  batch   70: loss=0.240\n",
      "  batch   71: loss=0.592\n",
      "  batch   72: loss=0.841\n",
      "  batch   73: loss=0.450\n",
      "  batch   74: loss=0.450\n",
      "  batch   75: loss=0.475\n",
      "  batch   76: loss=0.524\n",
      "  batch   77: loss=0.466\n",
      "  batch   78: loss=0.568\n",
      "  batch   79: loss=0.343\n",
      "  batch   80: loss=0.566\n",
      "  batch   81: loss=0.670\n",
      "  batch   82: loss=0.867\n",
      "Testing on validation set\n",
      "  acc=0.724\n",
      "Training epoch 94\n",
      "  batch    1: loss=0.449\n",
      "  batch    2: loss=0.372\n",
      "  batch    3: loss=0.452\n",
      "  batch    4: loss=0.297\n",
      "  batch    5: loss=0.410\n",
      "  batch    6: loss=0.539\n",
      "  batch    7: loss=0.514\n",
      "  batch    8: loss=0.318\n",
      "  batch    9: loss=0.247\n",
      "  batch   10: loss=0.451\n",
      "  batch   11: loss=0.398\n",
      "  batch   12: loss=0.392\n",
      "  batch   13: loss=0.495\n",
      "  batch   14: loss=0.691\n",
      "  batch   15: loss=0.474\n",
      "  batch   16: loss=0.582\n",
      "  batch   17: loss=0.517\n",
      "  batch   18: loss=0.606\n",
      "  batch   19: loss=0.602\n",
      "  batch   20: loss=0.632\n",
      "  batch   21: loss=0.382\n",
      "  batch   22: loss=0.663\n",
      "  batch   23: loss=0.464\n",
      "  batch   24: loss=0.491\n",
      "  batch   25: loss=0.479\n",
      "  batch   26: loss=0.611\n",
      "  batch   27: loss=0.317\n",
      "  batch   28: loss=0.504\n",
      "  batch   29: loss=0.435\n",
      "  batch   30: loss=0.439\n",
      "  batch   31: loss=0.286\n",
      "  batch   32: loss=0.502\n",
      "  batch   33: loss=0.498\n",
      "  batch   34: loss=0.511\n",
      "  batch   35: loss=0.318\n",
      "  batch   36: loss=0.735\n",
      "  batch   37: loss=0.377\n",
      "  batch   38: loss=0.507\n",
      "  batch   39: loss=0.667\n",
      "  batch   40: loss=0.485\n",
      "  batch   41: loss=0.474\n",
      "  batch   42: loss=0.574\n",
      "  batch   43: loss=0.524\n",
      "  batch   44: loss=0.790\n",
      "  batch   45: loss=0.389\n",
      "  batch   46: loss=0.660\n",
      "  batch   47: loss=0.258\n",
      "  batch   48: loss=0.533\n",
      "  batch   49: loss=0.484\n",
      "  batch   50: loss=0.539\n",
      "  batch   51: loss=0.504\n",
      "  batch   52: loss=0.472\n",
      "  batch   53: loss=0.155\n",
      "  batch   54: loss=0.421\n",
      "  batch   55: loss=0.414\n",
      "  batch   56: loss=0.394\n",
      "  batch   57: loss=0.562\n",
      "  batch   58: loss=0.387\n",
      "  batch   59: loss=0.354\n",
      "  batch   60: loss=0.334\n",
      "  batch   61: loss=0.239\n",
      "  batch   62: loss=0.354\n",
      "  batch   63: loss=0.500\n",
      "  batch   64: loss=0.379\n",
      "  batch   65: loss=0.325\n",
      "  batch   66: loss=0.584\n",
      "  batch   67: loss=0.446\n",
      "  batch   68: loss=0.507\n",
      "  batch   69: loss=0.643\n",
      "  batch   70: loss=0.463\n",
      "  batch   71: loss=0.378\n",
      "  batch   72: loss=0.400\n",
      "  batch   73: loss=0.595\n",
      "  batch   74: loss=0.525\n",
      "  batch   75: loss=0.748\n",
      "  batch   76: loss=0.465\n",
      "  batch   77: loss=0.517\n",
      "  batch   78: loss=0.678\n",
      "  batch   79: loss=0.602\n",
      "  batch   80: loss=0.613\n",
      "  batch   81: loss=0.645\n",
      "  batch   82: loss=0.241\n",
      "Testing on validation set\n",
      "  acc=0.722\n",
      "Training epoch 95\n",
      "  batch    1: loss=0.335\n",
      "  batch    2: loss=0.750\n",
      "  batch    3: loss=0.439\n",
      "  batch    4: loss=0.364\n",
      "  batch    5: loss=0.633\n",
      "  batch    6: loss=0.372\n",
      "  batch    7: loss=0.317\n",
      "  batch    8: loss=0.447\n",
      "  batch    9: loss=0.442\n",
      "  batch   10: loss=0.302\n",
      "  batch   11: loss=0.507\n",
      "  batch   12: loss=0.557\n",
      "  batch   13: loss=0.357\n",
      "  batch   14: loss=0.355\n",
      "  batch   15: loss=0.473\n",
      "  batch   16: loss=0.588\n",
      "  batch   17: loss=0.564\n",
      "  batch   18: loss=0.417\n",
      "  batch   19: loss=0.464\n",
      "  batch   20: loss=0.480\n",
      "  batch   21: loss=0.523\n",
      "  batch   22: loss=0.373\n",
      "  batch   23: loss=0.744\n",
      "  batch   24: loss=0.452\n",
      "  batch   25: loss=0.316\n",
      "  batch   26: loss=0.701\n",
      "  batch   27: loss=0.451\n",
      "  batch   28: loss=0.812\n",
      "  batch   29: loss=0.354\n",
      "  batch   30: loss=0.324\n",
      "  batch   31: loss=0.501\n",
      "  batch   32: loss=0.551\n",
      "  batch   33: loss=0.647\n",
      "  batch   34: loss=0.530\n",
      "  batch   35: loss=0.301\n",
      "  batch   36: loss=0.288\n",
      "  batch   37: loss=0.517\n",
      "  batch   38: loss=0.422\n",
      "  batch   39: loss=0.453\n",
      "  batch   40: loss=0.300\n",
      "  batch   41: loss=0.482\n",
      "  batch   42: loss=0.532\n",
      "  batch   43: loss=0.369\n",
      "  batch   44: loss=0.706\n",
      "  batch   45: loss=0.312\n",
      "  batch   46: loss=0.489\n",
      "  batch   47: loss=0.340\n",
      "  batch   48: loss=0.749\n",
      "  batch   49: loss=0.472\n",
      "  batch   50: loss=0.806\n",
      "  batch   51: loss=0.465\n",
      "  batch   52: loss=0.511\n",
      "  batch   53: loss=0.436\n",
      "  batch   54: loss=0.563\n",
      "  batch   55: loss=0.192\n",
      "  batch   56: loss=0.657\n",
      "  batch   57: loss=0.359\n",
      "  batch   58: loss=0.346\n",
      "  batch   59: loss=0.590\n",
      "  batch   60: loss=0.709\n",
      "  batch   61: loss=0.419\n",
      "  batch   62: loss=0.690\n",
      "  batch   63: loss=0.407\n",
      "  batch   64: loss=0.432\n",
      "  batch   65: loss=0.334\n",
      "  batch   66: loss=0.583\n",
      "  batch   67: loss=0.731\n",
      "  batch   68: loss=0.403\n",
      "  batch   69: loss=0.862\n",
      "  batch   70: loss=0.339\n",
      "  batch   71: loss=0.450\n",
      "  batch   72: loss=0.561\n",
      "  batch   73: loss=0.864\n",
      "  batch   74: loss=0.535\n",
      "  batch   75: loss=0.439\n",
      "  batch   76: loss=0.363\n",
      "  batch   77: loss=0.459\n",
      "  batch   78: loss=0.540\n",
      "  batch   79: loss=0.536\n",
      "  batch   80: loss=0.465\n",
      "  batch   81: loss=0.499\n",
      "  batch   82: loss=1.063\n",
      "Testing on validation set\n",
      "  acc=0.714\n",
      "Training epoch 96\n",
      "  batch    1: loss=0.822\n",
      "  batch    2: loss=0.392\n",
      "  batch    3: loss=0.459\n",
      "  batch    4: loss=0.433\n",
      "  batch    5: loss=0.660\n",
      "  batch    6: loss=0.465\n",
      "  batch    7: loss=0.456\n",
      "  batch    8: loss=0.581\n",
      "  batch    9: loss=0.555\n",
      "  batch   10: loss=0.495\n",
      "  batch   11: loss=0.428\n",
      "  batch   12: loss=0.405\n",
      "  batch   13: loss=0.768\n",
      "  batch   14: loss=0.500\n",
      "  batch   15: loss=0.590\n",
      "  batch   16: loss=0.507\n",
      "  batch   17: loss=0.464\n",
      "  batch   18: loss=0.506\n",
      "  batch   19: loss=0.478\n",
      "  batch   20: loss=0.286\n",
      "  batch   21: loss=0.341\n",
      "  batch   22: loss=0.435\n",
      "  batch   23: loss=0.434\n",
      "  batch   24: loss=0.326\n",
      "  batch   25: loss=0.412\n",
      "  batch   26: loss=0.370\n",
      "  batch   27: loss=0.454\n",
      "  batch   28: loss=0.278\n",
      "  batch   29: loss=0.644\n",
      "  batch   30: loss=0.592\n",
      "  batch   31: loss=0.469\n",
      "  batch   32: loss=0.562\n",
      "  batch   33: loss=0.525\n",
      "  batch   34: loss=0.416\n",
      "  batch   35: loss=0.481\n",
      "  batch   36: loss=0.346\n",
      "  batch   37: loss=0.367\n",
      "  batch   38: loss=0.390\n",
      "  batch   39: loss=0.335\n",
      "  batch   40: loss=0.281\n",
      "  batch   41: loss=0.606\n",
      "  batch   42: loss=0.525\n",
      "  batch   43: loss=0.322\n",
      "  batch   44: loss=0.385\n",
      "  batch   45: loss=0.470\n",
      "  batch   46: loss=0.426\n",
      "  batch   47: loss=0.576\n",
      "  batch   48: loss=0.444\n",
      "  batch   49: loss=0.707\n",
      "  batch   50: loss=0.367\n",
      "  batch   51: loss=0.258\n",
      "  batch   52: loss=0.599\n",
      "  batch   53: loss=0.256\n",
      "  batch   54: loss=0.409\n",
      "  batch   55: loss=0.504\n",
      "  batch   56: loss=0.649\n",
      "  batch   57: loss=0.265\n",
      "  batch   58: loss=0.299\n",
      "  batch   59: loss=0.339\n",
      "  batch   60: loss=0.455\n",
      "  batch   61: loss=0.425\n",
      "  batch   62: loss=0.382\n",
      "  batch   63: loss=0.657\n",
      "  batch   64: loss=0.570\n",
      "  batch   65: loss=0.286\n",
      "  batch   66: loss=0.378\n",
      "  batch   67: loss=0.350\n",
      "  batch   68: loss=0.299\n",
      "  batch   69: loss=0.612\n",
      "  batch   70: loss=0.464\n",
      "  batch   71: loss=0.569\n",
      "  batch   72: loss=0.458\n",
      "  batch   73: loss=0.483\n",
      "  batch   74: loss=0.459\n",
      "  batch   75: loss=0.371\n",
      "  batch   76: loss=0.622\n",
      "  batch   77: loss=0.287\n",
      "  batch   78: loss=0.435\n",
      "  batch   79: loss=0.546\n",
      "  batch   80: loss=0.501\n",
      "  batch   81: loss=0.474\n",
      "  batch   82: loss=0.509\n",
      "Testing on validation set\n",
      "  acc=0.722\n",
      "Training epoch 97\n",
      "  batch    1: loss=0.511\n",
      "  batch    2: loss=0.399\n",
      "  batch    3: loss=0.431\n",
      "  batch    4: loss=0.330\n",
      "  batch    5: loss=0.420\n",
      "  batch    6: loss=0.441\n",
      "  batch    7: loss=0.256\n",
      "  batch    8: loss=0.566\n",
      "  batch    9: loss=0.159\n",
      "  batch   10: loss=0.487\n",
      "  batch   11: loss=0.414\n",
      "  batch   12: loss=0.521\n",
      "  batch   13: loss=0.398\n",
      "  batch   14: loss=0.451\n",
      "  batch   15: loss=0.542\n",
      "  batch   16: loss=0.585\n",
      "  batch   17: loss=0.511\n",
      "  batch   18: loss=0.447\n",
      "  batch   19: loss=0.302\n",
      "  batch   20: loss=0.530\n",
      "  batch   21: loss=0.553\n",
      "  batch   22: loss=0.268\n",
      "  batch   23: loss=0.530\n",
      "  batch   24: loss=0.459\n",
      "  batch   25: loss=0.552\n",
      "  batch   26: loss=0.490\n",
      "  batch   27: loss=0.541\n",
      "  batch   28: loss=0.590\n",
      "  batch   29: loss=0.658\n",
      "  batch   30: loss=0.652\n",
      "  batch   31: loss=0.468\n",
      "  batch   32: loss=0.394\n",
      "  batch   33: loss=0.474\n",
      "  batch   34: loss=0.456\n",
      "  batch   35: loss=0.429\n",
      "  batch   36: loss=0.398\n",
      "  batch   37: loss=0.485\n",
      "  batch   38: loss=0.340\n",
      "  batch   39: loss=0.613\n",
      "  batch   40: loss=0.449\n",
      "  batch   41: loss=0.629\n",
      "  batch   42: loss=0.614\n",
      "  batch   43: loss=0.609\n",
      "  batch   44: loss=0.792\n",
      "  batch   45: loss=0.403\n",
      "  batch   46: loss=0.367\n",
      "  batch   47: loss=0.408\n",
      "  batch   48: loss=0.313\n",
      "  batch   49: loss=0.233\n",
      "  batch   50: loss=0.381\n",
      "  batch   51: loss=0.339\n",
      "  batch   52: loss=0.535\n",
      "  batch   53: loss=0.292\n",
      "  batch   54: loss=0.648\n",
      "  batch   55: loss=0.499\n",
      "  batch   56: loss=0.612\n",
      "  batch   57: loss=0.438\n",
      "  batch   58: loss=0.536\n",
      "  batch   59: loss=0.402\n",
      "  batch   60: loss=0.590\n",
      "  batch   61: loss=0.393\n",
      "  batch   62: loss=0.637\n",
      "  batch   63: loss=0.595\n",
      "  batch   64: loss=0.538\n",
      "  batch   65: loss=0.485\n",
      "  batch   66: loss=0.349\n",
      "  batch   67: loss=0.280\n",
      "  batch   68: loss=0.332\n",
      "  batch   69: loss=0.761\n",
      "  batch   70: loss=0.293\n",
      "  batch   71: loss=0.371\n",
      "  batch   72: loss=0.401\n",
      "  batch   73: loss=0.509\n",
      "  batch   74: loss=0.460\n",
      "  batch   75: loss=0.429\n",
      "  batch   76: loss=0.430\n",
      "  batch   77: loss=0.721\n",
      "  batch   78: loss=0.608\n",
      "  batch   79: loss=0.756\n",
      "  batch   80: loss=0.648\n",
      "  batch   81: loss=0.272\n",
      "  batch   82: loss=1.015\n",
      "Testing on validation set\n",
      "  acc=0.709\n",
      "Training epoch 98\n",
      "  batch    1: loss=0.401\n",
      "  batch    2: loss=0.477\n",
      "  batch    3: loss=0.436\n",
      "  batch    4: loss=0.364\n",
      "  batch    5: loss=0.432\n",
      "  batch    6: loss=0.327\n",
      "  batch    7: loss=0.413\n",
      "  batch    8: loss=0.590\n",
      "  batch    9: loss=0.497\n",
      "  batch   10: loss=0.200\n",
      "  batch   11: loss=0.840\n",
      "  batch   12: loss=0.533\n",
      "  batch   13: loss=0.465\n",
      "  batch   14: loss=0.340\n",
      "  batch   15: loss=0.401\n",
      "  batch   16: loss=0.474\n",
      "  batch   17: loss=0.628\n",
      "  batch   18: loss=0.267\n",
      "  batch   19: loss=0.397\n",
      "  batch   20: loss=0.606\n",
      "  batch   21: loss=0.457\n",
      "  batch   22: loss=0.294\n",
      "  batch   23: loss=0.524\n",
      "  batch   24: loss=0.585\n",
      "  batch   25: loss=0.473\n",
      "  batch   26: loss=0.434\n",
      "  batch   27: loss=0.440\n",
      "  batch   28: loss=0.263\n",
      "  batch   29: loss=0.468\n",
      "  batch   30: loss=0.461\n",
      "  batch   31: loss=0.741\n",
      "  batch   32: loss=0.526\n",
      "  batch   33: loss=0.414\n",
      "  batch   34: loss=0.342\n",
      "  batch   35: loss=0.215\n",
      "  batch   36: loss=0.281\n",
      "  batch   37: loss=0.655\n",
      "  batch   38: loss=0.686\n",
      "  batch   39: loss=0.367\n",
      "  batch   40: loss=0.353\n",
      "  batch   41: loss=0.449\n",
      "  batch   42: loss=0.482\n",
      "  batch   43: loss=0.504\n",
      "  batch   44: loss=0.411\n",
      "  batch   45: loss=0.395\n",
      "  batch   46: loss=0.475\n",
      "  batch   47: loss=0.534\n",
      "  batch   48: loss=0.396\n",
      "  batch   49: loss=0.242\n",
      "  batch   50: loss=0.546\n",
      "  batch   51: loss=0.584\n",
      "  batch   52: loss=0.298\n",
      "  batch   53: loss=0.609\n",
      "  batch   54: loss=0.442\n",
      "  batch   55: loss=0.498\n",
      "  batch   56: loss=0.424\n",
      "  batch   57: loss=0.365\n",
      "  batch   58: loss=0.418\n",
      "  batch   59: loss=0.289\n",
      "  batch   60: loss=0.417\n",
      "  batch   61: loss=0.317\n",
      "  batch   62: loss=0.355\n",
      "  batch   63: loss=0.567\n",
      "  batch   64: loss=0.459\n",
      "  batch   65: loss=0.373\n",
      "  batch   66: loss=0.348\n",
      "  batch   67: loss=0.559\n",
      "  batch   68: loss=0.569\n",
      "  batch   69: loss=0.409\n",
      "  batch   70: loss=0.659\n",
      "  batch   71: loss=0.361\n",
      "  batch   72: loss=0.406\n",
      "  batch   73: loss=0.599\n",
      "  batch   74: loss=0.644\n",
      "  batch   75: loss=0.341\n",
      "  batch   76: loss=0.591\n",
      "  batch   77: loss=0.439\n",
      "  batch   78: loss=0.405\n",
      "  batch   79: loss=0.358\n",
      "  batch   80: loss=0.569\n",
      "  batch   81: loss=0.734\n",
      "  batch   82: loss=1.221\n",
      "Testing on validation set\n",
      "  acc=0.722\n",
      "Training epoch 99\n",
      "  batch    1: loss=0.424\n",
      "  batch    2: loss=0.453\n",
      "  batch    3: loss=0.598\n",
      "  batch    4: loss=0.368\n",
      "  batch    5: loss=0.530\n",
      "  batch    6: loss=0.356\n",
      "  batch    7: loss=0.588\n",
      "  batch    8: loss=0.558\n",
      "  batch    9: loss=0.890\n",
      "  batch   10: loss=0.588\n",
      "  batch   11: loss=0.359\n",
      "  batch   12: loss=0.547\n",
      "  batch   13: loss=0.479\n",
      "  batch   14: loss=0.411\n",
      "  batch   15: loss=0.419\n",
      "  batch   16: loss=0.372\n",
      "  batch   17: loss=0.454\n",
      "  batch   18: loss=0.383\n",
      "  batch   19: loss=0.454\n",
      "  batch   20: loss=0.536\n",
      "  batch   21: loss=0.516\n",
      "  batch   22: loss=0.552\n",
      "  batch   23: loss=0.294\n",
      "  batch   24: loss=0.400\n",
      "  batch   25: loss=0.756\n",
      "  batch   26: loss=0.454\n",
      "  batch   27: loss=0.873\n",
      "  batch   28: loss=0.313\n",
      "  batch   29: loss=0.449\n",
      "  batch   30: loss=0.271\n",
      "  batch   31: loss=0.602\n",
      "  batch   32: loss=0.587\n",
      "  batch   33: loss=0.437\n",
      "  batch   34: loss=0.452\n",
      "  batch   35: loss=0.399\n",
      "  batch   36: loss=0.386\n",
      "  batch   37: loss=0.529\n",
      "  batch   38: loss=0.572\n",
      "  batch   39: loss=0.505\n",
      "  batch   40: loss=0.232\n",
      "  batch   41: loss=0.457\n",
      "  batch   42: loss=0.408\n",
      "  batch   43: loss=0.519\n",
      "  batch   44: loss=0.478\n",
      "  batch   45: loss=0.503\n",
      "  batch   46: loss=0.513\n",
      "  batch   47: loss=0.523\n",
      "  batch   48: loss=0.660\n",
      "  batch   49: loss=0.537\n",
      "  batch   50: loss=0.330\n",
      "  batch   51: loss=0.257\n",
      "  batch   52: loss=0.515\n",
      "  batch   53: loss=0.329\n",
      "  batch   54: loss=0.467\n",
      "  batch   55: loss=0.690\n",
      "  batch   56: loss=0.520\n",
      "  batch   57: loss=0.265\n",
      "  batch   58: loss=0.535\n",
      "  batch   59: loss=0.347\n",
      "  batch   60: loss=0.410\n",
      "  batch   61: loss=0.533\n",
      "  batch   62: loss=0.551\n",
      "  batch   63: loss=0.294\n",
      "  batch   64: loss=0.387\n",
      "  batch   65: loss=0.369\n",
      "  batch   66: loss=0.349\n",
      "  batch   67: loss=0.538\n",
      "  batch   68: loss=0.746\n",
      "  batch   69: loss=0.222\n",
      "  batch   70: loss=0.526\n",
      "  batch   71: loss=0.394\n",
      "  batch   72: loss=0.471\n",
      "  batch   73: loss=0.679\n",
      "  batch   74: loss=0.442\n",
      "  batch   75: loss=0.518\n",
      "  batch   76: loss=0.644\n",
      "  batch   77: loss=0.469\n",
      "  batch   78: loss=0.495\n",
      "  batch   79: loss=0.471\n",
      "  batch   80: loss=0.849\n",
      "  batch   81: loss=0.372\n",
      "  batch   82: loss=0.611\n",
      "Testing on validation set\n",
      "  acc=0.722\n"
     ]
    }
   ],
   "source": [
    "raw_model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "raw_model.classifier[-1] = nn.Linear(raw_model.last_channel, 101)\n",
    "raw_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    raw_model.parameters(),\n",
    "    lr=args.lr,\n",
    "    momentum=args.momentum\n",
    ")\n",
    "\n",
    "args.lr = 0.005\n",
    "args.num_epochs = 100\n",
    "\n",
    "for e in range(args.num_epochs):\n",
    "  print('Training epoch {}'.format(e))\n",
    "  train(args, raw_model, criterion, train_loader, optimizer, device)\n",
    "  print('Testing on validation set')\n",
    "  test(args, raw_model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Hu657vG0V906",
    "outputId": "414d4425-38cf-4324-da48-d0f1122be085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  acc=0.732\n"
     ]
    }
   ],
   "source": [
    "test(args, raw_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "caltech_101.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
