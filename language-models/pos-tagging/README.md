### Part of Speech Tagging

I've generally seen natural language processing as one of the most difficult area of computer science problems. During my NLP class I found a few cool projects, shown below.

##### [Probabilistic Context-Free Grammar](./pcfg)

A quick intro to a type of natural language model, a context-free grammar with probabilities/weights deciding frequency of rule selection.

##### [Log-Linear Model](./log-lin-model)

We covered the log-linear model which can be used to model feature interactions in a valid probability distribution. I used character/word embeddings and feature matrices to model the interactions, ultimately learning the language model to compute things such as the probability of a document given a corpus, and classify a document as belonging to one of a few training corpora.
